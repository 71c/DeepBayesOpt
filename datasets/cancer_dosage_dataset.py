from typing import Optional
import numpy as np
from scipy.stats import norm
import torch
from torch.utils.data import IterableDataset

from utils.utils import SizedInfiniteIterableMixin
from datasets.function_samples_dataset import (
    FunctionSamplesDataset, FunctionSamplesItem)


class CancerDosageObjectiveSampler:
    """Sampler of cancer dosage objective functions.
    
    Generates random objective functions of the form
    f(x) = sigmoid(intercept + coefs . x + noise), where
    x is a dosage vector with non-negative entries summing to at most 1.
    The intercept and coefficients are generated by sampling random
    features and multiplying by a sparse coefficient matrix.
    """
    def __init__(self,
                 dim_x: int,
                 dim_features: int,
                 nnz_per_row: int,
                 seed: int,
                 matrix_seed: int,
                 scale_intercept: float = 1.0,
                 scale_coef: float = 1.0,
                 noise_std: float = 0.1,
                 is_simplex: bool = True,
                 device = None):
        """Initializes a cancer dosage objective sampler.

        Args:
            dim_x: Dimensionality of the input domain x.
            dim_features: Number of random features for generating parameters.
            nnz_per_row: Number of non-zero entries per row in coefficient matrix.
            seed: Random seed for sampling objective functions.
            matrix_seed: Random seed for generating the coefficient matrix.
            scale_intercept: Scaling factor for intercept coefficients.
                intercept will be in the range [-scale_intercept, scale_intercept].
            scale_coef: Scaling factor for linear coefficients.
                Each coefficient will be in the range [-scale_coef, scale_coef],
                which makes it so that if x is >= 0 and sum(x) <= 1, then
                coefs . x is in the range [-scale_coef, scale_coef].
            noise_std: Standard deviation of Gaussian observation noise.
            is_simplex: If True, assumes x sums to at most 1.
                If False, assumes x is in [0, 1]^d, and scales coefficients
                down by dim_x to keep coefs . x in [-scale_coef, scale_coef].
            device: Torch device to use.
        """
        if not (0 < nnz_per_row <= dim_features):
            raise ValueError("nnz_per_row must be in the range (0, dim_features]")

        self.dim_x = dim_x
        self.dim_features = dim_features
        self.noise_std = noise_std
        self.device = device
        self.scale_intercept = scale_intercept
        self.scale_coef = scale_coef
        self.nnz_per_row = nnz_per_row
        self.seed = seed
        self.matrix_seed = matrix_seed
        self.is_simplex = is_simplex

        rng = np.random.default_rng(matrix_seed)

        # Construct the coefficient matrix
        n_rows = dim_x + 1 # First row is intercept
        n_cols = dim_features
        matrix = np.zeros((n_rows, n_cols))
        for i in range(n_rows):
            nonzero_indices = rng.choice(n_cols, size=nnz_per_row, replace=False)
            vals = rng.standard_normal(size=nnz_per_row)
            vals /= np.sum(np.abs(vals))
            if i == 0:
                vals *= scale_intercept
            else:
                vals *= scale_coef
                if not is_simplex:
                    # Scale down to keep coefs . x in [-scale_coef, scale_coef]
                    # because if not is_simplex then we assume that x is in [0, 1]^d
                    # rather than in the simplex, so sum(x) can be as large as dim_x.
                    vals /= dim_x
            matrix[i, nonzero_indices] = vals
        self.matrix = matrix

        self.rng = np.random.default_rng(seed)
    
    def sample(self):
        """Samples a new objective function and its generating features.

        Returns:
            tuple: A pair (func, features) where:
                - func: Callable taking tensor x (n x dim_x) and returning
                  sigmoid(intercept + x @ coefs + noise) as tensor (n,).
                - features: Tensor of shape (dim_features,) containing the
                  random features used to generate this objective.
        """
        features = self.rng.standard_normal(size=self.dim_features)
        features_quantiles = norm.cdf(features) * 2 - 1  # Map to be uniform([-1, 1])
        intercept_and_coefs = self.matrix @ features_quantiles # Shape (dim_x + 1,)
        
        intercept = torch.tensor(intercept_and_coefs[0], device=self.device)
        coefs = torch.tensor(intercept_and_coefs[1:], device=self.device)
        dimension = self.dim_x
        noise_std = self.noise_std

        def func(x):
            if x.dim() == 2:
                # n x d (n_datapoints x dimension)
                if x.size(1) != dimension:
                    raise ValueError(
                        f"Incorrect input {x.shape}: dimension does not match {dimension}")
            else:
                raise ValueError(
                    f"Incorrect input {x.shape}: should be of shape n x {dimension}")
            linear_output = intercept + x @ coefs
            if noise_std != 0:
                noise = torch.randn_like(linear_output, device=self.device) * noise_std
                linear_output = linear_output + noise
            return torch.sigmoid(linear_output)

        return func, {
            'features': torch.tensor(features, device=self.device),
            'intercept': intercept,
            'coefs': coefs
        }


class CancerDosageDataset(
    FunctionSamplesDataset, IterableDataset, SizedInfiniteIterableMixin):
    """An IterableDataset that generates random cancer dosage optimization problems.
    The x values are uniformly distributed on the simplex
    (non-negative entries summing to at most 1)."""

    def __init__(self,
                 dim_x: int,
                 dim_features: int,
                 nnz_per_row: int,
                 seed: int,
                 matrix_seed: int,
                 scale_intercept: float = 1.0,
                 scale_coef: float = 1.0,
                 noise_std: float = 0.1,
                 is_simplex: bool = True,
                 n_datapoints: Optional[int] = None,
                 n_datapoints_random_gen = None,
                 device = None,
                 dataset_size: Optional[int] = None):
        """Create a dataset that generates random cancer dosage optimization problems.

        Args:
            dim_x: Dimensionality of dosage input.
            dim_features: Number of random features for parameter generation.
            nnz_per_row: Number of non-zero entries per row in coefficient matrix.
            seed: Random seed for sampling objective functions.
            matrix_seed: Random seed for generating the coefficient matrix.
            scale_intercept: Scaling factor for intercept.
            scale_coef: Scaling factor for linear coefficients.
            noise_std: Standard deviation of observation noise.
            is_simplex: If True, assumes x sums to at most 1.
                If False, assumes x is in [0, 1]^d, and scales coefficients
                down by dim_x to keep coefs . x in [-scale_coef, scale_coef].
            seed: Random seed for sampling objective functions.
            matrix_seed: If provided, seed for generating
                the matrix used . If None, uses `seed`.
            n_datapoints: Number of dosage evaluations per sample (fixed).
            n_datapoints_random_gen: Generator for random number of dosage evaluations.
            device: torch.device for computations.
            dataset_size: Number of optimization problems to generate (None for infinite).
        """
        # Exactly one of n_datapoints and n_datapoints_random_gen should be specified
        if not ((n_datapoints is None) ^ (n_datapoints_random_gen is None)):
            raise ValueError("Exactly one of n_datapoints and n_datapoints_random_gen "
                             "should be specified.")
        if n_datapoints is not None and (
            not isinstance(n_datapoints, int) or n_datapoints <= 0):
            raise ValueError("n_datapoints should be a positive integer.")

        self.n_datapoints = n_datapoints
        self.n_datapoints_random_gen = n_datapoints_random_gen
        self.is_simplex = is_simplex

        self.objective_sampler = CancerDosageObjectiveSampler(
            dim_x=dim_x,
            dim_features=dim_features,
            nnz_per_row=nnz_per_row,
            seed=seed,
            matrix_seed=matrix_seed,
            scale_intercept=scale_intercept,
            scale_coef=scale_coef,
            noise_std=noise_std,
            is_simplex=is_simplex,
            device=device
        )
        self.device = self.objective_sampler.device

        if is_simplex:
            # Sample dosage points uniformly from the simplex
            # (non-negative entries summing to at most 1)
            # Use Dirichlet distribution with uniform parameters to sample from simplex
            # Drop last coordinate to get sum <= 1
            self._xvalue_distribution = torch.distributions.Dirichlet(
                torch.ones(dim_x + 1, device=device))
        else:
            self._xvalue_distribution = torch.distributions.Uniform(
                torch.zeros(dim_x, device=device),
                torch.ones(dim_x, device=device))

        # Required for compatibility with FunctionSamplesDataset infrastructure
        self._model_sampler = None

        if dataset_size is None:
            import math
            dataset_size = math.inf
        else:
            if not isinstance(dataset_size, int) or dataset_size <= 0:
                raise ValueError("dataset_size should be a positive integer or None.")
        self._size = dataset_size

    @property
    def data_is_fixed(self):
        return False

    def data_is_loaded(self):
        return False

    def _init_params(self):
        return tuple(), dict(
            dim_x=self.objective_sampler.dim_x,
            dim_features=self.objective_sampler.dim_features,
            nnz_per_row=self.objective_sampler.nnz_per_row,
            scale_intercept=self.objective_sampler.scale_intercept,
            scale_coef=self.objective_sampler.scale_coef,
            noise_std=self.objective_sampler.noise_std,
            is_simplex=self.objective_sampler.is_simplex,
            seed=self.objective_sampler.seed,
            matrix_seed=self.objective_sampler.matrix_seed,
            n_datapoints=self.n_datapoints,
            n_datapoints_random_gen=self.n_datapoints_random_gen,
            device=self.device,
            dataset_size=self._size
        )

    def save(self, dir_name: str, verbose: bool = True):
        raise NotImplementedError(
            "CancerDosageDataset does not support saving to a file")

    def copy_with_new_size(self, dataset_size: int):
        """Create a copy of the dataset with a new dataset size."""
        ret = self.__new__(self.__class__)
        ret.n_datapoints = self.n_datapoints
        ret.n_datapoints_random_gen = self.n_datapoints_random_gen
        ret.objective_sampler = self.objective_sampler
        ret.device = self.device
        ret._model_sampler = None
        ret._size = dataset_size
        return ret

    def random_split(self, lengths):
        # Delegate to the mixin implementation
        return SizedInfiniteIterableMixin.random_split(self, lengths)

    def _next(self):
        """Generate a random cancer dosage optimization problem.

        Returns:
            FunctionSamplesItem with:
            - x_values: dosage values (n_datapoints, dim_x)
            - y_values: corresponding survival probabilities (n_datapoints, 1)
        """
        # Determine number of dosage evaluations
        if self.n_datapoints is None:  # then it's given by a distribution
            n_dosage_evals = self.n_datapoints_random_gen()
            if not isinstance(n_dosage_evals, int) or n_dosage_evals <= 0:
                raise ValueError(
                    "n_datapoints_random_gen should return a positive integer.")
        else:
            n_dosage_evals = self.n_datapoints

        x_dosages = self._xvalue_distribution.sample((n_dosage_evals,))
        if self.is_simplex:
            # Drop last coordinate to get sum <= 1
            x_dosages = x_dosages[:, :-1]

        objective_function, _ = self.objective_sampler.sample()
        output = objective_function(x_dosages).unsqueeze(-1)

        return FunctionSamplesItem(x_dosages, output)


# Cache for cancer dosage function min/max values
_cancer_dosage_opt_cache = {}

def get_cancer_dosage_function_min_max(
        intercept: torch.Tensor,
        coefs: torch.Tensor,
        noise_std: float,
        is_simplex: bool,
        objective_name: str) -> tuple[float, float]:
    """Get exact min and max values for a cancer dosage objective function
    sigmoid(intercept + coefs @ x + noise).
    
    Args:
        intercept: Intercept term of the linear function.
        coefs: Coefficient vector for the linear function.
        noise_std: Standard deviation of observation noise.
        is_simplex: If True, x is constrained to simplex (x >= 0, sum(x) <= 1).
                   If False, x is constrained to hypercube (x in [0, 1]^d).
        objective_name: Name for caching purposes.
        
    Returns:
        Tuple of (min_value, max_value) after applying sigmoid.
    """
    if objective_name not in _cancer_dosage_opt_cache:
        # Solve linear program: min/max coefs @ x subject to constraints
        coefs_cpu = coefs.cpu().numpy()
        
        if is_simplex:
            # Simplex constraint: x >= 0, sum(x) <= 1
            # For max: put all weight on coordinate with largest positive coefficient
            # For min: put all weight on coordinate with most negative coefficient
            max_coef_idx = np.argmax(coefs_cpu)
            min_coef_idx = np.argmin(coefs_cpu)
            
            linear_max = max(coefs_cpu[max_coef_idx], 0.0)  # Could be 0 if all coefs negative
            linear_min = min(coefs_cpu[min_coef_idx], 0.0)  # Could be 0 if all coefs positive
        else:
            # Hypercube constraint: x in [0, 1]^d
            # For max: set x[i] = 1 if coefs[i] > 0, else x[i] = 0
            # For min: set x[i] = 0 if coefs[i] > 0, else x[i] = 1
            linear_max = np.sum(np.maximum(coefs_cpu, 0.0))
            linear_min = np.sum(np.minimum(coefs_cpu, 0.0))
        
        # Add intercept
        intercept_val = intercept.cpu().item()
        pre_link_max = linear_max + intercept_val
        pre_link_min = linear_min + intercept_val
        
        # Adjust for noise if present (before applying sigmoid)
        if noise_std > 0:
            noise_adjustment = 2.0 * noise_std
            pre_link_max += noise_adjustment
            pre_link_min -= noise_adjustment
        
        # Apply sigmoid to get final bounds
        y_min = torch.sigmoid(torch.tensor(pre_link_min)).item()
        y_max = torch.sigmoid(torch.tensor(pre_link_max)).item()
        
        print(f"Optimized {objective_name} with intercept={intercept_val}, "
              f"coefs={coefs_cpu}, {noise_std=}, {is_simplex=}: "
              f"pre_link_min={pre_link_min:.4f}, pre_link_max={pre_link_max:.4f}, "
              f"y_min={y_min:.4f}, y_max={y_max:.4f}")
        
        _cancer_dosage_opt_cache[objective_name] = (y_min, y_max)
    
    return _cancer_dosage_opt_cache[objective_name]


if __name__ == "__main__":
    import matplotlib.pyplot as plt

    # Test the dataset with low dimensions
    print("Testing CancerDosageDataset with low dimensions\n")

    num_functions = 12

    # Create a small dataset
    dataset = CancerDosageDataset(
        dim_x=5,
        dim_features=50,
        nnz_per_row=10,
        scale_intercept=4.0,
        scale_coef=20.0,
        noise_std=0.0,
        is_simplex=False,
        seed=42,
        matrix_seed=123,
        n_datapoints=100,       # dosage evaluations per function
        dataset_size=num_functions          # number of functions
    )

    print(f"Dataset configuration:")
    print(f"  dim_x: {dataset.objective_sampler.dim_x}")
    print(f"  dim_features: {dataset.objective_sampler.dim_features}")
    print(f"  noise_std: {dataset.objective_sampler.noise_std}")
    print(f"  n_datapoints per sample: {dataset.n_datapoints}")
    print(f"  dataset_size: {dataset._size}\n")

    print(f"Coefficient matrix shape: {dataset.objective_sampler.matrix.shape}")
    print(f"Coefficient matrix:\n{dataset.objective_sampler.matrix}\n")

    nrows_show = 10

    # Generate and display samples
    samples_list = []
    for i, sample in enumerate(dataset):
        samples_list.append(sample)
        print(f"Sample {i+1}:")
        print(f"  x_values shape: {sample.x_values.shape}")
        print(f"  x_values (first {nrows_show} rows):\n{sample.x_values[:nrows_show]}")
        print(f"  x_values sum per row (should be <= 1): {sample.x_values.sum(dim=1)[:nrows_show]}")
        print(f"  y_values shape: {sample.y_values.shape}")
        print(f"  y_values (first {nrows_show} rows): {sample.y_values[:nrows_show].squeeze()}")
        print(f"  y_values range: [{sample.y_values.min():.4f}, {sample.y_values.max():.4f}]")
        print()

    # Create histograms of y values for each function
    ncols = int(np.ceil(np.sqrt(num_functions)))
    nrows_plot = int(np.ceil(num_functions / ncols))

    fig, axes = plt.subplots(nrows_plot, ncols, figsize=(4*ncols, 3*nrows_plot))
    if num_functions == 1:
        axes = np.array([axes])
    axes = axes.flatten()

    for i, sample in enumerate(samples_list):
        y_values = sample.y_values.cpu().numpy().flatten()
        axes[i].hist(y_values, bins='auto', edgecolor='black', alpha=0.7)
        axes[i].set_xlabel('y value')
        axes[i].set_ylabel('Frequency')
        axes[i].set_title(f'Function {i+1} - y value distribution')
        axes[i].grid(alpha=0.3)

    # Hide unused subplots
    for i in range(num_functions, len(axes)):
        axes[i].axis('off')

    plt.tight_layout()
    # plt.show()

    # save the figure 
    fig.savefig("cancer_dosage_dataset_histograms.pdf")
