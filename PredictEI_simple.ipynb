{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install botorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting botorch\n",
            "  Downloading botorch-0.10.0-py3-none-any.whl (613 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from botorch) (1.11.4)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.10/dist-packages (from botorch) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from botorch) (2.2.1+cu121)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.9.0-py3-none-any.whl (745 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.2/745.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch==1.11 (from botorch)\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linear-operator==0.5.1 (from botorch)\n",
            "  Downloading linear_operator-0.5.1-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch==1.11->botorch) (1.2.2)\n",
            "Collecting jaxtyping>=0.2.9 (from linear-operator==0.5.1->botorch)\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard~=2.13.3 (from linear-operator==0.5.1->botorch)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->botorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->botorch) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.11->botorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.11->botorch) (3.4.0)\n",
            "Installing collected packages: pyro-api, typeguard, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, pyro-ppl, linear-operator, gpytorch, botorch\n",
            "Successfully installed botorch-0.10.0 gpytorch-1.11 jaxtyping-0.2.28 linear-operator-0.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pyro-api-0.1.2 pyro-ppl-1.9.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mregrjzrYp5_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.acquisition.analytic import ExpectedImprovement\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(torch.double) # double == float64\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question: How to set the lengthscale for each batch of the kernel?\n",
        "# (will figure this out)\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/kernels.html#gpytorch.kernels.Kernel\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/kernels/kernel.html#Kernel\n",
        "\n",
        "# Question: when maximizing the likelihood of batched GP, then does it maximize the\n",
        "# sum of all the likelihoods of all the batches, or does it maximize them independently?\n",
        "# I would prefer the latter, but this tutorial\n",
        "# https://github.com/cornellius-gp/gpytorch/blob/master/examples/08_Advanced_Usage/Simple_Batch_Mode_GP_Regression.ipynb\n",
        "# maximizes the sum. But I'm not sure what `botorch.fit.fit_gpytorch_mll` does."
      ],
      "metadata": {
        "id": "UnpZ5oOD6xg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_EI_GP(X_hist, y_hist, X, kernel, fit_params=False):\n",
        "    \"\"\"Calculate the exact Expected Improvements at `n_eval` points,\n",
        "    given `N` histories each of length `n_train`.\n",
        "    Assumes noise-free observations, so gives a fixed noise level of 1e-6\n",
        "\n",
        "    Args:\n",
        "        X_hist: History x values, of shape `(N, n_train, d)`\n",
        "        y_hist: History y values, of shape `(N, n_train)` or `(N, n_train, 1)`\n",
        "        X: Evaluation x points, of shape `(N, n_eval, d)`\n",
        "        kernel: the kernel to use\n",
        "        fit_params: whether to fit parameters by maximizing the marginal log\n",
        "            likelihood\n",
        "\n",
        "    Returns:\n",
        "        A `(N, n_eval)`-dim tensor of Expected Improvement values at the\n",
        "        given design points `X`.\n",
        "    \"\"\"\n",
        "    # Get y_hist into (N, n_train, 1) shape so we can give to SingleTaskGP\n",
        "    if y_hist.dim() == 2:\n",
        "        y_hist = y_hist.unsqueeze(-1)\n",
        "    elif y_hist.dim() == 3:\n",
        "        assert y_hist.size(2) == 1\n",
        "    else:\n",
        "        raise AssertionError(\"y_hist dimension must be 2 or 3\")\n",
        "\n",
        "    assert X_hist.dim() == X.dim() == 3\n",
        "    assert X_hist.size(0) == y_hist.size(0) == X.size(0) # N=N=N\n",
        "    assert X_hist.size(1) == y_hist.size(1) # n_train=n_train\n",
        "    assert X_hist.size(2) == X.size(2) # d=d\n",
        "\n",
        "    y_hist_var = torch.full_like(y_hist, 1e-6)\n",
        "    model = SingleTaskGP(X_hist, y_hist, y_hist_var, covar_module=kernel)\n",
        "\n",
        "    if fit_params:\n",
        "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "        fit_gpytorch_mll(mll)\n",
        "\n",
        "    # best_f has shape (N,)\n",
        "    best_f = y_hist.squeeze().amax(1) # unsqueezed so need to squeeze again\n",
        "    EI_object = ExpectedImprovement(model, best_f=best_f, maximize=True)\n",
        "\n",
        "    # X currently has shape (N, n_eval, d)\n",
        "    # Make it have shape (b_1, b_2, 1, d) where (b_1, b_2) = (N, n_eval)\n",
        "    # The added \"1\" would be the \"q\" for \"q-batch\" in general\n",
        "    X = X.unsqueeze(2)\n",
        "\n",
        "    # But also need to swap the batch dimensions to align with what it says here\n",
        "    # https://botorch.org/docs/batching#batched-models\n",
        "    X = torch.transpose(X, 0, 1) # Now has shape (n_eval, N, 1, d)\n",
        "\n",
        "    EI_values = EI_object(X) # shape (n_eval, N)\n",
        "\n",
        "    EI_values = torch.transpose(EI_values, 0, 1) # need to swap again\n",
        "\n",
        "    return EI_values # shape (N, n_eval)\n"
      ],
      "metadata": {
        "id": "6TirkEC7a5Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.2, 0.9, 3.1], device=device)\n",
        "y = torch.tensor([0.1, 0.2, -1.1])\n",
        "x * y"
      ],
      "metadata": {
        "id": "4jVuau2aYkQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}