{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.acquisition.analytic import ExpectedImprovement\n",
        "\n",
        "from torch.distributions import Uniform, Normal, Independent, Distribution\n",
        "from torch import Tensor\n",
        "from botorch.models.model import Model\n",
        "from typing import List\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnpZ5oOD6xg_"
      },
      "outputs": [],
      "source": [
        "# Question: How to set the lengthscale for each batch of the kernel?\n",
        "# (will figure this out)\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/kernels.html#gpytorch.kernels.Kernel\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/kernels/kernel.html#Kernel\n",
        "\n",
        "# Question: when maximizing the likelihood of batched GP, then does it maximize the\n",
        "# sum of all the likelihoods of all the batches, or does it maximize them independently?\n",
        "# I would prefer the latter, but this tutorial\n",
        "# https://github.com/cornellius-gp/gpytorch/blob/master/examples/08_Advanced_Usage/Simple_Batch_Mode_GP_Regression.ipynb\n",
        "# maximizes the sum. But I'm not sure what `botorch.fit.fit_gpytorch_mll` does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6TirkEC7a5Mq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gpytorch.models.gp.GP"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpytorch.models.gp.GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://pytorch.org/docs/stable/data.html#map-style-datasets\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0502, 0.2043, 0.2682, 0.4175],\n",
              "         [0.2595, 0.4476, 0.9753, 0.9090],\n",
              "         [0.3216, 0.9895, 0.0275, 0.6854],\n",
              "         [0.2925, 0.5978, 0.6946, 0.4047],\n",
              "         [0.0677, 0.4458, 0.4330, 0.7364],\n",
              "         [0.0247, 0.4647, 0.0088, 0.7085],\n",
              "         [0.3631, 0.7085, 0.1066, 0.6757],\n",
              "         [0.9992, 0.8855, 0.3953, 0.6791],\n",
              "         [0.6873, 0.4191, 0.7254, 0.9278],\n",
              "         [0.6426, 0.6090, 0.1075, 0.6560],\n",
              "         [0.1030, 0.1263, 0.2853, 0.5611],\n",
              "         [0.5030, 0.8255, 0.5013, 0.0890],\n",
              "         [0.8301, 0.7563, 0.1136, 0.7293],\n",
              "         [0.5443, 0.8416, 0.1191, 0.1747],\n",
              "         [0.5138, 0.0511, 0.3795, 0.3961],\n",
              "         [0.3495, 0.5621, 0.9127, 0.3534],\n",
              "         [0.4982, 0.4669, 0.2925, 0.1053],\n",
              "         [0.9870, 0.9217, 0.1165, 0.3036],\n",
              "         [0.5972, 0.7843, 0.1710, 0.5932],\n",
              "         [0.6746, 0.5347, 0.1628, 0.3182]]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dimension = 4\n",
        "m = Uniform(torch.zeros(dimension), torch.ones(dimension))\n",
        "xvalue_distribution = Independent(m, 1)\n",
        "\n",
        "ss = xvalue_distribution.sample(torch.Size([20]))\n",
        "ss.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.5565e-02, 8.5571e-05, 6.4938e-03],\n",
            "        [3.5321e-01, 1.5565e-02, 2.3545e-05],\n",
            "        [9.5923e-01, 5.1374e-01, 1.7782e-09]], grad_fn=<RBFCovarianceBackward>)\n"
          ]
        }
      ],
      "source": [
        "kernel = RBFKernel()\n",
        "x1 = torch.tensor([1.0, 2.0, 3.2])\n",
        "x2 = torch.tensor([3.0, 4., -1.2])\n",
        "print(kernel(x1, x2).to_dense())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
