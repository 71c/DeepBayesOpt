{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.acquisition.analytic import ExpectedImprovement\n",
        "\n",
        "from torch.distributions import Uniform, Normal, Independent, Distribution\n",
        "from typing import List\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnpZ5oOD6xg_"
      },
      "outputs": [],
      "source": [
        "# Question: How to set the lengthscale for each batch of the kernel?\n",
        "# (will figure this out)\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/kernels.html#gpytorch.kernels.Kernel\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/kernels/kernel.html#Kernel\n",
        "\n",
        "# Question: when maximizing the likelihood of batched GP, then does it maximize the\n",
        "# sum of all the likelihoods of all the batches, or does it maximize them independently?\n",
        "# I would prefer the latter, but this tutorial\n",
        "# https://github.com/cornellius-gp/gpytorch/blob/master/examples/08_Advanced_Usage/Simple_Batch_Mode_GP_Regression.ipynb\n",
        "# maximizes the sum. But I'm not sure what `botorch.fit.fit_gpytorch_mll` does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6TirkEC7a5Mq"
      },
      "outputs": [],
      "source": [
        "def calculate_EI_GP(X_hist, y_hist, X, kernel, fit_params=False):\n",
        "    \"\"\"Calculate the exact Expected Improvements at `n_eval` points,\n",
        "    given `N` histories each of length `n_train`.\n",
        "    Assumes noise-free observations, so gives a fixed noise level of 1e-6\n",
        "\n",
        "    Args:\n",
        "        X_hist: History x values, of shape `(N, n_train, d)`\n",
        "        y_hist: History y values, of shape `(N, n_train)` or `(N, n_train, 1)`\n",
        "        X: Evaluation x points, of shape `(N, n_eval, d)`\n",
        "        kernel: the kernel to use\n",
        "        fit_params: whether to fit parameters by maximizing the marginal log\n",
        "            likelihood\n",
        "\n",
        "    Returns:\n",
        "        A `(N, n_eval)`-dim tensor of Expected Improvement values at the\n",
        "        given design points `X`.\n",
        "    \"\"\"\n",
        "    # Get y_hist into (N, n_train, 1) shape so we can give to SingleTaskGP\n",
        "    if y_hist.dim() == 2:\n",
        "        y_hist = y_hist.unsqueeze(-1)\n",
        "    elif y_hist.dim() == 3:\n",
        "        assert y_hist.size(2) == 1\n",
        "    else:\n",
        "        raise AssertionError(\"y_hist dimension must be 2 or 3\")\n",
        "\n",
        "    assert X_hist.dim() == X.dim() == 3\n",
        "    assert X_hist.size(0) == y_hist.size(0) == X.size(0) # N=N=N\n",
        "    assert X_hist.size(1) == y_hist.size(1) # n_train=n_train\n",
        "    assert X_hist.size(2) == X.size(2) # d=d\n",
        "\n",
        "    y_hist_var = torch.full_like(y_hist, 1e-6)\n",
        "    model = SingleTaskGP(X_hist, y_hist, y_hist_var, covar_module=kernel)\n",
        "\n",
        "    if fit_params:\n",
        "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "        fit_gpytorch_mll(mll)\n",
        "\n",
        "    # best_f has shape (N,)\n",
        "    best_f = y_hist.squeeze().amax(1) # unsqueezed so need to squeeze again\n",
        "    EI_object = ExpectedImprovement(model, best_f=best_f, maximize=True)\n",
        "\n",
        "    # X currently has shape (N, n_eval, d)\n",
        "    # Make it have shape (b_1, b_2, 1, d) where (b_1, b_2) = (N, n_eval)\n",
        "    # The added \"1\" would be the \"q\" for \"q-batch\" in general\n",
        "    X = X.unsqueeze(2)\n",
        "\n",
        "    # But also need to swap the batch dimensions to align with what it says here\n",
        "    # https://botorch.org/docs/batching#batched-models\n",
        "    X = torch.transpose(X, 0, 1) # Now has shape (n_eval, N, 1, d)\n",
        "\n",
        "    EI_values = EI_object(X) # shape (n_eval, N)\n",
        "\n",
        "    EI_values = torch.transpose(EI_values, 0, 1) # need to swap again\n",
        "\n",
        "    return EI_values # shape (N, n_eval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gpytorch.models.gp.GP"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpytorch.models.gp.GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://pytorch.org/docs/stable/data.html#map-style-datasets\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n",
        "class GaussainProcessRandomDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, dimension, n_datapoints:int=None,\n",
        "                 n_datapoints_random_gen=None,\n",
        "                 xvalue_distribution: Distribution=None,\n",
        "                 models: List[botorch.models.model.Model]=None, # gpytorch.models.gp.GP\n",
        "                 model_probabilities=None, observation_noise:bool=False):\n",
        "        \"\"\"Create a dataset that generates random Gaussian Process data.\n",
        "\n",
        "        Args:\n",
        "            dimension: The dimension of the feature space d\n",
        "            n_datapoints: number of (x,y) pairs to generate with each sample;\n",
        "                could be None\n",
        "            n_datapoints_random_gen: a callable that returns a random natural\n",
        "                number that is the number of datapoints.\n",
        "                Note: exactly one of n_datapoints and n_datapoints_random_gen\n",
        "                should be speicified (not be None).\n",
        "            xvalue_distribution: a torch.distributions.Distribution object that\n",
        "                represents the probability distribution for generating each iid\n",
        "                value $x \\in \\mathbb{R}^{dimension}$. Default: iid Uniform(0,1)\n",
        "            models: a list of models to choose from randomly; defaults to a\n",
        "                single SingleTaskGP model with the default BoTorch Matern 5/2\n",
        "                kernel and Gamma priors for the lengthscale, outputscale, and\n",
        "                noise level.\n",
        "                It is *assumed* that each model provided is single-output,\n",
        "                single-batch, and contains *no data*.\n",
        "            model_probabilities: list of probability of choosing each model\n",
        "            observation_noise: boolean specifying whether to generate the data\n",
        "                to include the \"observation noise\" given by the model's\n",
        "                likelihood (True), or not (False)\n",
        "        \"\"\"\n",
        "        self.dimension = dimension\n",
        "        self.observation_noise = observation_noise\n",
        "\n",
        "        # exacly one of them should be specified; verify this by xor\n",
        "        assert (n_datapoints is None) ^ (n_datapoints_random_gen is None)\n",
        "        self.n_datapoints = n_datapoints\n",
        "        self.n_datapoints_random_gen = n_datapoints_random_gen\n",
        "        \n",
        "        if xvalue_distribution is None:\n",
        "            # m = Normal(torch.zeros(dimension), torch.ones(dimension))\n",
        "            m = Uniform(torch.zeros(dimension), torch.ones(dimension))\n",
        "            xvalue_distribution = Independent(m, 1)\n",
        "        self.xvalue_distribution = xvalue_distribution\n",
        "\n",
        "        if models is None: # models is None implies model_probabilities is None\n",
        "            assert model_probabilities is None\n",
        "\n",
        "            train_X = torch.empty(1, 0, dimension) # (nbatch, n_data, dimension)\n",
        "            train_Y = torch.empty(1, 0, 1)         # (nbatch, n_data, n_out)\n",
        "            # Default: Matern 5/2 kernel with gamma priors on\n",
        "            # lengthscale, outputscale, and noise level\n",
        "            models = [SingleTaskGP(train_X, train_Y)]\n",
        "            model_probabilities = torch.tensor([1.0])\n",
        "        elif model_probabilities is None:\n",
        "            model_probabilities = torch.full([len(models)], 1/len(models))\n",
        "        else: # if both were specified, then,\n",
        "            model_probabilities = torch.as_tensor(model_probabilities)\n",
        "            assert model_probabilities.dim() == 1\n",
        "            assert len(models) == len(model_probabilities)\n",
        "        self.models = models\n",
        "        self.model_probabilities = model_probabilities\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        # pick the model\n",
        "        # https://discuss.pytorch.org/t/torch-equivalent-of-numpy-random-choice/16146\n",
        "        model_index = self.model_probabilities.multinomial(num_samples=1, \n",
        "                                                           replacement=True)[0]\n",
        "        model = self.models[model_index]\n",
        "        random_model = model.pyro_sample_from_prior()\n",
        "\n",
        "        # pick the number of data points\n",
        "        if self.n_datapoints is None: # then it's given by a distribution\n",
        "            n_datapoints = self.n_datapoints_random_gen()\n",
        "        else:\n",
        "            n_datapoints = self.n_datapoints\n",
        "\n",
        "        # generate the x-values\n",
        "        x_values = self.xvalue_distribution.sample(torch.Size([n_datapoints]))\n",
        "        assert x_values.dim() == 2 # should have shape (n_datapoints, dimension)\n",
        "        x_values = x_values.unsqueeze(0) # make have 1 batch for Botorch\n",
        "\n",
        "        # It is assumed that all the models don't have any data,\n",
        "        # so the \"posterior\" is actually just a prior.\n",
        "        # There are ways to draw from prior if the models don't have data, but\n",
        "        # they are either hacky or specific to GPyTorch (To be honest, I think\n",
        "        # both BoTorch and GPyTorch were not designed well)\n",
        "        # This is a botorch.posteriors.Posterior object.\n",
        "        prior = random_model.posterior(x_values,\n",
        "                                observation_noise=self.observation_noise)\n",
        "\n",
        "        #        n_samples, n_batch, n_datapoints, n_out\n",
        "        # shape (1,         1,       n_datapoints, 1)\n",
        "        y_values = prior.sample(torch.Size([1]))\n",
        "        y_values = y_values.squeeze() # shape (n_datapoints,)\n",
        "\n",
        "        return x_values, y_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0502, 0.2043, 0.2682, 0.4175],\n",
              "         [0.2595, 0.4476, 0.9753, 0.9090],\n",
              "         [0.3216, 0.9895, 0.0275, 0.6854],\n",
              "         [0.2925, 0.5978, 0.6946, 0.4047],\n",
              "         [0.0677, 0.4458, 0.4330, 0.7364],\n",
              "         [0.0247, 0.4647, 0.0088, 0.7085],\n",
              "         [0.3631, 0.7085, 0.1066, 0.6757],\n",
              "         [0.9992, 0.8855, 0.3953, 0.6791],\n",
              "         [0.6873, 0.4191, 0.7254, 0.9278],\n",
              "         [0.6426, 0.6090, 0.1075, 0.6560],\n",
              "         [0.1030, 0.1263, 0.2853, 0.5611],\n",
              "         [0.5030, 0.8255, 0.5013, 0.0890],\n",
              "         [0.8301, 0.7563, 0.1136, 0.7293],\n",
              "         [0.5443, 0.8416, 0.1191, 0.1747],\n",
              "         [0.5138, 0.0511, 0.3795, 0.3961],\n",
              "         [0.3495, 0.5621, 0.9127, 0.3534],\n",
              "         [0.4982, 0.4669, 0.2925, 0.1053],\n",
              "         [0.9870, 0.9217, 0.1165, 0.3036],\n",
              "         [0.5972, 0.7843, 0.1710, 0.5932],\n",
              "         [0.6746, 0.5347, 0.1628, 0.3182]]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dimension = 4\n",
        "m = Uniform(torch.zeros(dimension), torch.ones(dimension))\n",
        "xvalue_distribution = Independent(m, 1)\n",
        "\n",
        "ss = xvalue_distribution.sample(torch.Size([20]))\n",
        "ss.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.5565e-02, 8.5571e-05, 6.4938e-03],\n",
            "        [3.5321e-01, 1.5565e-02, 2.3545e-05],\n",
            "        [9.5923e-01, 5.1374e-01, 1.7782e-09]], grad_fn=<RBFCovarianceBackward>)\n"
          ]
        }
      ],
      "source": [
        "kernel = RBFKernel()\n",
        "x1 = torch.tensor([1.0, 2.0, 3.2])\n",
        "x2 = torch.tensor([3.0, 4., -1.2])\n",
        "print(kernel(x1, x2).to_dense())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
