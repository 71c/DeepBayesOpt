parameters:
  max_history:
    value: 20
  dimension:
    value: 8
  lengthscale:
    value: 0.49
  method:
    value: gittins
  gi_loss_normalization:
    value: normal
  lamda:
    value: 1.00e-02
  train_samples_size:
    value: 10000
  layer_width:
    value: 300
  epochs:
    value: 10000
  learning_rate:
    value: 1.00e-02
  batch_size:
    value: 512
  lr_scheduler:
    value: ReduceLROnPlateau
  lr_scheduler_patience:
    values: [25, 150, 900]
  lr_scheduler_factor:
    values: [0.1, 0.3, 0.9]
  early_stopping:
    value: true
  patience:
    value: 3000
