parameters:
  max_history:
    value: 20
  method:
    values: ['gittins', 'mse_ei']
  gi_loss_normalization:
    value: normal
  lamda:
    value: 1.e-2
  train_samples_size:
    value: 100000
  layer_width:
    value: 512
  dimension:
    value: 16
  patience:
    value: 30
  epochs:
    value: 1000
  learning_rate:
    value: 3.e-5
