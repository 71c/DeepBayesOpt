parameters:
  max_history:
    value: 20
  dimension:
    value: 1
  lengthscale:
    value: 0.05
  method:
    value: gittins
  gi_loss_normalization:
    value: normal
  lamda:
    value: 1.00e-02
  train_samples_size:
    value: 10000
  layer_width:
    value: 300
  epochs:
    value: 5000
  learning_rate:
    value: 3.00e-04
  batch_size:
    value: 512
  lr_scheduler:
    values: [null] # [null, 'ReduceLROnPlateau']
  lr_scheduler_patience:
    value: 200
  lr_scheduler_factor:
    value: 0.5
  early_stopping:
    value: true
  patience:
    value: 1500
