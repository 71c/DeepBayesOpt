{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset, LazyMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "FunctionSamplesItem(tensor([[0.8516, 0.2163],\n",
            "        [0.5338, 0.5516],\n",
            "        [0.1333, 0.9557]]), tensor([[0.5394],\n",
            "        [1.2450],\n",
            "        [3.9864]]), SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "\n",
            "-----Transforming outcomes with Exp------\n",
            "FunctionSamplesItem(tensor([[0.8516, 0.2163],\n",
            "        [0.5338, 0.5516],\n",
            "        [0.1333, 0.9557]]), tensor([[ 1.7150],\n",
            "        [ 3.4729],\n",
            "        [53.8614]]), SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            "  (outcome_transform): Log()\n",
            "))\n",
            "\n",
            "-----Standardizing outcomes------\n",
            "Unstandardize(\n",
            "  (_original_transform): Standardize()\n",
            ")\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from botorch.models.transforms.outcome import Power\n",
        "from utils import Exp\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    n_datapoints=3, observation_noise=False,\n",
        "    dimension=2, randomize_params=True)\n",
        "# u = next(dataset)\n",
        "# a = u.model\n",
        "# v = next(dataset)\n",
        "# b = v.model\n",
        "\n",
        "q = dataset.fix_samples(1, lazy=False)\n",
        "print(q[0]._model is dataset.model_sampler._models[0])\n",
        "print(q.model_sampler is dataset.model_sampler)\n",
        "print(q.model_sampler._models is dataset.model_sampler._models)\n",
        "print(q.model_sampler._models[0] is dataset.model_sampler._models[0])\n",
        "# print(q[0]._model)\n",
        "# print(dataset.model_sampler._models[0])\n",
        "\n",
        "# print(list(dataset.model_sampler._models[0].named_parameters()))\n",
        "for w in q:\n",
        "    print(w)\n",
        "\n",
        "print(\"\\n-----Transforming outcomes with Exp------\")\n",
        "q = q.transform_outcomes(Exp())\n",
        "\n",
        "for w in q:\n",
        "    print(w)\n",
        "\n",
        "print(\"\\n-----Standardizing outcomes------\")\n",
        "q = q.standardize_outcomes()\n",
        "\n",
        "for w in q:\n",
        "    print(w.model_params['outcome_transform'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "cannot delete function call (1259788926.py, line 12)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    del getattr(inferred_noise_model, \"outcome_transform\")\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot delete function call\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "\n",
        "\n",
        "train_X = torch.rand(20, 2, dtype=torch.float64)\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
        "outcome_transform = Standardize(m=1)\n",
        "inferred_noise_model = SingleTaskGP(\n",
        "     train_X, train_Y, outcome_transform=outcome_transform,\n",
        " )\n",
        "# list(inferred_noise_model.named_parameters())\n",
        "del getattr(inferred_noise_model, \"outcome_transform\")\n",
        "inferred_noise_model.outcome_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([ 0.3948, -1.7935, -0.8180,  0.3494, -0.2001,  0.1001, -0.2954,  0.4537,\n",
            "         2.0997, -0.2908], dtype=torch.float64)\n",
            "Calling model on some data\n",
            "model.training=False\n",
            "model._has_transformed_inputs=True\n",
            "model.train_inputs=(tensor([[0.7102, 0.1549],\n",
            "        [0.7035, 1.0000],\n",
            "        [1.0000, 0.3079],\n",
            "        [0.7362, 0.0025],\n",
            "        [0.2533, 0.9342],\n",
            "        [0.8057, 0.0000],\n",
            "        [0.3650, 0.8843],\n",
            "        [0.7010, 0.1131],\n",
            "        [0.0000, 0.2348],\n",
            "        [0.5883, 0.6833]], dtype=torch.float64),)\n",
            "Conditioning model on observations\n",
            "conditioned_model.training=False\n",
            "conditioned_model._has_transformed_inputs=True\n",
            "conditioned_model.train_inputs=[tensor([[ 7.1019e-01,  1.5492e-01],\n",
            "        [ 7.0347e-01,  1.0000e+00],\n",
            "        [ 1.0000e+00,  3.0792e-01],\n",
            "        [ 7.3619e-01,  2.4605e-03],\n",
            "        [ 2.5326e-01,  9.3416e-01],\n",
            "        [ 8.0567e-01,  0.0000e+00],\n",
            "        [ 3.6505e-01,  8.8430e-01],\n",
            "        [ 7.0097e-01,  1.1313e-01],\n",
            "        [ 0.0000e+00,  2.3482e-01],\n",
            "        [ 5.8832e-01,  6.8334e-01],\n",
            "        [-3.1587e+00, -4.6962e+00],\n",
            "        [-3.8841e+00, -2.6259e+00],\n",
            "        [-4.0152e+00, -2.8635e+00],\n",
            "        [-3.0429e+00, -4.7722e+00],\n",
            "        [-3.7615e+00, -3.8339e+00],\n",
            "        [-4.8684e+00, -3.8188e+00]], dtype=torch.float64)]\n",
            "conditioned_model.train_targets=tensor([ 0.3948, -1.7935, -0.8180,  0.3494, -0.2001,  0.1001, -0.2954,  0.4537,\n",
            "         2.0997, -0.2908,  0.0784, -1.8108, -1.1104, -0.1874,  0.5365,  1.4317],\n",
            "       dtype=torch.float64)\n",
            "conditioned_model._original_train_inputs=tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64)\n",
            "Putting conditioned_model into train mode\n",
            "conditioned_model.train_inputs=(tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64),)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Calling model on some data\")\n",
        "test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "posterior = model.posterior(test_X, observation_noise=False)\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "\n",
        "print(\"Conditioning model on observations\")\n",
        "new_X = torch.rand(6, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "new_Y = torch.sin(new_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "conditioned_model = model.condition_on_observations(new_X, new_Y)\n",
        "\n",
        "print(f\"{conditioned_model.training=}\")\n",
        "print(f\"{conditioned_model._has_transformed_inputs=}\")\n",
        "print(f\"{conditioned_model.train_inputs=}\")\n",
        "print(f\"{conditioned_model.train_targets=}\")\n",
        "print(f\"{conditioned_model._original_train_inputs=}\")\n",
        "\n",
        "print(\"Putting conditioned_model into train mode\")\n",
        "conditioned_model.train()\n",
        "print(f\"{conditioned_model.train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([-0.5637,  1.2837, -1.0384,  1.2481,  0.6752,  0.7921,  0.0285, -1.7573,\n",
            "        -0.2946, -0.3735], dtype=torch.float64)\n",
            "Conditioning model with fantasize\n",
            "conditioned_model.training=False\n",
            "conditioned_model._has_transformed_inputs=True\n",
            "conditioned_model.train_inputs=[tensor([[0.8044, 0.7015],\n",
            "        [0.0000, 0.5023],\n",
            "        [0.6317, 0.9911],\n",
            "        [0.6101, 0.0509],\n",
            "        [0.8198, 0.0000],\n",
            "        [0.5076, 0.5067],\n",
            "        [0.9905, 0.2678],\n",
            "        [1.0000, 0.8923],\n",
            "        [0.1314, 1.0000],\n",
            "        [0.5693, 0.8297],\n",
            "        [0.8321, 0.0569],\n",
            "        [0.9675, 0.3989],\n",
            "        [0.6555, 0.0056],\n",
            "        [0.3748, 0.1025]], dtype=torch.float64)]\n",
            "conditioned_model.train_targets=tensor([-0.5637,  1.2837, -1.0384,  1.2481,  0.6752,  0.7921,  0.0285, -1.7573,\n",
            "        -0.2946, -0.3735,  1.3920,  2.8240,  2.2946,  0.6888],\n",
            "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "conditioned_model._original_train_inputs=tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64)\n",
            "Putting conditioned_model into train mode\n",
            "conditioned_model.train_inputs=(tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64),)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Conditioning model with fantasize\")\n",
        "test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "sampler = SobolQMCNormalSampler(sample_shape=torch.Size([]))\n",
        "conditioned_model = model.fantasize(test_X, sampler)\n",
        "\n",
        "print(f\"{conditioned_model.training=}\")\n",
        "print(f\"{conditioned_model._has_transformed_inputs=}\")\n",
        "print(f\"{conditioned_model.train_inputs=}\")\n",
        "print(f\"{conditioned_model.train_targets=}\")\n",
        "print(f\"{conditioned_model._original_train_inputs=}\")\n",
        "\n",
        "print(\"Putting conditioned_model into train mode\")\n",
        "conditioned_model.train()\n",
        "print(f\"{conditioned_model.train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 7.9117],\n",
            "        [ 9.2967],\n",
            "        [ 7.0802],\n",
            "        [ 8.7771],\n",
            "        [12.3827],\n",
            "        [ 7.3197],\n",
            "        [11.9977],\n",
            "        [ 8.3104],\n",
            "        [10.1119],\n",
            "        [10.9766]], dtype=torch.float64)\n",
            "None\n",
            "model.input_transform.training=True\n",
            "model.outcome_transform.training=True\n",
            "model.outcome_transform._is_trained=tensor(True)\n",
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-2.8159, -4.1093],\n",
            "        [-3.6376, -3.6202],\n",
            "        [-3.0420, -3.4919],\n",
            "        [-4.8481, -2.9231],\n",
            "        [-4.3684, -4.4265],\n",
            "        [-3.3781, -3.2260],\n",
            "        [-4.0482, -4.8298],\n",
            "        [-4.2994, -2.8498],\n",
            "        [-3.6454, -3.9289],\n",
            "        [-3.8356, -4.1062]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([-0.7962, -0.0634, -1.2362, -0.3383,  1.5695, -1.1095,  1.3658, -0.5853,\n",
            "         0.3680,  0.8256], dtype=torch.float64)\n",
            "model.outcome_transform.means=tensor([[9.4165]], dtype=torch.float64)\n",
            "model.outcome_transform.stdvs=tensor([[1.8899]], dtype=torch.float64)\n",
            "Setting the train data\n",
            "model.outcome_transform.means=tensor([[9.4165]], dtype=torch.float64)\n",
            "model.outcome_transform.stdvs=tensor([[1.8899]], dtype=torch.float64)\n",
            "model.outcome_transform.training=True\n",
            "model.outcome_transform._is_trained=tensor(True)\n",
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-3.6494, -3.9058],\n",
            "        [-3.3544, -2.9186],\n",
            "        [-4.6076, -3.4505],\n",
            "        [-4.2176, -4.6105],\n",
            "        [-3.9023, -4.4430],\n",
            "        [-4.1271, -3.7834]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([ 0.3460, -1.6658,  0.5497,  1.5256,  1.1505,  0.7760],\n",
            "       dtype=torch.float64)\n",
            "Putting in eval mode\n",
            "model.training=False\n",
            "model._has_transformed_inputs=True\n",
            "model.train_inputs=(tensor([[0.5898, 0.4667],\n",
            "        [0.7350, 0.9652],\n",
            "        [0.1184, 0.6966],\n",
            "        [0.3102, 0.1107],\n",
            "        [0.4654, 0.1953],\n",
            "        [0.3548, 0.5285]], dtype=torch.float64),)\n",
            "model._original_train_inputs=tensor([[-3.6494, -3.9058],\n",
            "        [-3.3544, -2.9186],\n",
            "        [-4.6076, -3.4505],\n",
            "        [-4.2176, -4.6105],\n",
            "        [-3.9023, -4.4430],\n",
            "        [-4.1271, -3.7834]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from utils import *\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "print(train_Y)\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "print(model._original_train_inputs)\n",
        "# model.eval()\n",
        "print(f\"{model.input_transform.training=}\")\n",
        "print(f\"{model.outcome_transform.training=}\")\n",
        "print(f\"{model.outcome_transform._is_trained=}\")\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "# print(\"Calling model on some data\")\n",
        "# test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "# posterior = model.posterior(test_X, observation_noise=False)\n",
        "# print(f\"{model.input_transform.training=}\")\n",
        "# print(f\"{model.outcome_transform.training=}\")\n",
        "# print(f\"{model.training=}\")\n",
        "# print(f\"{model._has_transformed_inputs=}\")\n",
        "# print(f\"{model.train_inputs=}\")\n",
        "\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(f\"{model.outcome_transform.means=}\")\n",
        "    print(f\"{model.outcome_transform.stdvs=}\")\n",
        "\n",
        "print(\"Setting the train data\")\n",
        "# model.train()\n",
        "new_X = torch.rand(6, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "new_Y = torch.sin(new_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model.set_train_data_with_transforms(new_X, new_Y, strict=False)\n",
        "\n",
        "\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(f\"{model.outcome_transform.means=}\")\n",
        "    print(f\"{model.outcome_transform.stdvs=}\")\n",
        "    print(f\"{model.outcome_transform.training=}\")\n",
        "    print(f\"{model.outcome_transform._is_trained=}\")\n",
        "\n",
        "# model.set_train_data(new_X, new_Y, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Putting in eval mode\")\n",
        "model.eval()\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model._original_train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 4, 5, 7])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X = torch.rand(3, 1, 5, 7)\n",
        "num_outputs = 4\n",
        "train_X = train_X.unsqueeze(-3).expand(\n",
        "        train_X.shape[:-2] + torch.Size([num_outputs]) + train_X.shape[-2:]\n",
        "    ).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\", \"input_transform._coefficient\", \"input_transform._offset\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m SingleTaskGP(\n\u001b[1;32m     13\u001b[0m      train_X, train_Y,\n\u001b[1;32m     14\u001b[0m      outcome_transform\u001b[38;5;241m=\u001b[39mStandardize(m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m      input_transform\u001b[38;5;241m=\u001b[39mNormalize(d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     16\u001b[0m      train_Yvar\u001b[38;5;241m=\u001b[39mtrain_Yvar)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# model = SingleTaskGP(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#      train_X, train_Y,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#      covar_module=ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1])),\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#      train_Yvar=train_Yvar)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m LogNEI \u001b[38;5;241m=\u001b[39m \u001b[43mLogNoisyExpectedImprovement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/acquisition/analytic.py:634\u001b[0m, in \u001b[0;36mLogNoisyExpectedImprovement.__init__\u001b[0;34m(self, model, X_observed, num_fantasies, maximize, posterior_transform)\u001b[0m\n\u001b[1;32m    632\u001b[0m batch_X_observed \u001b[38;5;241m=\u001b[39m X_observed\u001b[38;5;241m.\u001b[39mexpand(num_fantasies, \u001b[38;5;241m*\u001b[39mX_observed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# The fantasy model will operate in batch mode\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m fantasy_model \u001b[38;5;241m=\u001b[39m \u001b[43m_get_noiseless_fantasy_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_X_observed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_X_observed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_fantasized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_fantasized\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mfantasy_model, posterior_transform\u001b[38;5;241m=\u001b[39mposterior_transform)\n\u001b[1;32m    638\u001b[0m best_f, _ \u001b[38;5;241m=\u001b[39m Y_fantasized\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m Y_fantasized\u001b[38;5;241m.\u001b[39mmin(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/acquisition/analytic.py:1088\u001b[0m, in \u001b[0;36m_get_noiseless_fantasy_model\u001b[0;34m(model, batch_X_observed, Y_fantasized)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# load hyperparameters from original model\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m deepcopy(model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m-> 1088\u001b[0m \u001b[43mfantasy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fantasy_model\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\", \"input_transform._coefficient\", \"input_transform._offset\". "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.acquisition.analytic import LogNoisyExpectedImprovement\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
        "train_Yvar = torch.full_like(train_Y, 1e-3)\n",
        "\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2),\n",
        "     train_Yvar=train_Yvar)\n",
        "\n",
        "# model = SingleTaskGP(\n",
        "#      train_X, train_Y,\n",
        "#      covar_module=ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1])),\n",
        "#      train_Yvar=train_Yvar)\n",
        "\n",
        "\n",
        "LogNEI = LogNoisyExpectedImprovement(model, train_X)\n",
        "\n",
        "\n",
        "# print(model.state_dict())\n",
        "# print(f\"{model.training=}\")\n",
        "# print(f\"{model._has_transformed_inputs=}\")\n",
        "# print(f\"{model.train_inputs=}\")\n",
        "\n",
        "# print(LogNEI.model)\n",
        "# nei = LogNEI(test_X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "ename": "BotorchTensorDimensionError",
          "evalue": "An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBotorchTensorDimensionError\u001b[0m               Traceback (most recent call last)",
            "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.3\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4.9\u001b[39m\n\u001b[1;32m      2\u001b[0m train_Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(train_X)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTaskGP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/models/gp_regression.py:161\u001b[0m, in \u001b[0;36mSingleTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, train_Yvar, likelihood, covar_module, mean_module, outcome_transform, input_transform)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outcome_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     train_Y, train_Yvar \u001b[38;5;241m=\u001b[39m outcome_transform(train_Y, train_Yvar)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tensor_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformed_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Yvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ignore_X_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ignore_X_dims_scaling_check\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m validate_input_scaling(\n\u001b[1;32m    164\u001b[0m     train_X\u001b[38;5;241m=\u001b[39mtransformed_X,\n\u001b[1;32m    165\u001b[0m     train_Y\u001b[38;5;241m=\u001b[39mtrain_Y,\n\u001b[1;32m    166\u001b[0m     train_Yvar\u001b[38;5;241m=\u001b[39mtrain_Yvar,\n\u001b[1;32m    167\u001b[0m     ignore_X_dims\u001b[38;5;241m=\u001b[39mignore_X_dims,\n\u001b[1;32m    168\u001b[0m )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/models/gpytorch.py:99\u001b[0m, in \u001b[0;36mGPyTorchModel._validate_tensor_args\u001b[0;34m(X, Y, Yvar, strict)\u001b[0m\n\u001b[1;32m     93\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected X and Y to have the same number of dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got X with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y with dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BotorchTensorDimensionError(message)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-strict enforcement of botorch tensor conventions. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing error would have been raised with strict enforcement: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    107\u001b[0m     )\n",
            "\u001b[0;31mBotorchTensorDimensionError\u001b[0m: An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1)."
          ]
        }
      ],
      "source": [
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=False)\n",
        "\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 5)\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "class MyClass:\n",
        "    @staticmethod\n",
        "    def test(bla, bd):\n",
        "        return bla, bd\n",
        "\n",
        "# Create the partial function using the static method from the class\n",
        "partial_test = partial(MyClass.test, 3)\n",
        "\n",
        "# Call the partial function\n",
        "result = partial_test(bd=5)\n",
        "print(result)  # Output: (3, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2828]], grad_fn=<SoftplusBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.1478,  5.0348])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from random_gp_function import RandomGPFunction\n",
        "\n",
        "model = GaussianProcessRandomDataset(\n",
        "    n_datapoints=1, observation_noise=False,\n",
        "    dimension=1, randomize_params=True)._model_sampler.sample()\n",
        "print(model.covar_module.base_kernel.lengthscale)\n",
        "f = RandomGPFunction(model, observation_noise=False)\n",
        "f(torch.tensor([[1.3], [0.1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                lazy_dataset[0].y_values: tensor([-0.9738, -8.1376, -5.5296,  1.1879, -3.6971, -3.0373,  0.1646])\n",
            "            lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Made transformed dataset\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[0].y_values: tensor([9.4822e-01, 6.6221e+01, 3.0576e+01, 1.4112e+00, 1.3668e+01, 9.2250e+00,\n",
            "        2.7100e-02])\n",
            "                lazy_dataset[2].y_values: tensor([-3.5430, 16.7996, -4.0666, -9.9256, -6.6908,  6.6380,  2.7995])\n",
            "            lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[2].y_values: tensor([ 12.5526, 282.2257,  16.5370,  98.5173,  44.7665,  44.0632,   7.8373])\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[-1].y_values: tensor([ 28.5056,  35.2907,   0.7458,  28.3431,   0.3593, 157.7786,   6.0825])\n",
            "            lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "            lazy_dataset.data_is_loaded(): False\n",
            "transformed_lazy_dataset.data_is_loaded(): False\n",
            "Evaluating all items\n",
            "            lazy_dataset evaluated items: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "            lazy_dataset.data_is_loaded(): True\n",
            "transformed_lazy_dataset.data_is_loaded(): True\n",
            "transformed_gp_dataset: OutcomeTransformedFunctionSamplesIterableDataset(\n",
            "  GaussianProcessRandomDataset(\n",
            "    n_datapoints=7,\n",
            "    n_datapoints_random_gen=None,\n",
            "    observation_noise=False,\n",
            "    xvalue_distribution=Independent(Uniform(low: torch.Size([3]), high: torch.Size([3])), 1),\n",
            "    models=[SingleTaskGP(\n",
            "      (likelihood): GaussianLikelihood(\n",
            "        (noise_covar): HomoskedasticNoise(\n",
            "          (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "        )\n",
            "      )\n",
            "      (mean_module): ConstantMean()\n",
            "      (covar_module): ScaleKernel(\n",
            "        (base_kernel): MaternKernel(\n",
            "          (lengthscale_prior): GammaPrior()\n",
            "          (raw_lengthscale_constraint): Positive()\n",
            "        )\n",
            "        (outputscale_prior): GammaPrior()\n",
            "        (raw_outputscale_constraint): Positive()\n",
            "      )\n",
            "    )],\n",
            "    model_probabilities=tensor([1.]),\n",
            "    set_random_model_train_data=False,\n",
            "    dataset_size=15,\n",
            "    randomize_params=True\n",
            "  ),\n",
            "  Power()\n",
            ")\n",
            "FunctionSamplesItem(tensor([[0.1263, 0.6740, 0.2122],\n",
            "        [0.6192, 0.5454, 0.2939],\n",
            "        [0.4166, 0.7264, 0.6728],\n",
            "        [0.5016, 0.1548, 0.7987],\n",
            "        [0.6692, 0.6335, 0.4488],\n",
            "        [0.6474, 0.1837, 0.2562],\n",
            "        [0.1997, 0.2802, 0.8447]]), tensor([43.2417,  0.9727, 30.0391,  1.8355, 37.7149,  9.9940, 19.0214]))\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset\n",
        "from botorch.models.transforms.outcome import Power\n",
        "\n",
        "gp_dataset = GaussianProcessRandomDataset(\n",
        "    dataset_size=15,\n",
        "    n_datapoints=7, observation_noise=False, dimension=3, randomize_params=True)\n",
        "lazy_dataset = gp_dataset.fix_samples(lazy=True)\n",
        "print(\"                lazy_dataset[0].y_values:\", lazy_dataset[0].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "\n",
        "square_transform = Power(2)\n",
        "transformed_lazy_dataset = lazy_dataset.transform_outcomes(square_transform)\n",
        "print(\"Made transformed dataset\")\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "print(\"    transformed_lazy_dataset[0].y_values:\", transformed_lazy_dataset[0].y_values)\n",
        "\n",
        "print(\"                lazy_dataset[2].y_values:\", lazy_dataset[2].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "print(\"    transformed_lazy_dataset[2].y_values:\", transformed_lazy_dataset[2].y_values)\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "\n",
        "print(\"    transformed_lazy_dataset[-1].y_values:\", transformed_lazy_dataset[-1].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "print(\"            lazy_dataset.data_is_loaded():\", lazy_dataset.data_is_loaded())\n",
        "print(\"transformed_lazy_dataset.data_is_loaded():\", transformed_lazy_dataset.data_is_loaded())\n",
        "\n",
        "\n",
        "print(\"Evaluating all items\")\n",
        "for i in range(len(lazy_dataset)):\n",
        "    lazy_dataset[i]\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "print(\"            lazy_dataset.data_is_loaded():\", lazy_dataset.data_is_loaded())\n",
        "print(\"transformed_lazy_dataset.data_is_loaded():\", transformed_lazy_dataset.data_is_loaded())\n",
        "\n",
        "transformed_gp_dataset = gp_dataset.transform_outcomes(square_transform)\n",
        "print(\"transformed_gp_dataset:\", transformed_gp_dataset)\n",
        "print(next(iter(transformed_gp_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.0432,  3.3867,  0.5625,  0.4680])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.rand(4, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1, 2, [999, 3]], [1, 2, [999, 3]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l=[1,2,[2,3]]\n",
        "v = l.copy()\n",
        "v[2][0] = 999\n",
        "l, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# f.model._clear_cache()\n",
        "print(f.model.prediction_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 2])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.model.train_inputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8689, 0.0254, 0.7824],\n",
              "        [0.6075, 0.9092, 0.8809],\n",
              "        [0.5809, 0.7194, 0.0127],\n",
              "        [0.3432, 0.9606, 0.5279],\n",
              "        [0.9266, 0.4266, 0.9935]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand(5, 3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[ 1.3000,  4.2000],\n",
              "         [ 0.1000, -0.1000],\n",
              "         [ 0.0000,  3.2000]])]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.model.train_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "f.model._clear_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.1577)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([0.0, 0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-1.3204)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([1.0, 0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1577, -0.1577])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, 0.0], [0.0, 0.0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0529])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, -0.1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0529, -0.1577,  0.0159, -0.1577, -0.6754])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, -0.1],\n",
        "                [0.0, 0.0],\n",
        "                [8.3, 9.1],\n",
        "                [0.0, 0.0],\n",
        "                [-20.0, 50.3]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[1.4000, 8.9000],\n",
            "        [8.2000, 3.1000],\n",
            "        [2.4000, 1.1000]]), [[0, 2], [1], [3]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "def get_unique(x):\n",
        "    unique_indices_list = []\n",
        "    for input_index in range(x.size(0)):\n",
        "        input_point = x[input_index]\n",
        "        \n",
        "        found_matching_point = False\n",
        "        for unique_point_index, original_indices in enumerate(unique_indices_list):\n",
        "            unique_point = x[original_indices[0]]\n",
        "            if torch.equal(input_point, unique_point):\n",
        "                unique_indices_list[unique_point_index].append(input_index)\n",
        "                found_matching_point = True\n",
        "        \n",
        "        if not found_matching_point:\n",
        "            unique_indices_list.append([input_index])\n",
        "    \n",
        "    return x[[inds[0] for inds in unique_indices_list]], unique_indices_list\n",
        "\n",
        "u = torch.tensor([\n",
        "    [1.4, 8.9],\n",
        "    [8.2, 3.1],\n",
        "    [1.4, 8.9],\n",
        "    [2.4, 1.1]\n",
        "])\n",
        "print(get_unique(u))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function mygen at 0x7fd5c1b0b430>\n",
            "<generator object mygen at 0x7fd5c1b64430>\n",
            "<generator object mygen at 0x7fd5c1b64430>\n"
          ]
        }
      ],
      "source": [
        "def mygen():\n",
        "    while True:\n",
        "        yield 1\n",
        "\n",
        "print(mygen)\n",
        "print(mygen())\n",
        "print(iter(mygen()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(False), False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from botorch.models.transforms.outcome import Standardize\n",
        "s = Standardize(1)\n",
        "s.eval()\n",
        "s._is_trained, s.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([10.,  2.,  3.], requires_grad=True), tensor([10.,  2.,  3.]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x.detach()\n",
        "y[0] = 10.\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "float"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "type(x.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.to(None) is x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = (torch.tensor([1.2, 3.4]), torch.tensor(9.))\n",
        "b = tuple(x for x in a)\n",
        "a == b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "{'items_list': [1, 2, 3], 'model_index': 0, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}}\n",
            "TESTING_______\n",
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "TupleWithModel(4, 5, 6)\n",
            "All tests passed!\n",
            "MORE TESTING_______\n",
            "4 2\n",
            "{'x_hist': 1, 'y_hist': 2, 'x_cand': 3, 'vals_cand': 4, 'model_index': 2, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}, 'give_improvements': 2} <class 'dict'>\n",
            "AcquisitionDatasetModelItem(1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "), give_improvements=2)\n",
            "ERROR! (as expected): AcquisitionDatasetModelItem.__init__: model should be a SingleTaskGP or ModelsWithParamsList instance.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3577]), std = tensor([0.7010])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n",
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.4534]), std = tensor([0.8826])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from gpytorch.kernels import RBFKernel\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "\n",
        "from dataset_with_models import RandomModelSampler, TupleWithModel\n",
        "\n",
        "# Create a dummy SingleTaskGP model\n",
        "class DummyGP(SingleTaskGP):\n",
        "    def __init__(self, train_X, train_Y):\n",
        "        super().__init__(train_X, train_Y)\n",
        "        self.mean_module = ConstantMean()\n",
        "        self.covar_module = RBFKernel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# Create dummy data\n",
        "train_X = torch.rand(10, 1)\n",
        "train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "# Initialize dummy models\n",
        "model1 = DummyGP(train_X, train_Y)\n",
        "model2 = DummyGP(train_X, train_Y)\n",
        "model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "\n",
        "# Initialize RandomModelSampler\n",
        "sampler = RandomModelSampler(models)\n",
        "\n",
        "# Example usage of TupleWithModel\n",
        "tuple_with_model = TupleWithModel(1, 2, 3, model=model1)\n",
        "\n",
        "print(tuple_with_model)\n",
        "print(tuple_with_model.to_dict())\n",
        "\n",
        "\n",
        "def test_tuple_with_model():\n",
        "    # Create dummy data\n",
        "    train_X = torch.rand(10, 1)\n",
        "    train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "    # Initialize dummy models\n",
        "    model1 = DummyGP(train_X, train_Y)\n",
        "    model2 = DummyGP(train_X, train_Y)\n",
        "    model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "    models = [model1, model2, model3]\n",
        "    sampler = RandomModelSampler(models)\n",
        "\n",
        "    # Initialize TupleWithModel instances\n",
        "    twm1 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    twm2 = TupleWithModel(1, 2, 3, model=model2)\n",
        "    twm3 = TupleWithModel(4, 5, 6)\n",
        "\n",
        "    assert TupleWithModel(*twm1._tuple) == twm1\n",
        "\n",
        "    # Test __len__\n",
        "    assert len(twm1) == 4\n",
        "    assert len(twm3) == 3\n",
        "\n",
        "    # Test __getitem__\n",
        "    assert twm1[0] == 1\n",
        "    assert twm1[1] == 2\n",
        "    assert twm1[2] == 3\n",
        "    assert twm1[3] == model1\n",
        "\n",
        "    # Test __repr__\n",
        "    print(twm1)\n",
        "    print(twm3)\n",
        "\n",
        "    # Test __eq__\n",
        "    twm4 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    assert twm1 == twm4\n",
        "    assert twm1 != twm2\n",
        "    assert twm1 != twm3\n",
        "\n",
        "    # Test to_dict and from_dict\n",
        "    twm_dict = twm1.to_dict()\n",
        "    twm_reconstructed = TupleWithModel.from_dict(twm_dict, model_sampler=sampler)\n",
        "    assert twm1 == twm_reconstructed\n",
        "\n",
        "    # Test initialization with kwargs\n",
        "    twm5 = TupleWithModel(a=1, b=2, c=3)\n",
        "    assert twm5.tuple_no_model == tuple()\n",
        "    assert twm5._kwargs == {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "    twm6 = TupleWithModel(4, 1, ba=3, s=\"df\")\n",
        "    assert twm6.tuple_no_model == (4, 1)\n",
        "    assert twm6._kwargs == {'ba': 3, 's': \"df\"}\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "print(\"TESTING_______\")\n",
        "test_tuple_with_model()\n",
        "\n",
        "from acquisition_dataset import AcquisitionDatasetModelItem\n",
        "\n",
        "print(\"MORE TESTING_______\")\n",
        "\n",
        "x = AcquisitionDatasetModelItem(1, 2, 3, 4, give_improvements=2, model=model3)\n",
        "print(x.vals_cand, x.give_improvements)\n",
        "d = x.to_dict()\n",
        "print(d, type(d))\n",
        "y = AcquisitionDatasetModelItem.from_dict(d, model_sampler=sampler)\n",
        "print(y)\n",
        "\n",
        "v = AcquisitionDatasetModelItem(*y._tuple, **y._kwargs)\n",
        "assert v == y\n",
        "\n",
        "w = AcquisitionDatasetModelItem(*v._tuple + (v.model_params,), **v._kwargs)\n",
        "assert w == y\n",
        "\n",
        "x = AcquisitionDatasetModelItem(*v._tuple, model_params=v.model_params, **v._kwargs)\n",
        "assert x == y\n",
        "\n",
        "try:\n",
        "    q = AcquisitionDatasetModelItem(*v._tuple[:-1] + (v.model_params, v.model), **v._kwargs)\n",
        "    assert False\n",
        "except ValueError as e:\n",
        "    print(\"ERROR! (as expected):\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x_hist': 777,\n",
              " 'y_hist': 2,\n",
              " 'x_cand': -19,\n",
              " 'vals_cand': 4,\n",
              " 'model_index': 2,\n",
              " 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]),\n",
              "  'mean_module.raw_constant': tensor(0.),\n",
              "  'covar_module.raw_lengthscale': tensor([[0.]])},\n",
              " 'give_improvements': 78888}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = AcquisitionDatasetModelItem(1, 2, 3, 4, give_improvements=2, model=model3)\n",
        "x.x_hist = 777\n",
        "x.give_improvements = 78888\n",
        "x[2] = -19\n",
        "assert AcquisitionDatasetModelItem(*x._tuple, **x._kwargs) == x\n",
        "x.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': -100, 'b': 5, 'c': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {'a': 4, 'b': 5}\n",
        "dict(d, c=0, a=-100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000],\n",
              "        [0.5000],\n",
              "        [1.0000],\n",
              "        [1.5000],\n",
              "        [2.0000]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.linspace(0, 2, 5).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3890],\n",
              "        [0.2284],\n",
              "        [0.2776],\n",
              "        [0.0168],\n",
              "        [0.9678]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5187,  0.6291],\n",
            "        [ 0.9814, -0.4486],\n",
            "        [-0.6453,  2.0720]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ScaleKernel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# randint_gen = get_uniform_randint_generator(4, 20)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dataset = GaussianProcessRandomDataset(\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     device=device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# torch.manual_seed(1703)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m OBSERVATION_NOISE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mScaleKernel\u001b[49m(RBFKernel())\n\u001b[1;32m     11\u001b[0m kernel\u001b[38;5;241m.\u001b[39minitialize(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_kernel.lengthscale\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.2\u001b[39m)})\n\u001b[1;32m     12\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m GaussianLikelihood(\n\u001b[1;32m     13\u001b[0m     noise_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize(),\n\u001b[1;32m     14\u001b[0m     noise_constraint\u001b[38;5;241m=\u001b[39mGreaterThan(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;241m0.0\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ScaleKernel' is not defined"
          ]
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    device=device, randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "model.set_train_data(x_values, y_values, strict=False)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mLazyMapFunctionSamplesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:624\u001b[0m, in \u001b[0;36mLazyMapDatasetWithModels.__init__\u001b[0;34m(self, dataset, n_realizations)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_realizations \u001b[38;5;241m=\u001b[39m n_realizations\n\u001b[0;32m--> 624\u001b[0m items_generator, size \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_items_generator_and_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_realizations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items_generator \u001b[38;5;241m=\u001b[39m items_generator\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m size\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:329\u001b[0m, in \u001b[0;36mDatasetWithModels._get_items_generator_and_size\u001b[0;34m(self, n_samples, verbose, verbose_message)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iterable_is_finite(dataset):\n\u001b[0;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt store an infinite-sized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if n_samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not specified. Either specify n_samples or use a finite-sized dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# The dataset is finite and we want to save all of it\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     new_data_iterable \u001b[38;5;241m=\u001b[39m dataset\n",
            "\u001b[0;31mValueError\u001b[0m: Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset."
          ]
        }
      ],
      "source": [
        "# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "# LazyMapFunctionSamplesDataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0.]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fba130f4ee0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7216, 0.5588, 0.0163],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.8445, 0.7417, 0.1469],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.8424, 0.6213, 0.9883],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460]])\n",
            "tensor([2, 4, 0, 6, 7, 1, 3, 5])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163]])\n",
            "tensor([[0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.4122, -9.7531, -9.2286, -9.5989, -9.1321, -9.4680, -9.3031, -9.7429,\n",
              "        -9.3805, -9.6507, -9.0406, -9.3168, -9.1272, -9.9820, -9.1291, -9.4314,\n",
              "        -9.7203, -9.4293, -9.0302, -9.4230])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.]),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.]], requires_grad=True)}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.),\n",
              " 'covar_module.raw_outputscale': tensor(0.),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.]])}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 237.86it/s]\n"
          ]
        }
      ],
      "source": [
        "fixed_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3770e-01, 5.9728e-01, 1.3027e-01, 8.7175e-01, 1.3623e-01],\n",
              "        [2.8008e-01, 5.2939e-01, 7.4921e-01, 6.7475e-01, 7.0635e-01],\n",
              "        [3.8596e-04, 1.7254e-01, 9.1312e-01, 5.6526e-01, 8.1478e-01],\n",
              "        [4.3732e-01, 4.3083e-01, 3.0867e-01, 7.7489e-01, 8.4643e-01],\n",
              "        [6.1417e-01, 7.0303e-01, 8.9406e-02, 6.5903e-01, 9.4700e-01],\n",
              "        [1.3595e-01, 2.9692e-01, 8.0865e-01, 3.6557e-01, 8.0262e-02],\n",
              "        [5.5435e-01, 2.0977e-01, 9.9751e-01, 2.5552e-01, 2.0415e-01],\n",
              "        [9.2425e-01, 4.8544e-01, 7.1970e-01, 3.0899e-01, 4.5466e-02],\n",
              "        [4.7055e-01, 6.2878e-01, 3.4137e-01, 1.5561e-01, 2.4682e-01],\n",
              "        [5.0904e-01, 5.2614e-01, 5.8093e-01, 3.4311e-02, 5.9625e-01],\n",
              "        [2.4432e-02, 3.5175e-01, 1.1442e-01, 4.1488e-01, 2.4443e-01],\n",
              "        [1.9026e-01, 5.0099e-01, 8.4974e-01, 9.3262e-01, 9.7229e-01],\n",
              "        [6.5269e-01, 1.5853e-01, 5.4473e-01, 3.1906e-01, 5.2323e-01],\n",
              "        [3.3650e-01, 5.1750e-01, 7.4551e-01, 5.5767e-01, 2.9194e-01],\n",
              "        [9.8836e-01, 4.7839e-01, 9.2729e-01, 5.5478e-02, 3.0561e-01],\n",
              "        [5.3924e-01, 5.8842e-02, 8.9266e-01, 9.7812e-01, 5.7267e-01],\n",
              "        [3.1673e-01, 2.5540e-01, 2.3361e-01, 5.1155e-01, 1.0439e-01],\n",
              "        [9.1125e-01, 9.1233e-01, 2.4270e-01, 6.6415e-01, 5.5721e-01],\n",
              "        [7.4868e-01, 8.5152e-01, 9.0714e-01, 2.8652e-01, 1.8544e-01],\n",
              "        [6.2989e-01, 1.9168e-02, 2.5467e-02, 8.0095e-01, 6.3958e-01]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = ListMapFunctionSamplesDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FunctionSamplesItem([0], [0]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([1], [1]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([2], [2]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([3], [3]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([4], [4]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([5], [5]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([6], [6]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([7], [7]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([8], [8]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([9], [9]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([10], [10]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([11], [11]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([12], [12]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([13], [13]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([14], [14]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([15], [15]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([16], [16]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([17], [17]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([18], [18]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([19], [19]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([12, 13], [33]) <class 'function_samples_dataset.FunctionSamplesItem'>\n"
          ]
        }
      ],
      "source": [
        "# test_dataset = ListMapFunctionSamplesDataset([\n",
        "#     ([i], [i]) for i in range(20)\n",
        "# ] + [([12, 13], [33], SingleTaskGP(torch.zeros(2, 1), torch.zeros(2, 1), likelihood=likelihood, covar_module=kernel))])\n",
        "\n",
        "test_dataset = ListMapFunctionSamplesDataset([\n",
        "    ([i], [i]) for i in range(20)\n",
        "] + [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = ListMapFunctionSamplesDataset(\n",
        "#     [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x, type(x))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')\n",
        " # \"Generating GP realizations:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/123 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123/123 [00:00<00:00, 291.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating and saving realizations from GaussianProcessRandomDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 94/94 [00:00<00:00, 285.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5, dataset_size=94)\n",
        "function_samples_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 123)\n",
        "function_samples_dataset = function_samples_dataset[:20]\n",
        "function_samples_dataset.save('fixed', 17)\n",
        "rand_dataset.save('random')\n",
        "loaded_dataset = ListMapFunctionSamplesDataset.load('fixed')\n",
        "print(len(loaded_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 17)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0}\n",
            "1 batches:, want 27 prints, got 1 prints\n",
            "[0]\n",
            "\n",
            "{0, 1}\n",
            "2 batches:, want 27 prints, got 2 prints\n",
            "[0 1]\n",
            "\n",
            "{0, 1, 2}\n",
            "3 batches:, want 27 prints, got 3 prints\n",
            "[0 1 2]\n",
            "\n",
            "{0, 1, 2, 3}\n",
            "4 batches:, want 27 prints, got 4 prints\n",
            "[0 1 2 3]\n",
            "\n",
            "{0, 1, 2, 3, 4}\n",
            "5 batches:, want 27 prints, got 5 prints\n",
            "[0 1 2 3 4]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5}\n",
            "6 batches:, want 27 prints, got 6 prints\n",
            "[0 1 2 3 4 5]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6}\n",
            "7 batches:, want 27 prints, got 7 prints\n",
            "[0 1 2 3 4 5 6]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "8 batches:, want 27 prints, got 8 prints\n",
            "[0 1 2 3 4 5 6 7]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "9 batches:, want 27 prints, got 9 prints\n",
            "[0 1 2 3 4 5 6 7 8]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10 batches:, want 27 prints, got 10 prints\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
            "11 batches:, want 27 prints, got 11 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
            "12 batches:, want 27 prints, got 12 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
            "13 batches:, want 27 prints, got 13 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
            "14 batches:, want 27 prints, got 14 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
            "15 batches:, want 27 prints, got 15 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
            "16 batches:, want 27 prints, got 16 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
            "17 batches:, want 27 prints, got 17 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
            "18 batches:, want 27 prints, got 18 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n",
            "19 batches:, want 27 prints, got 19 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
            "20 batches:, want 27 prints, got 20 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}\n",
            "21 batches:, want 27 prints, got 21 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21}\n",
            "22 batches:, want 27 prints, got 22 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}\n",
            "23 batches:, want 27 prints, got 23 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}\n",
            "24 batches:, want 27 prints, got 24 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24}\n",
            "25 batches:, want 27 prints, got 25 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n",
            "26 batches:, want 27 prints, got 26 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26}\n",
            "27 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n",
            "28 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28}\n",
            "29 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24 25\n",
            " 26 27 28]\n",
            "\n",
            "{0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29}\n",
            "30 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 25 26\n",
            " 27 28 29]\n",
            "\n",
            "{0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30}\n",
            "31 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  5  6  7  8  9 10 12 13 14 15 16 17 18 20 21 22 23 24 25 27\n",
            " 28 29 30]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31}\n",
            "32 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 23 24 25 26 27\n",
            " 29 30 31]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32}\n",
            "33 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  9 10 11 12 14 15 16 17 18 20 21 22 23 25 26 27 28\n",
            " 30 31 32]\n",
            "\n",
            "{0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33}\n",
            "34 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  6  8  9 10 11 13 14 15 16 18 19 20 22 23 24 25 27 28 29\n",
            " 30 32 33]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34}\n",
            "35 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 10 12 13 14 16 17 18 20 21 22 24 25 26 27 29 30\n",
            " 31 33 34]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35}\n",
            "36 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 11 12 13 15 16 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 34 35]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36}\n",
            "37 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  8 10 11 12 14 15 17 18 19 21 22 24 25 26 28 29 30 32\n",
            " 33 35 36]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 36, 37}\n",
            "38 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 11 13 14 16 17 18 20 21 23 24 26 27 28 30 31 33\n",
            " 34 36 37]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38}\n",
            "39 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 12 13 15 16 18 19 20 22 23 25 26 28 29 31 32 34\n",
            " 35 37 38]\n",
            "\n",
            "{0, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 26, 27, 28, 30, 32, 33, 34, 36, 38, 39}\n",
            "40 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  4  6  8  9 10 12 14 15 16 18 20 21 22 24 26 27 28 30 32 33 34\n",
            " 36 38 39]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40}\n",
            "41 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 12 14 15 17 18 20 22 23 25 26 28 29 31 32 34 35\n",
            " 37 38 40]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 24, 25, 27, 28, 30, 32, 33, 35, 36, 38, 39, 41}\n",
            "42 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 13 14 16 17 19 20 22 24 25 27 28 30 32 33 35 36\n",
            " 38 39 41]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 10, 11, 13, 15, 16, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 36, 37, 39, 40, 42}\n",
            "43 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8 10 11 13 15 16 18 19 21 23 24 26 27 29 31 32 34 36 37\n",
            " 39 40 42]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 13, 15, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 35, 36, 38, 40, 41, 43}\n",
            "44 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 13 15 17 18 20 22 23 25 26 28 30 31 33 35 36 38\n",
            " 40 41 43]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 14, 15, 17, 19, 20, 22, 24, 25, 27, 29, 30, 32, 34, 36, 37, 39, 41, 42, 44}\n",
            "45 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 14 15 17 19 20 22 24 25 27 29 30 32 34 36 37 39\n",
            " 41 42 44]\n",
            "\n",
            "{0, 2, 3, 5, 7, 9, 10, 12, 14, 16, 17, 19, 21, 22, 24, 26, 28, 29, 31, 33, 35, 36, 38, 40, 42, 43, 45}\n",
            "46 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  9 10 12 14 16 17 19 21 22 24 26 28 29 31 33 35 36 38 40\n",
            " 42 43 45]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 12, 14, 16, 18, 19, 21, 23, 25, 27, 28, 30, 32, 34, 35, 37, 39, 41, 42, 44, 46}\n",
            "47 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 12 14 16 18 19 21 23 25 27 28 30 32 34 35 37 39 41\n",
            " 42 44 46]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 13, 14, 16, 18, 20, 22, 24, 25, 27, 29, 31, 33, 34, 36, 38, 40, 42, 43, 45, 47}\n",
            "48 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 13 14 16 18 20 22 24 25 27 29 31 33 34 36 38 40 42\n",
            " 43 45 47]\n",
            "\n",
            "{0, 2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 28, 30, 31, 33, 35, 37, 39, 41, 42, 44, 46, 48}\n",
            "49 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  7  9 11 13 15 17 18 20 22 24 26 28 30 31 33 35 37 39 41 42\n",
            " 44 46 48]\n",
            "\n",
            "{0, 2, 4, 6, 8, 9, 11, 13, 15, 17, 19, 21, 23, 24, 26, 28, 30, 32, 34, 36, 38, 40, 41, 43, 45, 47, 49}\n",
            "50 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8  9 11 13 15 17 19 21 23 24 26 28 30 32 34 36 38 40 41 43\n",
            " 45 47 49]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 38, 40, 42, 44, 46, 48, 50}\n",
            "51 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 13 15 17 19 21 23 25 27 29 31 33 35 37 38 40 42 44\n",
            " 46 48 50]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51}\n",
            "52 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 27 29 31 33 35 37 39 41 43 45\n",
            " 47 49 51]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52}\n",
            "53 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46\n",
            " 48 50 52]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53}\n",
            "54 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 29 31 33 35 37 39 41 43 45 47\n",
            " 49 51 53]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 52, 54}\n",
            "55 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 15 17 19 21 23 25 27 29 31 33 35 37 39 42 44 46 48\n",
            " 50 52 54]\n",
            "\n",
            "{0, 2, 4, 6, 8, 11, 13, 15, 17, 19, 21, 23, 25, 28, 30, 32, 34, 36, 38, 40, 42, 44, 47, 49, 51, 53, 55}\n",
            "56 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 11 13 15 17 19 21 23 25 28 30 32 34 36 38 40 42 44 47 49\n",
            " 51 53 55]\n",
            "\n",
            "{0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 22, 24, 26, 28, 30, 32, 34, 37, 39, 41, 43, 45, 47, 50, 52, 54, 56}\n",
            "57 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  9 11 13 15 17 19 22 24 26 28 30 32 34 37 39 41 43 45 47 50\n",
            " 52 54 56]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 15, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 53, 55, 57}\n",
            "58 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 15 18 20 22 24 26 29 31 33 35 37 39 42 44 46 48 50\n",
            " 53 55 57]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 16, 18, 20, 22, 25, 27, 29, 31, 33, 36, 38, 40, 42, 45, 47, 49, 51, 54, 56, 58}\n",
            "59 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 16 18 20 22 25 27 29 31 33 36 38 40 42 45 47 49 51\n",
            " 54 56 58]\n",
            "\n",
            "{0, 2, 5, 7, 9, 11, 14, 16, 18, 20, 23, 25, 27, 30, 32, 34, 36, 39, 41, 43, 45, 48, 50, 52, 54, 57, 59}\n",
            "60 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 11 14 16 18 20 23 25 27 30 32 34 36 39 41 43 45 48 50 52\n",
            " 54 57 59]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 18, 21, 23, 25, 28, 30, 32, 35, 37, 39, 42, 44, 46, 48, 51, 53, 55, 58, 60}\n",
            "61 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 18 21 23 25 28 30 32 35 37 39 42 44 46 48 51 53\n",
            " 55 58 60]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 19, 21, 23, 26, 28, 30, 33, 35, 38, 40, 42, 45, 47, 49, 52, 54, 56, 59, 61}\n",
            "62 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 19 21 23 26 28 30 33 35 38 40 42 45 47 49 52 54\n",
            " 56 59 61]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 29, 31, 33, 36, 38, 41, 43, 45, 48, 50, 52, 55, 57, 60, 62}\n",
            "63 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 14 17 19 21 24 26 29 31 33 36 38 41 43 45 48 50 52 55\n",
            " 57 60 62]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 19, 22, 24, 27, 29, 31, 34, 36, 39, 41, 44, 46, 48, 51, 53, 56, 58, 61, 63}\n",
            "64 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 19 22 24 27 29 31 34 36 39 41 44 46 48 51 53 56\n",
            " 58 61 63]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 20, 22, 25, 27, 30, 32, 34, 37, 39, 42, 44, 47, 49, 52, 54, 57, 59, 62, 64}\n",
            "65 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 20 22 25 27 30 32 34 37 39 42 44 47 49 52 54 57\n",
            " 59 62 64]\n",
            "\n",
            "{0, 2, 5, 8, 10, 12, 15, 18, 20, 22, 25, 28, 30, 32, 35, 38, 40, 42, 45, 48, 50, 52, 55, 58, 60, 62, 65}\n",
            "66 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  8 10 12 15 18 20 22 25 28 30 32 35 38 40 42 45 48 50 52 55 58\n",
            " 60 62 65]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 20, 23, 25, 28, 30, 33, 36, 38, 41, 43, 46, 48, 51, 53, 56, 58, 61, 63, 66}\n",
            "67 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 20 23 25 28 30 33 36 38 41 43 46 48 51 53 56 58\n",
            " 61 63 66]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 21, 23, 26, 28, 31, 34, 36, 39, 41, 44, 46, 49, 52, 54, 57, 59, 62, 64, 67}\n",
            "68 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 21 23 26 28 31 34 36 39 41 44 46 49 52 54 57 59\n",
            " 62 64 67]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 16, 18, 21, 24, 26, 29, 31, 34, 37, 39, 42, 44, 47, 50, 52, 55, 58, 60, 63, 65, 68}\n",
            "69 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 16 18 21 24 26 29 31 34 37 39 42 44 47 50 52 55 58 60\n",
            " 63 65 68]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 21, 24, 27, 29, 32, 34, 37, 40, 42, 45, 48, 50, 53, 56, 58, 61, 64, 66, 69}\n",
            "70 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 21 24 27 29 32 34 37 40 42 45 48 50 53 56 58 61\n",
            " 64 66 69]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 22, 24, 27, 30, 32, 35, 38, 40, 43, 46, 48, 51, 54, 57, 59, 62, 65, 67, 70}\n",
            "71 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 22 24 27 30 32 35 38 40 43 46 48 51 54 57 59 62\n",
            " 65 67 70]\n",
            "\n",
            "{0, 3, 5, 8, 11, 14, 16, 19, 22, 25, 27, 30, 33, 36, 38, 41, 44, 46, 49, 52, 55, 57, 60, 63, 66, 68, 71}\n",
            "72 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 14 16 19 22 25 27 30 33 36 38 41 44 46 49 52 55 57 60 63\n",
            " 66 68 71]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 19, 22, 25, 28, 30, 33, 36, 39, 42, 44, 47, 50, 53, 55, 58, 61, 64, 66, 69, 72}\n",
            "73 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 19 22 25 28 30 33 36 39 42 44 47 50 53 55 58 61 64\n",
            " 66 69 72]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 20, 22, 25, 28, 31, 34, 36, 39, 42, 45, 48, 51, 53, 56, 59, 62, 65, 67, 70, 73}\n",
            "74 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 20 22 25 28 31 34 36 39 42 45 48 51 53 56 59 62 65\n",
            " 67 70 73]\n",
            "\n",
            "{0, 3, 6, 9, 11, 14, 17, 20, 23, 26, 28, 31, 34, 37, 40, 43, 46, 48, 51, 54, 57, 60, 63, 65, 68, 71, 74}\n",
            "75 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 11 14 17 20 23 26 28 31 34 37 40 43 46 48 51 54 57 60 63 65\n",
            " 68 71 74]\n",
            "\n",
            "{0, 3, 6, 9, 12, 14, 17, 20, 23, 26, 29, 32, 35, 38, 40, 43, 46, 49, 52, 55, 58, 61, 63, 66, 69, 72, 75}\n",
            "76 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 14 17 20 23 26 29 32 35 38 40 43 46 49 52 55 58 61 63 66\n",
            " 69 72 75]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56, 58, 61, 64, 67, 70, 73, 76}\n",
            "77 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 20 23 26 29 32 35 38 41 44 47 50 53 56 58 61 64 67\n",
            " 70 73 76]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 38, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 71, 74, 77}\n",
            "78 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 38 41 44 47 50 53 56 59 62 65 68\n",
            " 71 74 77]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78}\n",
            "79 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69\n",
            " 72 75 78]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 70, 73, 76, 79}\n",
            "80 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 40 43 46 49 52 55 58 61 64 67 70\n",
            " 73 76 79]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55, 58, 62, 65, 68, 71, 74, 77, 80}\n",
            "81 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 22 25 28 31 34 37 40 43 46 49 52 55 58 62 65 68 71\n",
            " 74 77 80]\n",
            "\n",
            "{0, 3, 6, 9, 12, 16, 19, 22, 25, 28, 31, 34, 37, 40, 44, 47, 50, 53, 56, 59, 62, 65, 69, 72, 75, 78, 81}\n",
            "82 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 16 19 22 25 28 31 34 37 40 44 47 50 53 56 59 62 65 69 72\n",
            " 75 78 81]\n",
            "\n",
            "{0, 3, 6, 9, 13, 16, 19, 22, 25, 28, 32, 35, 38, 41, 44, 47, 50, 54, 57, 60, 63, 66, 69, 73, 76, 79, 82}\n",
            "83 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 13 16 19 22 25 28 32 35 38 41 44 47 50 54 57 60 63 66 69 73\n",
            " 76 79 82]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 22, 26, 29, 32, 35, 38, 42, 45, 48, 51, 54, 57, 61, 64, 67, 70, 73, 77, 80, 83}\n",
            "84 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 22 26 29 32 35 38 42 45 48 51 54 57 61 64 67 70 73\n",
            " 77 80 83]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 23, 26, 29, 32, 36, 39, 42, 45, 48, 52, 55, 58, 61, 65, 68, 71, 74, 78, 81, 84}\n",
            "85 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 23 26 29 32 36 39 42 45 48 52 55 58 61 65 68 71 74\n",
            " 78 81 84]\n",
            "\n",
            "{0, 3, 7, 10, 13, 16, 20, 23, 26, 29, 33, 36, 39, 42, 46, 49, 52, 56, 59, 62, 65, 69, 72, 75, 78, 82, 85}\n",
            "86 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 16 20 23 26 29 33 36 39 42 46 49 52 56 59 62 65 69 72 75\n",
            " 78 82 85]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 26, 30, 33, 36, 40, 43, 46, 50, 53, 56, 60, 63, 66, 69, 73, 76, 79, 83, 86}\n",
            "87 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 26 30 33 36 40 43 46 50 53 56 60 63 66 69 73 76\n",
            " 79 83 86]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 27, 30, 33, 37, 40, 44, 47, 50, 54, 57, 60, 64, 67, 70, 74, 77, 80, 84, 87}\n",
            "88 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 27 30 33 37 40 44 47 50 54 57 60 64 67 70 74 77\n",
            " 80 84 87]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 20, 24, 27, 30, 34, 37, 41, 44, 47, 51, 54, 58, 61, 64, 68, 71, 74, 78, 81, 85, 88}\n",
            "89 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 20 24 27 30 34 37 41 44 47 51 54 58 61 64 68 71 74 78\n",
            " 81 85 88]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 27, 31, 34, 38, 41, 44, 48, 51, 55, 58, 62, 65, 68, 72, 75, 79, 82, 86, 89}\n",
            "90 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 27 31 34 38 41 44 48 51 55 58 62 65 68 72 75 79\n",
            " 82 86 89]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 28, 31, 35, 38, 42, 45, 48, 52, 55, 59, 62, 66, 69, 73, 76, 80, 83, 87, 90}\n",
            "91 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 28 31 35 38 42 45 48 52 55 59 62 66 69 73 76 80\n",
            " 83 87 90]\n",
            "\n",
            "{0, 4, 7, 10, 14, 18, 21, 24, 28, 32, 35, 38, 42, 46, 49, 52, 56, 60, 63, 66, 70, 74, 77, 80, 84, 88, 91}\n",
            "92 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 10 14 18 21 24 28 32 35 38 42 46 49 52 56 60 63 66 70 74 77 80\n",
            " 84 88 91]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 28, 32, 35, 39, 42, 46, 50, 53, 57, 60, 64, 67, 71, 74, 78, 81, 85, 88, 92}\n",
            "93 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 28 32 35 39 42 46 50 53 57 60 64 67 71 74 78 81\n",
            " 85 88 92]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 29, 32, 36, 39, 43, 46, 50, 54, 57, 61, 64, 68, 72, 75, 79, 82, 86, 89, 93}\n",
            "94 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 29 32 36 39 43 46 50 54 57 61 64 68 72 75 79 82\n",
            " 86 89 93]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 22, 25, 29, 33, 36, 40, 43, 47, 51, 54, 58, 61, 65, 69, 72, 76, 80, 83, 87, 90, 94}\n",
            "95 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 22 25 29 33 36 40 43 47 51 54 58 61 65 69 72 76 80 83\n",
            " 87 90 94]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 29, 33, 37, 40, 44, 48, 51, 55, 58, 62, 66, 69, 73, 77, 80, 84, 88, 91, 95}\n",
            "96 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 29 33 37 40 44 48 51 55 58 62 66 69 73 77 80 84\n",
            " 88 91 95]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 30, 33, 37, 41, 44, 48, 52, 55, 59, 63, 66, 70, 74, 78, 81, 85, 89, 92, 96}\n",
            "97 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 30 33 37 41 44 48 52 55 59 63 66 70 74 78 81 85\n",
            " 89 92 96]\n",
            "\n",
            "{0, 4, 7, 11, 15, 19, 22, 26, 30, 34, 37, 41, 45, 48, 52, 56, 60, 63, 67, 71, 75, 78, 82, 86, 90, 93, 97}\n",
            "98 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 19 22 26 30 34 37 41 45 48 52 56 60 63 67 71 75 78 82 86\n",
            " 90 93 97]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 26, 30, 34, 38, 41, 45, 49, 53, 57, 60, 64, 68, 72, 75, 79, 83, 87, 90, 94, 98}\n",
            "99 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 26 30 34 38 41 45 49 53 57 60 64 68 72 75 79 83 87\n",
            " 90 94 98]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 65, 69, 72, 76, 80, 84, 88, 91, 95, 99}\n",
            "100 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 27 30 34 38 42 46 50 53 57 61 65 69 72 76 80 84 88\n",
            " 91 95 99]\n",
            "\n",
            "Elapsed time: 0.128855 seconds\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from utils import int_linspace\n",
        "from tictoc import tic, toc\n",
        "\n",
        "n_prints = 27\n",
        "\n",
        "tic()\n",
        "for k in range(1):\n",
        "    for n_iter in range(1, 100+1):\n",
        "        # every_n = math.ceil(n_iter / n_prints)\n",
        "        # nums = [x for x in range(n_iter) if x % every_n == 0]\n",
        "        \n",
        "        nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "        print(set(nums))\n",
        "\n",
        "        actual_n_prints = len(nums)\n",
        "        \n",
        "        print(f'{n_iter} batches:, want {n_prints} prints, got {actual_n_prints} prints')\n",
        "        print(nums)\n",
        "        print()\n",
        "toc()\n",
        "\n",
        "# tic()\n",
        "# for k in range(10_000):\n",
        "#     n_iter = 6700000\n",
        "#     nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "# toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 191.19it/s]\n"
          ]
        }
      ],
      "source": [
        "function_samples_dataset_2 = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 151.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([20, 6]) torch.Size([20])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "torch.Size([40, 6]) torch.Size([40])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=20)\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 150.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dataset_with_models.MapFunctionSamplesSubset'>\n",
            "<class 'dataset_with_models.MapFunctionSamplesSubset'> 12\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.0183, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5937, -0.7234, -0.7051, -0.3100,  0.2769, -0.5216]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(24.7716, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3166,  0.5050, -0.4871, -0.4972,  0.1745,  0.8940]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.7187, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3906, -0.7809, -1.0721, -0.8058, -0.3789, -1.7219]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([16, 6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([16])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.5066, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.6178, -1.3973, -0.9966,  0.0687, -0.8019, -0.7827]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(19.7305, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3467, -3.4180, -0.4457,  0.0798,  0.7735, -2.3735]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(30.5852, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3173, -0.1330, -0.6055, -1.2983,  0.1788, -1.1704]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.1442, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.4117,  0.7357,  0.2728, -0.0876,  0.0997, -1.9339]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.1815, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.4540, -1.2818, -0.0256, -0.7721, -0.2421, -0.2774]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.8933, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5878,  0.3725, -1.0817, -0.9872, -0.2428, -0.3045]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.7568, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.0724, -0.6240,  0.2163,  1.1081, -1.6193, -0.1446]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([27, 6]) torch.Size([27])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.9243, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4186, -1.4162, -0.9122, -0.3766, -0.8241, -1.9416]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.8280, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.9496, -1.6693, -1.7773,  0.0875, -1.2961, -0.7184]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "17 14 12 12\n",
            "\n",
            "\n",
            "torch.Size([3, 17, 6]) torch.Size([3, 17]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 17]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 19, 6]) torch.Size([3, 19]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 19]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 30, 6]) torch.Size([3, 30]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 30]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 18, 6]) torch.Size([3, 18]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 18]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "dataset = dataset[:-3]\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1), len(train_subset_1))\n",
        "# train_subset_1 = train_subset_1[:4]\n",
        "# print(type(train_subset_1), len(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = ListMapFunctionSamplesDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(dataset), len(train_dataset), len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = FunctionSamplesAcquisitionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function_samples_dataset.GaussianProcessRandomDataset at 0x7fba1761b850>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient w.r.t x (Approach a): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradient w.r.t x (Approach b): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradients w.r.t x are equal: True\n",
            "Gradient w.r.t y (Approach a): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradient w.r.t y (Approach b): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradients w.r.t y are equal: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=True)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=True)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data:\n",
            " tensor([[[ 0.,  1.,  2.,  3.],\n",
            "         [ 4.,  5.,  6.,  7.],\n",
            "         [ 8.,  9., 10., 11.]],\n",
            "\n",
            "        [[12., 13., 14., 15.],\n",
            "         [16., 17., 18., 19.],\n",
            "         [20., 21., 22., 23.]]], dtype=torch.float32)\n",
            "mask: torch.bool\n",
            " tensor([[[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]],\n",
            "\n",
            "        [[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]]])\n",
            "data masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "data2 masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "stacked_masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 43.,   0.,   0.,   0.,   0.,   0.,  35.,   0.,   0.,   0.,  31.,\n",
              "          0.,   0.,  36.,   0.,  30.,   0.,  36.,   0.,  38.,  36.,  44.,\n",
              "         37.,  28.,  23.,  59.,  39.,  69.,  71.,  67.,  77., 106.,  66.,\n",
              "        106., 144., 149., 130., 136., 198., 145., 243., 230., 236., 285.,\n",
              "        289., 381., 376., 404., 513., 531., 587., 625., 717., 777., 863.,\n",
              "        964.]),\n",
              " array([0.        , 0.10185326, 0.20370652, 0.30555978, 0.40741303,\n",
              "        0.50926629, 0.61111955, 0.71297281, 0.81482607, 0.91667933,\n",
              "        1.01853258, 1.12038584, 1.2222391 , 1.32409236, 1.42594562,\n",
              "        1.52779888, 1.62965214, 1.73150539, 1.83335865, 1.93521191,\n",
              "        2.03706517, 2.13891843, 2.24077169, 2.34262494, 2.4444782 ,\n",
              "        2.54633146, 2.64818472, 2.75003798, 2.85189124, 2.9537445 ,\n",
              "        3.05559775, 3.15745101, 3.25930427, 3.36115753, 3.46301079,\n",
              "        3.56486405, 3.66671731, 3.76857056, 3.87042382, 3.97227708,\n",
              "        4.07413034, 4.1759836 , 4.27783686, 4.37969011, 4.48154337,\n",
              "        4.58339663, 4.68524989, 4.78710315, 4.88895641, 4.99080967,\n",
              "        5.09266292, 5.19451618, 5.29636944, 5.3982227 , 5.50007596,\n",
              "        5.60192922, 5.70378247]),\n",
              " <BarContainer object of 56 artists>)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([479,  61, 736, 798,  30, 101,   1, 207, 625,  55, 805,   2, 456, 702,\n",
            "        554, 463, 154,  42,  80,  63, 324, 101,  34,  31, 401,  58, 893, 635,\n",
            "        533,  19, 598, 977, 753,  74, 293,  14, 125, 583,  10, 754,  15, 326,\n",
            "          5, 111, 422,  43,  80, 139, 185, 349, 108,  42,  37, 765, 146, 121,\n",
            "          2,  57,  34,  19,  22,  36,  63, 365,  21,  13, 911,  31, 913,  36,\n",
            "         17,  14, 299,   5,   7,  52,   6,  93,  50,  28,  31,   6, 168,  39,\n",
            "         10, 405,   6, 133,  79,  24,   6,  98,  12, 202, 736,   8, 238, 179,\n",
            "         19, 130, 193,  66, 371, 167, 484, 162, 935,  11,  20, 145,  17,  99,\n",
            "          3, 177,  10, 776,  94, 524, 266, 316,  51,  45,  33,  20, 133,   2,\n",
            "        845, 219,   9,  61, 353,  28,   9,  70, 187, 409, 740, 638,  28,  18,\n",
            "        191,  35, 148, 618, 394,  70, 381,   5, 411, 394,   1,  31, 318, 237,\n",
            "         39, 284, 312,  47, 158, 105,  44,  99, 133, 908,  39, 273, 134,  18,\n",
            "          5, 716, 279, 115,  44,  46, 106,  53,  26, 646,  18, 986, 994,  61,\n",
            "        218, 963,  17, 156,  47, 605,   4,  50,  58, 244, 729,  38, 993,  74,\n",
            "         21,  22,   6, 166, 798,   2, 312, 561,  53,  80, 235, 163, 159,  39,\n",
            "        155, 180, 252,   9, 818, 388,  18,  14,  64,   9,  42,  24, 416,   4,\n",
            "        734,  60,  15, 295, 232, 578, 235, 330, 272, 209, 275,  51,   2, 573,\n",
            "         14,  42, 109,   5,  79,  23, 119, 988,  90, 426, 182,  65, 132, 235,\n",
            "         68,  26,  63, 330,  25, 296, 372, 127,  49,  12,  40, 124, 169, 224,\n",
            "        238,  16,  19, 648, 107, 516, 614,  94, 737,  35,  35, 161,  11,  68,\n",
            "        742,  16, 348,  21, 346, 699,  21,   2,   3,  35,  10, 179,  13,  30,\n",
            "        114,  60,  24, 242, 258, 119,  48, 181,  15, 104,  23, 527,   7, 443,\n",
            "         21,   6,  49,  19, 927,   9, 604, 317, 519, 128, 178, 177, 555,  61,\n",
            "        177, 561, 160,  69,  34, 396, 849,  25, 311,  35,  13, 418, 895,  46,\n",
            "         82, 688, 436, 840,  50, 280, 810,  96,   1, 647,  76,  61,  69,  34,\n",
            "        722,   5,   1, 606,  39,  66, 354, 228, 108,   1,   5,  81,  28,  15,\n",
            "        375,  13, 343, 154, 475, 975, 475,   1,  17, 271,  51, 482, 491, 782,\n",
            "        390, 448,  58, 465, 100,  59,  42, 186,  19, 192,  37, 251,  51, 493,\n",
            "         15,   2,   8, 629, 105, 257,  50, 266, 100, 283,  35, 217, 192,  14,\n",
            "         16, 213, 107, 253,  96, 212, 703,  11, 355,  40,  80,  28, 415,   3,\n",
            "         94, 165,  47,   7, 138,  32, 137,  14, 893,  16,  42, 459, 663, 147,\n",
            "         43,  10, 308, 563, 382,  65,  10,  66,   8,   5, 131,   3, 100,  82,\n",
            "        253, 943, 370,  15,  41,  10,  13,  81,  23, 658,   7, 303, 803, 108,\n",
            "        899, 904, 791, 649, 327, 208, 312,   6, 153,  66, 306, 393,  17,   6,\n",
            "         22, 105,  37, 598, 101,  10, 981,  56, 114,  12,  21,   1,  48, 133,\n",
            "        311, 695, 195, 709, 793,  19,  65, 414, 648, 382,  61,  94, 325, 591,\n",
            "         53,  22, 390, 103, 267, 150, 162, 877,  74,  30, 813,  52,  29, 268,\n",
            "        162,   4,  25, 699, 241, 133,  26,  54,  82,  76,  35,   4,  44,  16,\n",
            "        713, 203, 405, 962, 149, 776, 364, 213,  54,  20,  88,  59, 115, 341,\n",
            "        315,  98, 349,  48,  23, 199,   7, 682, 948, 490, 179,  77,  66,  97,\n",
            "        183, 234,  49,  40,  34, 137, 159, 504, 289, 664, 622,  32,  82,  13,\n",
            "        243,   4, 100, 222,   4,  97,  30,  86,  75, 271, 108,   1, 630, 850,\n",
            "        820, 681, 255,   7,  63, 104,   2, 175, 499,  16,  95, 125,   8,  83,\n",
            "         28,  47,  38, 115, 461,  90, 237,  34,   1,  58,  62,  11, 919,  66,\n",
            "        705,  29,  10,  28, 459,  45,  46, 620,   2,   1, 102,   8,   9, 378,\n",
            "        587, 453, 280, 667, 286, 235,  48,   5,  11, 151, 188, 472, 479, 879,\n",
            "        163, 213, 689,  30, 446, 901,  55, 346,  37,  57,  19,  79,   2, 157,\n",
            "          2,  70,  27, 227,  12, 533, 220,  28, 335,  66,  37,  34,  79,  62,\n",
            "         27, 249,   4, 134, 177, 383,  12,  53,  74,  86,  53,  77,  59, 941,\n",
            "         11,  19,  47, 144,  56, 219, 763, 155, 122,  18, 518,  37, 287,  89,\n",
            "          2, 579, 428,  28,  59, 150, 648,  46, 574, 477, 127,  13, 975,   3,\n",
            "          4, 617, 148, 206, 109, 989, 334, 787,  47, 297,   2, 936, 512, 110,\n",
            "        527, 197,  77, 185, 188,  33,  57, 400,  14, 492, 839, 569,   3,  16,\n",
            "         18, 696, 101,  15, 237,  40,  57,  67, 250, 111, 107, 112, 849,  58,\n",
            "         29, 368, 526, 385, 269, 795,  51,  90, 128, 338, 508,  31, 504,  76,\n",
            "          5, 969,  29, 271,  29,  17,   6,  35,  20,  13, 384,  40, 519,  72,\n",
            "        514, 564, 156, 342,   2, 120, 355, 369,  45, 246, 435, 178, 237, 312,\n",
            "          2, 354,  69,  77, 137, 933,  85,   8, 242,   8, 272, 114, 255, 355,\n",
            "        294,  35, 159,   3, 110,  35, 321,  58,   2, 290,  76, 192, 190, 137,\n",
            "        115, 167,  51, 584, 926,  10, 843, 111, 929, 197,  53, 268,  22, 108,\n",
            "        940, 189, 208,  33,  25,  18, 200, 334, 811, 638, 931,  34,  19, 931,\n",
            "        216,   4, 837,   8, 135, 998,  56,  27, 743,  85,   4, 213,   9, 526,\n",
            "         21, 563, 291,   4,  29, 691, 668,   1, 915, 129,  45,  11, 131,  34,\n",
            "        170,  15, 112,  58,  66,   1,  10,  24, 260,  12, 295, 299,  19, 101,\n",
            "         17,  61, 615,  33,  13, 459,  99,  17,  76,  39,   2, 335,  14, 227,\n",
            "        885, 160, 106,  23, 412,  23, 124,  62,  20,  22, 454, 662,  11,   4,\n",
            "        338, 160, 243, 385,  98,   3, 120, 135,  16, 535, 843, 538, 244, 108,\n",
            "         30, 962, 776, 108,  44, 763,  57, 161,   8,  72,  21,  93,   1, 232,\n",
            "        295, 209, 118, 516, 994,  19,  29, 569,  51,  87,  89,  44,  24, 350,\n",
            "         56, 104, 234,  38,   2,  83,  86,   9, 470,  23, 129, 150,  16, 290,\n",
            "        306,   4, 510, 371, 106,  42,  15, 152, 556,  22, 143,  13,  19, 131,\n",
            "        255, 604, 186, 223,   9, 571], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
