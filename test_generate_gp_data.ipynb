{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0.5744, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(-0.7171, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.3002]], requires_grad=True)\n",
            "\n",
            "True:   l=0.693, sigma^2=0.693, noise=0\n",
            "Fitted: l=0.554, sigma^2=0.398, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABg2ElEQVR4nO2dd3iUxfq/79mW3hsphIRIDSlCgiBSlaJyVCxfxK7HgoiiR/zZARE96vGI9ehBxYqCAnaPCopUkRpakB4gJIH0XjbZ+f0xSQgQYJPsQhLmvq69kt13dt55Uz7v7DPP8xkhpUSj0Wg0bR/D2R6ARqPRaByDFnSNRqNpJ2hB12g0mnaCFnSNRqNpJ2hB12g0mnaCFnSNRqNpJ5xW0IUQs4UQR4QQW09y/EYhxObaxyohRILjh6nRaDSa02HPDP1DYNQpju8DBksp44FngVkOGJdGo9FomojpdA2klMuEEFGnOL6qwdPVQIQDxqXRaDSaJnJaQW8ifwf+Z0/DwMBAGRUV5eDTazQaTftm/fr1OVLKoMaOOUzQhRBDUYJ+0Sna3A3cDRAZGcm6descdXqNRqM5JxBC7D/ZMYdkuQgh4oH3gCullLknayelnCWlTJJSJgUFNXqD0Wg0Gk0zabGgCyEigYXAzVLKnS0fkkaj0Wiaw2lDLkKIz4EhQKAQIh2YCpgBpJTvAFOAAOA/QgiAaillkrMGrNFoNJrGsSfLZdxpjt8J3OmwEWk07RCr1Up6ejoVFRVneyiaNoKrqysRERGYzWa73+PoLBeNRtMI6enpeHl5ERUVRe0nWY3mpEgpyc3NJT09nejoaLvfp0v/NZozQEVFBQEBAVrMNXYhhCAgIKDJn+i0oGs0Zwgt5pqm0Jy/Fy3oGo1G005om4K+eTOsWXO2R6HRtCnS09O58sor6dKlCzExMUyaNImqqioAPvzwQyZOnHiWR3ginp6ejb5uNBpJTEwkNjaWhIQEXnnlFWw22yn7SktL47PPPrP73Lm5uSQmJpKYmEiHDh0IDw+vf173c2tttE1B37ULXngBvv0WTvNL1GjaKpmZMHgwZGW1vC8pJVdffTVXXXUVu3btYufOnZSUlPDkk0+2vPOTUF1d7bS+3dzcSElJYdu2bSxatIgff/yRZ5555pTvaaqgBwQEkJKSQkpKCuPHj+ehhx6qf26xWADnXmNzaJOCfiQbig0+8OWX8P77UFl5toek0TicZ5+FFStg+vSW9/Xbb7/h6urK7bffDqgZ7syZM5k9ezZlZWUAHDx4kFGjRtGtW7d6cSwtLeXyyy8nISGBXr16MW/ePADWr1/P4MGD6dOnDyNHjiQzMxOAIUOG8MQTTzB48GCee+45oqKi6mfOZWVldOzYEavVyp49exg1ahR9+vRh4MCB/PXXXwDs27eP/v37k5yczNNPP23XtQUHBzNr1izefPNNpJSkpaUxcOBAevfuTe/evVm1SvkHPvbYYyxfvpzExERmzpx50nan47bbbuMf//gHQ4cO5dFHH2XatGm8/PLL9cd79epFWloaAJ9++il9+/YlMTGRe+65h5qaGrvO0VzaZNrint1QusFEZN+OnLdiFYbDh2HiRPD1PdtD02hajJsbNExuePtt9XB1hfLy5vW5bds2+vTpc8xr3t7eREZGsnv3bgDWrFnD1q1bcXd3Jzk5mcsvv5z9+/cTFhbGDz/8AEBhYSFWq5X777+fb775hqCgIObNm8eTTz7J7NmzASgoKGDp0qUAbNiwgaVLlzJ06FC+++47Ro4cidls5u677+add96hS5cu/Pnnn0yYMIHffvuNSZMmce+993LLLbfw1ltv2X19nTt3xmazceTIEYKDg1m0aBGurq7s2rWLcePGsW7dOl544QVefvllvv/+e0DdYBprZw87d+5k8eLFGI1Gpk2b1mib7du3M2/ePFauXInZbGbChAnMmTOHW265xe7raiptUtABTCbYtt1AdlAkfTiA67Rp8NBD0KnT2R6aRtMi9u6FyZPh66+hrAzc3WHMGGgwCWwyUspGsyYavj58+HACAgIAuPrqq1mxYgWXXXYZkydP5tFHH2X06NEMHDiQrVu3snXrVoYPHw5ATU0NoaGh9X2OHTv2mO/nzZvH0KFDmTt3LhMmTKCkpIRVq1Zx3XXX1berrP2UvXLlShYsWADAzTffzKOPPtqkawRVxDVx4kRSUlIwGo3s3Nm4I4m97Rrjuuuuw2g0nrLNr7/+yvr160lOTgagvLyc4OBgu8/RHNqsoBuEmpDn5QsWF4TRt0seQdOnI8aPh9ofoEbTFgkNBW9vNUt3dVVfvb2hQ4fm9xkbG1svlHUUFRVx8OBBYmJiWL9+/QmCL4Sga9eurF+/nh9//JHHH3+cESNGMGbMGGJjY/njjz8aPZeHh0f991dccQWPP/44eXl5rF+/nmHDhlFaWoqvry8pKSmNvr856Xp79+7FaDQSHBzMM888Q0hICJs2bcJms+Hq6troe2bOnGlXu8ZoeI0mk+mYBdm63HEpJbfeeiv//Oc/m3w9zaVNxtDrEAK8vMBigZWp/mzNDKB65uvwxRfQyhYrNJqmcPgwjB8Pq1erry1dGL344ospKyvj448/BtSs+uGHH+a2227D3d0dgEWLFpGXl0d5eTlff/01AwYMICMjA3d3d2666SYmT57Mhg0b6NatG9nZ2fWCbrVa2bZtW6Pn9fT0pG/fvkyaNInRo0djNBrx9vYmOjqaL7/8ElDCt2nTJgAGDBjA3LlzAZgzZ45d15adnc348eOZOHEiQggKCwsJDQ3FYDDwySef1Metvby8KC4urn/fydo1laioKDZs2ACoENO+ffsA9TOfP38+R44cASAvL4/9+0/qfOsQ2rSg12GxqNn6ngx3luztRNHnP8Arr0Bh4dkemkbTLBYuhLfegoQE9XXhwpb1J4Tgq6++4ssvv6RLly507doVV1dXnn/++fo2F110ETfffDOJiYlcc801JCUlsWXLlvpFveeee46nnnoKi8XC/PnzefTRR0lISCAxMfGUC4pjx47l008/PSYUM2fOHN5//30SEhKIjY3lm2++AeC1117jrbfeIjk5mcJT/P+Wl5fXpy1ecskljBgxgqlTpwIwYcIEPvroI/r168fOnTvrZ9Px8fGYTCYSEhKYOXPmSds1lWuuuYa8vDwSExN5++236dq1KwA9e/ZkxowZjBgxgvj4eIYPH16/eOwsRF3c6UyTlJQkm7vBxR+TF2D97idsoeEnHCsvh4pySUJwBpHd3TE9eD+cd15Lh6vRtIjt27fTo0ePsz0MTRujsb8bIcT6kznatosZekPc3MDHV7A5J5zVqwXFj86An37S+eoajabd0+4EHcBgUCGYIoMvS3aGkfb8Z1j//ToUFJztoWk0Go3TaHOCXrg0Bd/vPsI/ZycBR1LxLM7EWNN4Ga67O3j6WUgpjGbdx9vInfAUcvOWMzxijUajOTO0ubTFLd+n0XPnCvzJh7yjrx8xdOCIJYJCj1BqvP0x+3lS6emPwWDA109QWBHOmpRiOt/9LyL+PhKPm65W8RmNRqNpJ7Q5QY/5x1W8uyuYgpXbMJgMuJbn41uRRYg1nZiKXfSp+AXX3ErYByV4sMfSg2yPKERAMC5B3uws60TOy4uJWLSRsKl3Y47terYvSaPRaBxCmxP00FAYdF4m1u1rGmS5eALdya6J45PSv1NWUIW5MIfAkv2cV5XK4KqvMedXU7PbwF/GWPZ79ORIUQk5/zeDDrePIuzeqxAe7mfzsjQajabFtLkY+qlwNVrp4n2EhMgCesaZCO4fQ+Ggv7Gwz/O813EaX3reTon0YHjRAsZk/ZcuqV+z57F3+aHLg+yfsxxqUzgPp2SS4juYI5sdYHOn0bQShBDcfPPN9c+rq6sJCgpi9OjRTjvnfffdR2JiIj179sTNza3efnb+/PlOO+e5TJuboTcVISDEs5QQT4AIyong+9LLKckoxj9vD30qVtAh83esN33An3/vT+nlYzFt2ciAwhWsuGE6wVv/c7YvQaNxCB4eHmzdupXy8nLc3NxYtGgR4eEn1nI4kjqDrbS0NEaPHn1CuX9NTc1pPVE09tOuZugnQ0rlsFtSAkV5VjzKcgj3KsKnozc7Yi7ly6B7+NFyFcmVKxi2cCKDdr2PERuDt70NQlAu9OKppn1w6aWX1jsnfv7554wbN67+WGlpKXfccQfJycmcf/759dWbJ7OZ/f333xkyZAjXXnst3bt358Ybb8SeQsXff/+doUOHcsMNNxAXF0daWhq9evWqP/7yyy/XOxiezGZX0zjtdoZeVaWqRg22ajwrcwlyrcDDU+DewYIhOgrRIQTRIRjh40NMjcBaJVm9ZRzitVdJqlqFGeXrUIYbyyNv5Lwf/yLmsu5n+ao07YEHH4ST+FI1m8REePXV07e7/vrrmT59OqNHj2bz5s3ccccdLF++HIDnnnuOYcOGMXv2bAoKCujbty+XXHLJSe1oATZu3Mi2bdsICwtjwIABrFy5kosuuui046iz6o2Ojq73Dm+Mk9nsahqnXQl6dTWUlgI2G0Fk0y2wAu8AMx4D+2C5MAkiIiAoSFUeNUI0sOyHRRhSV1KOCxaqyCWASw7Mhstns9ztYqrG3crQd67HYNYfEzVtj/j4eNLS0vj888+57LLLjjn2yy+/8O2339Zv1lBRUcGBAwcICws7qc1s3759iYiIACAxMZG0tDS7BL1v375ER0efss2pbHY1jXNaQRdCzAZGA0eklL0aOS6A14DLgDLgNinlBkcP9FRUVqrZuJuhkni/wwQFSDwG9UYMGwZduij3Ljsx5x9mRex4Oky5m6zpszBnH2LPJU9TvPAX+pUvJWj2IrZ/+Dz7LrmLYfPG4+qrLDcPp2SSOeR6wpbNIzi+BT6nmnaPPTNpZ3LFFVcwefJkfv/9d3Jzc+tfl1KyYMECunXrdkz7adOmndRm1sXFpf57o9Fo95Zs9tjP2my2U9rsak7Enhj6h8CoUxy/FOhS+7gbeLvlw7KPigrIzweLrKR/+H4u7p1P9INX4fnOy4j774fY2CaJOUD/jIUM3voW3f4vgcFb3+LCw18zZM7djDzwPlkz3mVhwN8x2qq57JeHyPOL4X8Dn6cst5y/bnqWuMIVbL/BAfuFaTRO5I477mDKlCnExcUd8/rIkSN544036uPgGzduBBxnM3syQkJCOHLkCLm5uVRWVtbvKHQqm11N45xW0KWUyzimJvMErgQ+lorVgK8QIvQU7R1CRQWYDdUMijrA4Pg8Qu69BtNr/4YrroDaXVcciSXIh7gnr2JM+lu4fPEJ33R7hCzRgUtXPIl7oDuDt72tF1I1bYKIiAgmTZp0wutPP/00VquV+Ph4evXqVb+np6NsZk+G2WxmypQpXHDBBYwePZru3Y+uVZ3MZlfTOHbZ5wohooDvTxJy+R54QUq5ovb5r8CjUsoTvHGFEHejZvFERkb2aa7Z+8HXFuD+1Wf4dfLCMGokjB6tdro4k0hJ4fYMfv/7x/Rb/SohKBP7Ssysi7yGLt/N1KEXTT3aPlfTHM6GfW5j+0U1epeQUs6SUiZJKZOCgoKafcKOXd0JGJmEYcazMG7cmRdzACHw6RnOlX88zl89xlCDoAaBC1biDvzAxgc/oGzTLrBaz/zYNBrNOYkjslzSgY4NnkcAGQ7o9+SMGqUezdh70BlYCo6wIvZeAv5xCwX3PUFcxVpGLnmClN5fktc5iS6juxN4cQJusZ1Vpo3ZfLaHrNFo2iGOEPRvgYlCiLnABUChlNLJ+yy1DiGvo39Gg/3B7viVtIXr+eWOtxlU+B2Juzfy61uj2LlwC8HBguAOBrzionC/IA46d4bwcPDza3XXpNFo2h72pC1+DgwBAoUQ6cBUwAwgpXwH+BGVsrgblbZ4u7MG21aIuroPfl2nsuF2H1ZuyWB05QLKD7jxW8m17K0IwXVPDkH/+5bgEImfj8Q92BPRtSv06AEdO0JY2NkJI2k0mjbNaQVdSjnuNMclcJ/DRtRO8OnVkYt+fJpt977Btyv8CM3Zxpi82aQW9GJf91EccenIwcMgs8BzXyVRu3YQtHQjXt4Cg7SBvz/UiXxEhBL5Bvm/Go1GczztqlK0tWEO8iXhk0dwfeBNshaX8VFZX0Yd+YRuqa/wq/fVeMd1Q5hMWK0upB5xwZYFJhNEhEvCDRX4bdiEafVqVdkqpQrP9OqlhL5jR5WeqUM1Go2mFi3oTka4udL9rQdwefy/mL5ey7KQ8bjsSuWKoi/Zv6oTqV2vwq2Db/06aU0NHEwX7D/ghhBuhIbWare/xFxWAosXw88/q8ZeXhAfD3G18Xgt8G2GKVPgwAHH9RcZCdNPU9OWlZXFgw8+yNq1a3FxcSEqKopXX32Vrl2bvsnL8uXLGT9+PGazmR9++IFJkyY1aok7ZMgQXn75ZZKSGs2ycwr33XcfK1eupKqqin379tVXvj711FNce+21Z2wcZwMt6GcCi4XoF+/FxdsVw6fLKU7owYdZUxiy/2NG7nidJZlXYYjrgTCZMRqPhs9tNjh8GA4dUl7WoaFeREZ6ERiiZvJUVMDatbBihXpDQAAkJSmRj4mBBmXZmtbFgQMQFeW4/k7hbwWoKssxY8Zw6623MnfuXABSUlI4fPhwswR9zpw5TJ48mdtvV0tmrcnf/Fy27D0n7HNbBSYTYU/eTszNF+KVl0aHENjU9+985TKOi4u+otMf86jKLTrmLQYDeHqCr68S+SNHYPVq+N//YMMGyClxxRbcATp1UlM0g0HN4F9+GSZOhNdeU4JfUnJ2rlnTaliyZAlms5nx48fXv5aYmMjAgQORUvLII4/Qq1cv4uLimDdvHnBye9z33nuPL774gunTp3PjjTceY39bXl7O9ddfT3x8PGPHjqW8vLz+fL/88gv9+/end+/eXHfddZTU/l1GRUUxdepUevfuTVxcXL1FbklJCbfffjtxcXHEx8ezYMGCU/ZzKs4Vy149Qz+TmEyEPP53DDVWds1dT6FPJ7wv6MKsvc9wefoshm59g6XB12Lq3gXEsffaOnEHFZY5dEjN8iwWiI6Gjh0Fnp7u4O5+tNHOncqnVQgVex88WPnb6MXVc46tW7fSp0+fRo8tXLiQlJQUNm3aRE5ODsnJyQwaNAho3B73zjvvZMWKFYwePZprr732GPvbt99+G3d3dzZv3szmzZvp3bs3ADk5OcyYMYPFixfj4eHBiy++yCuvvMKUKVMACAwMZMOGDfznP//h5Zdf5r333uPZZ5/Fx8eHLVu2AJCfn3/afk7FuWDZqwX9TGM2E/TkPRhr3mT7l1soFpF0jbGxKvg+PDf/waVH5rIlvze5iRcfFefjaBiWsVqVbu/YoRJjYmIgJARMJqOyCgYVu9m7F7ZsUUVN/fvDwIGqsY65n/OsWLGCcePGYTQaCQkJYfDgwaxduxZvb+8m2+MuW7aMBx54AFBWvfHx8QCsXr2a1NRUBgwYAEBVVRX9+/evf9/VV18NQJ8+fVi4UNV1LF68uD48BODn58f3339/yn5Oxblg2asF/WxgseD/1AS6l77M1h8PUGEII8irkup+fXgntRc35b1O2No0Urr8H8awkFN2ZTaDj49KgiktVREWs1mtkXbqVHtPMBggMFA9rFb44w9YulSlQl56KfTpc9Kbh6Z9EBsbe9I496n8nJpjjysamSRIKRk+fDiff/75Kc/T8BxSyhP6Ol0/p+JcsOzVMfSzhasrAc88QK+Bfpjzj1BVBSajpHuchbldp5JBOBfvegfjlhSEtJ22OyHAzU3F211c1Kz9l1+UwOfn1+9/rdQ+LEypfUUFvP8+/OMf8NVXkHcqU01NW2bYsGFUVlby7rvv1r+2du1ali5dyqBBg5g3bx41NTVkZ2ezbNky+vbt26zzDBo0iDlz5gAqzLN582YA+vXrx8qVK9m9ezcAZWVlx2yU0RgjRozgzTffrH+en5/frH4ao71a9mpBP5t4exPw/MPEn29A5udTN/k5L7SUnX1vYJ75JgbmfUPg6u8QFWV2d2syqVm7j4/Kklm6FJYvV4uq9cIuBHh7q1QLPz/4/nuYPBk++kg11DiVyEiVmeKoR2Tkqc8nhOCrr75i0aJFxMTEEBsby7Rp0wgLC2PMmDHEx8eTkJDAsGHDeOmll+jQoXlOoffeey8lJSXEx8fz0ksv1d8YgoKC+PDDDxk3bhzx8fH069fvtIuNTz31FPn5+fTq1YuEhASWLFnSrH4ao71a9tpln+sMkpKSZN2+hOc8aWlkTZzBur3+uAW4U5dRVW0zsG2r5M78lygXHmztcS0EBTe5eynVjk6VlWoG36OHirOf8Mm4pgYyM9XXIUNUOCa46efTnIi2z9U0h7Nhn6tpKVFRdJg2noQOWRTnW6kL7ZkMNhLiJbM7zyBX+nFR6iyMu/9qMM22DyFUiNzXV0VZ/vgDliw5bsYOarU1IkI9li+Hxx+HL76A4mKHXapGo3EeWtBbC0lJRDx4HfG+BygssB0jtHEdC1mTeDe/GkYw8NA8vFOWYahpus96wzh7ZSWsXKl0+4TQeZ2wd+gAP/0Ejzyi8tu1t7tG06rRgt6KEKMvp9MNF9HV9SBFx9YY0dGnmIoLBvGO6yR6F/1O+J8LMVY0b+bcUNiLi1WMfe1alSVzDGazCs76+sInn8DUqSo/UqPRtEq0oLcmDAaMd9xKl4sjCTVknVDg6WOp4Lxkf/7p9xLB1nS6r/kUc0HzFzCFAA8PpddZWWoSvn17IxNxV1dVvVRSAs89B+++ywl3HI1Gc9bRgt7acHXF8o+JxMUL3KqLqU2PrcdksNE/vpT/dPwnpdKNPps+wHJob4tOKYQqVPL0VBPwX39Va6MnhOr9/VVWzOrVKr6+dm2T4/kajcZ5aEFvjQQF4fbI/fTtnEN1ubXR0PUFnXP4vscjbOB8Ltz9CR67NrZYXI1GNVsXQmn26tVQdny2pMGg7B/d3eGNN+Ctt6CwsEXn1Wg0jkELemulZ0+87hxL37CDFBdJbI3UFvUKzmZX77EsMFxHcsa3+G9ZirDVtPjULi5K2HNy1Gw9LY0Tz+/hocIwKSnw1FOwbVuLz6txLunp6Vx55ZV06dKFmJgYJk2aRFVVFQAffvghEydOPMsjPBHPOgOj4zAajSQmJhIbG0tCQgKvvPLKMZWfjZGWlsZnn33W5DHUnavukZaWxoUXXthonykpKfz4449NPseQIUNwRBq3FvTWzKhRBF2aTGJQOoWFjU/AO3nlY0vuyxvmh4jPX0ro+u8wVrfce6IuDOPmBhs3qoyYExZNhTi66fWLL8Lnn0OtQGgcQGamMlTLympxV1JKrr76aq666ip27drFzp07KSkp4cknn3TAQBvHHpuA5uLm5kZKSgrbtm1j0aJF/PjjjzzzzDOnfE9zBb3uXHWPqKgoVq1a1WifzRV0R6EFvTVjMCDuuJ1O8T5EeuWfNB08yLWEzn2DeMb9BaLLthG15gvMzcyAOR6TSc3WCwvht9+Uw+MJNxZvb2Ul8PPP8M9/Qna2Q859zvPss8rr/nQ7V9jBb7/9hqura71/udFoZObMmcyePZuy2rjawYMHGTVqFN26dasXx9LSUi6//HISEhLo1atXvbXu+vXrGTx4MH369GHkyJFkZqp94YcMGcITTzzB4MGDee6554iKiqqfOZeVldGxY0esVutJLWr37dtH//79SU5O5umnn7br2oKDg5k1axZvvvkmUkrS0tIYOHAgvXv3pnfv3vXi+9hjj7F8+XISExOZOXPmSdvZQ90nh4Z9vvjii0yZMoV58+aRmJjIvHnzKC0t5Y477iA5OZnzzz+/vur0VDbDLUGbc7V2PD0xTrqf+KenU7DLnbIyl0Z9tDxMlQzoY2DK5td5ovD/4bpuDnsSr6HCM6jFQxBCLZharbB+vZo4JiYet3+G0ahEPTMTnn4aJkxQG21omo6bG8eshr/9tnq4uqqS32awbdu2E+xzvb29iYyMrPdFqbOXdXd3Jzk5mcsvv5z9+/cTFhbGDz/8AEBhYSFWq5X777+fb775hqCgIObNm8eTTz7J7NmzASgoKGDp0qUAbNiwgaVLlzJ06FC+++47Ro4cidlsPqlF7aRJk7j33nu55ZZb6jeqsIfOnTtjs9k4cuQIwcHBLFq0CFdXV3bt2sW4ceNYt24dL7zwAi+//HK9b0tZWVmj7Y6nvLycxMREAKKjo/nqq6/qjx3fZ0hICOvWrav3oHniiScYNmwYs2fPpqCggL59+3LJJZfw3//+t1Gb4ZaiZ+htgehozLffxAXh6Vir5Enre0wGG8MTjvBc8OtU1whiN3yKW8Ehhw3DbFaz9cOHVaVpbu5xDYRQxUienmqTje+/byT4rjkte/fCDTccdcB0d4cbb4R9+5rdZWPOhce/Pnz4cAICAnBzc+Pqq69mxYoVxMXFsXjxYh599FGWL1+Oj48PO3bsYOvWrQwfPpzExERmzJhBenp6fZ9jx4495vu6Wf3cuXMZO3bsMRa1iYmJ3HPPPfUz/JUrVzJunNqX/uabb27yNQJYrVbuuusu4uLiuO6660hNTW20vb3tGoZcGoq5Pfzyyy+88MILJCYmMmTIECoqKjhw4ADLli3jpptuAo61GW4peobeVhg6FM/UVC6wbuKPAxH4+KiEk+MxCMmoHvt5y+UFbjn4HAmbPmVrz+soCerskGHUeXpVVMCyZdCzJ3TpctxYPD3V9H3ePDh4EG6/XW+q0RRCQ4/+kF1d1Vdvb3WzbCaxsbH1O/7UUVRUxMGDB4mJiWH9+vUnCL4Qgq5du7J+/Xp+/PFHHn/8cUaMGMGYMWOIjY3ljz/+aPRcDW1qr7jiCh5//HHy8vJYv349w4YNo7S09JQWtY3deE7H3r17MRqNBAcH88wzzxASEsKmTZuw2Wy4nuRvb+bMmXa1awlSShYsWFC/r2lDmnOdp0PP0NsKBgPcdhshnT3p1qHwtHU9l3Tex9yYJ9hGTxJTP8PnUOOzj+bi6qo0JjUV1qxpZC20zpR9zRoVV9fWvE3j8GEYP17ljo4f3+KF0YsvvpiysjI+/vhjQO2r+fDDD3PbbbfhXvtJYNGiReTl5VFeXs7XX3/NgAEDyMjIwN3dnZtuuonJkyezYcMGunXrRnZ2dr2gW61Wtp0ky8nT05O+ffsyadIkRo8ejdFoPKVF7YABA+o3taiz4T0d2dnZjB8/nokTJyKEoLCwkNDQUAwGA5988gk1NSrzy8vLi+IGC1Ena9cUju/z+OcjR47kjTfeqP/0sHHjRuDkNsMtRQt6W8LLC3HfBLoF5+HvZT3tVqGDItJY1G0iyxjE+bu/xG9/ikOHU5e3XheCOSEdXQgVV8/KUgt7Bw869PztmoULVY5/QoL6WruLT3Ops8/98ssv6dKlC127dsXV1ZXnn3++vs1FF13EzTffTGJiItdccw1JSUls2bKFvn37kpiYyHPPPcdTTz2FxWJh/vz5PProoyQkJJCYmHjKBcWxY8fy6aefHhOKOZlF7WuvvcZbb71FcnIyhaeob6iLa8fGxnLJJZcwYsQIpk6dCsCECRP46KOP6NevHzt37qz/xBAfH4/JZCIhIYGZM2eetF1TOL7PoUOHkpqaWr8o+vTTT2O1WomPj6dXr171C70nsxluKXbZ5wohRgGvAUbgPSnlC8cd9wE+BSJRYZyXpZQfnKpPbZ/bAr79lvJP5/PrnmgsLgKL5dTNU3I7Er31O67kG7ZGjCKnc1+Hbz1XVgbV1Wrzo/DwRhrk5ipHsIceUv695xjaPlfTHBxunyuEMAJvAZcCPYFxQoiexzW7D0iVUiYAQ4B/CyFOIzOaZnPZZbgldOOCqCxKS0+/7pgYcJCDCZcxR9xIr/SfCN653OEl++7uKjnjzz/hr8YcfgMCVGL7iy+qRhqNxuHYE3LpC+yWUu6VUlYBc4Erj2sjAS+hovyeQB7gvKqCcx2TCe66i6AASfdO5RQVnV6fe/lmUJI4gP+K8fTMWkLo9l8dLup1WTDbt8O6dXBCXYmXl9pZ4623VIxG+8BoNA7FHkEPBxoGP9NrX2vIm0APIAPYAkyS8sSNMIUQdwsh1gkh1mXr4pOWERwMt91GV+9M/HxtJ1ZxNkI378NYevdipuEfdMteScS2n+zar7QpGAxK1A8dglWrOMFcDDc3FZOZPRt++EGLukbjQOwR9MaCrcf/F44EUoAwIBF4UwjhfcKbpJwlpUySUiYFBbW84OWcp39/jAP60zfsEFLaV3Uf7ZlNQO8o/ml8kvNy19Bxyw8O8X9piBBqP9PCQpXaeMLirYuL8lmfN09tTq1FXaNxCPYIejrQscHzCNRMvCG3AwulYjewD+iOxrkIATfdhFuQJ8ndiuyKpwNEeuTSsXcwU43P0jl/A522fOcUUffyUtWlS5dCfv5xDcxmlQHz1VewYIEWdY3GAdgj6GuBLkKI6NqFzuuBb49rcwC4GEAIEQJ0A1pm0q2xDy8vuOceQow5xETV2L3vRIR7Hl37ePGk8QWiCjYRtfkbhM3xyx4eHiq9cflytYfpMZhMStS/+UbtXaqrSjWaFnFaQZdSVgMTgZ+B7cAXUsptQojxQojxtc2eBS4UQmwBfgUelVLmOGvQmuPo2RMxaiSxPul4eTXiingSwt3yie3jyv8z/ZtOhVvovOlrDE4QdVdXFWVZtUrF1o/BZFKbZnz/Pcyfr2fqTkQIcUw5fXV1NUFBQYwePdqp573tttuIjo6ut599/fXXmTJlCosXLwbg1VdfrTcIA47JjbeX1mr/e6axq/RfSvkj8ONxr73T4PsMYIRjh6ZpEtdcg3HzZvqa8vhtoz/V1UorT0eYWz709uPhDa/x76JJsEmyL2EMNoNjXSFcXNSC6Zo10Lu3mpjXYzQqUf/uOxWKueoqh+fJa1RJ/tatWykvL8fNzY1FixYR3mjRgOP517/+xbXXXtvosVdffZWbbrqpvmL1+eef54knnjgj42pv6ErR9oKrK9xzD162IhJjrXalMtYR5pZPn96Sh0yv07Eolc6bvnLKTN1sVhGi9esb8Zmqc2tcuBB+/FHP1J3EpZdeWu+c+Pnnn9cbYQEntXo9mc3s77//zpAhQ7j22mvp3r07N954I/YUKoKatc+fP5/XX3+djIwMhg4dytChQ3nsscfqq0BvvPFGAD799NP6atV77rmnvkT/gw8+oGvXrgwePJiVK1c67GfUltHmXO2Jzp3hyivp+PU3ZIVHcfiw8luxhzC3fJJ6+/Pg+jd4teh+2AR7nTBTN5lUBszGjVBTAzExDSbjJpPKfvn8c5XeOGyYQ8/danjwQbXTkyNJTIRXXz1ts+uvv57p06czevRoNm/ezB133MHy5csBeO655xq1ej2ZHS0ob5Jt27YRFhbGgAEDWLlyJRdddNEJ533kkUeYMWMGAJ988kn96w888ACvvPIKS5YsITAwEIA333yz3rhr+/btzJs3j5UrV2I2m5kwYQJz5sxh+PDhTJ06lfXr1+Pj48PQoUM5//zzW/ADbB9oQW9vXH45hg0bON+Sza95QVRWHudbfgrC3fKw9Q5g0oY3ea1oImyGPfFjkA4WdaNRifrmzWodtEuXBqJuNqs9Sz/8ULk2OsjjQqOIj48nLS2Nzz//nMsuu+yYY7/88gvffvstL7/8MkC91WtYWBgTJ04kJSUFo9HIzp0769/Tt29fIiIiAOq3Z2tM0E8VcjkVv/76K+vXryc5ORlQHi7BwcH8+eefDBkyhLr057Fjxx4zrnMVLejtDYsF7roLy9SpJCVUseJPC2Zz41a7jdHRPRfZO5CHNrzGzMJJsMXAnrirkAajQ4dZJ+pbtyoxP++8BqLu4qIsZP/zH5UmExvr0HOfdeyYSTuTK664gsmTJ/P777+T28DU/mRWr9OmTTupzaxLg9mC0Wh0+LZzUkpuvfVW/vnPfx7z+tdff+0U+9m2jo6ht0ciI+GaawiqPETXLtLuVMb6t7vnEJdo4mHDTCIKttJ56zcOz1OHo6K+ZQvs2XNc2NzNTfm/zJzZoo0dNCdyxx13MGXKFOLi4o55/WRWr46wmT0Vx1vOms1mrLW7uFx88cXMnz+fI7U5r3l5eezfv58LLrig/oZktVrrrXjPdbSgt1dGjYLOnekWmI23t/2pjHV09jxCt0Q3HhEv0zF/C51TvwcH2wTAseGXE3Tby0vN0P/970aS2DXNJSIigkmTJp3w+smsXh1hM3sq7r77bi699FKGDh1a/zw+Pp4bb7yRnj17MmPGDEaMGEF8fDzDhw8nMzOT0NBQpk2bRv/+/bnkkksctoVbW8cu+1xnoO1zzwCHDsHTT1Pk3oElKy14eNiXytiQ1KII0lOyeV4+wYGg3uztMdopKYU1NcoqoE+f41IagfrV3aeeUiLfBtH2uZrm4HD7XE0bJjwcrrsO7+JDxMfJJqUy1tHTO53g+A5ME1OJzN5A9I6fnJJSaDQqzd6woZHio5AQ5af+xhvKU12j0TSKFvT2zvDh0LkznTyy6dABGoQq7SbRdz9uPWN4gUfpdHgNUbsWOUXUTSaV2LJ2rZqUH0N4OOzcqbJftEWARtMoWtDbOyYT3HknhsoKzo+twmCwz5XxeC4I3ENlj0ReZRJRmX8Que93hw8VVNaiu7vaSvOYbUiFUIu9K1Yo212NRnMCWtDPBcLD4f/+D7fcdPr0lpSWNm+CPTj4L7K6DmIWd9H54DIi9q9w/FhRmZd13i/HZOgYDErUv/xS7aCh0WiOQQv6ucIll0BMDB1M2URF0eRUxjpGhW5mW8zf+JQbOS/tV8LSnbOdnKur0u+VK4/L0DGboUMHePttSEtzyrk1mraKFvRzhdrQi6iooFfXKlxdoby8eV2NiVjP0k638hVX0XXPT4RkbnTsWGtxd1fZL3/8cdxaqLu7Cra/+ioUFDjl3BpNW0RXip5LhIfDNddg/uILkpKiWbbsqAtiU7mh00req56Ex6FSLtn5PTaTC9lBx+8d3nI8PdWniTVroH//BmmXfn4qHeY//4FHHlEz97bElClw4IDj+ouMhOnTT9kkKyuLBx98kLVr1+Li4kJUVBSvvvoqXbt2bfLpli9fzvjx4zGbzfzwww9MmjSJ+fPnn9BuyJAhvPzyyyQlNZpl5zRuu+02li5dio+PD6CKqXJychg0aBCXXHIJr776KnfffXeLHB4//PBD1q1bx5tvvunw8TcXLejnGiNHwpo1BGQfoXv3YHbsUHuANhUh4M6Y33nDOhWPI6VckPoVNXEW8vzPc/SI8fJSWYsbN6o89fobUFgY7NihtrK78ca2Zbl74ICyDHYUpwk/SSkZM2YMt956K3PnzgUgJSWFw4cPN0vQ58yZw+TJk7n99tsBGhXzs825aNmrQy7nGrWhF8rL6RpVhY9P06tI6xAC7uu+mOf9/81m4ui+9Ut8Ch0462xwHh8fSE+H1NQGC7p1mS8//6w2L9WclCVLlmA2mxk/fnz9a4mJiQwcOBApJY888gi9evUiLi6OefPmASe3x33vvff44osvmD59OjfeeCNpaWn06tULUOZZ119/PfHx8YwdO5byBnG9X375hf79+9O7d2+uu+46Smo3m42KimLq1Kn07t2buLg4/vrrLwBKSkq4/fbbiYuLIz4+ngULFpyyn9NxLlj2akE/F+nYUW2IkXWIpCSorlaP5mAUkkmxi3jU+x32ySh6bJ6LZ3GmY8fLUVHftQv27284AKMKJX30kfZ8OQVbt26lT58+jR5buHAhKSkpbNq0icWLF/PII4+Qmal+hxs3buTVV18lNTWVvXv3snLlSu68806uuOIK/vWvfzFnzpxj+nr77bdxd3dn8+bNPPnkk6xfvx6AnJwcZsyYweLFi9mwYQNJSUm88sor9e8LDAxkw4YN3HvvvfVuj88++yw+Pj5s2bKFzZs3M2zYsNP205BHHnmkfpekLVu21L/+wAMPEBYWxpIlS1iyZAkvvPACbm5upKSkMGfOnGMse+scJufMmUNmZiZTp05l5cqVLFq0iNTU1Ob/QpyEFvRzlZEjITISr8oc4uJUwVFza4Ushhr+Eb+Y8R6fcNgWRM/Nn+NW5vgdCA0GFX7ZuPE4axdXVxVsf/315qfvnMOsWLGCcePGYTQaCQkJYfDgwaxduxY4ao9rMBjq7XFPxbJly7jpppsAZdUbHx8PwOrVq0lNTWXAgAEkJiby0Ucfsb/Bnfnqq68GoE+fPvXnWLx4Mffdd199Gz8/v9P205B//etfpKSkkJKScoIR2aloaNmbmJjIr7/+yt69e4+x7LVYLIwdO9buPs8UWtDPVcxmFXopLSU6wkpICNj5ybVR3IxVPJiwhNtc51FS7UZsyme4VBQ6bry1mEwqyeXPP4/Tbn9/dVd6912VGqM5htjY2PrZ8vGcys+pOfa4jdnaSikZPnx4vcCmpqby/vvvn3CehueQUp7Q1+n6cQR1lr1159ixYwfTpk076bW1JrSgn8t06gRXXYXIOERiogprNKeKtA4fczkTElcxzjwfm7WGnps+w1zVzAD9KXBxUZGWE9IZw8Nh0ya1N6nmGIYNG0ZlZSXvvvtu/Wtr165l6dKlDBo0iHnz5lFTU0N2djbLli2jbzM3Fhk0aFB9GGbr1q1s3rwZgH79+rFy5Up2794NQFlZ2Wk3pBgxYsQxGST5+fnN6qcx2qtlrxb0c51LL4XwcNzLczn/fJpdRVpHkEsRtyamMNb4JZaKInpsnoux2vGGWu7uSszXrm0wIRdCrQ8sXKhWT1szkZEqM8VRj8jIU55OCMFXX33FokWLiImJITY2lmnTphEWFsaYMWOIj48nISGBYcOG8dJLL9GhQ4dmXda9995LSUkJ8fHxvPTSS/U3hqCgID788EPGjRtHfHw8/fr1q1/8PBlPPfUU+fn59OrVi4SEBJYsWdKsfhqjvVr2avtcjRKEadOQYeFs2GImPV0tQLaEHcVh/JwSzDzbdRR6R5KaMM7h+5NKqeqKoqMhIaFB1mJRkVL7Z59VoZhWgLbP1TQHbZ+raTpRUXDllYiMQ8TFqZBGRUXLuuzmlcGAXoX8ndn4F+2j27aFCAdvkCGEyqHfu/e4BBdvb7BaYdas5qfvaDRtELsEXQgxSgixQwixWwjx2EnaDBFCpAghtgkhljp2mBqnc/nlEBqKpTiXpCRlC9BSl9o+fvuI6enCJF4jJG87XXZ853Db3bp0xk2bIKdhYk1oKGzfDt9+69DzaTStmdMKuhDCCLwFXAr0BMYJIXoe18YX+A9whZQyFrjO8UPVOBWLBe6+G4qLCfStpksXx2QADg5KxdwlmqlMI+xwCp33/OJwUTcaj2a+1BdJ1cXTv/5aCXsr4GyFNzVtk+b8vdgzQ+8L7JZS7pVSVgFzgSuPa3MDsFBKeaB2IHoDyLZIdDT87W+Qnk737irnu7lVpA25ImwdBztdxBtMJPLQaiIPOr7CzsVF3SfWrGkQZTGZIDBQ+b0UOj6Fsim4urqSm5urRV1jF1JKcnNzcXV1bdL77FmlCgcONnieDlxwXJuugFkI8TvgBbwmpfy4SSPRtA5Gj4a1azEV5ZGU5M/vvyuBbOpepMdzc6flvFl1AwGZudyw73OsZjcyQxuvXGwunp5Kt1NSlOeLEKh4+qFDMHs2TJrUPCcyBxAREUF6ejrZ2dln5fyatoerqysRERFNeo89/6aNZdIfP80wAX2AiwE34A8hxGop5TEJokKIu4G7ASJPk2alOUu4uKjQyzPP4NPRm169TGzerBYfW1JTIQRM6PILL1gfwS8nn5E7f8RqciPHwQ6N3t5w8KBKbuncufbFsDBVXrp4MYwY4dDz2YvZbCY6OvqsnFtz7mDPdCUd6NjgeQSQ0Uibn6SUpVLKHGAZkHB8R1LKWVLKJCllUlBQUHPHrHE2nTvDFVdAejrR0RAc3LIq0jqMQvJIj++Z4fMvVnMB3bd/hW++Y/1XhFCivnmzcmisfzEiAj7//DgjGI2mfWGPoK8FugghooUQFuB64PjUgW+AgUIIkxDCHRWSaR0rUZrmMXo0hIZiyFcFRy2tIq3DYqjhyV7f8qDHu+yQXem5dR5excfPD1qG0ajsXf78s8EmHhaLism8807LczI1mlbKaQVdSlkNTAR+Ron0F1LKbUKI8UKI8bVttgM/AZuBNcB7Usqtzhu2xum4uMBdd0FREe6WaodUkdbhbqriifgfuM11Hpm2EGKdYObl6qoqSI+pJA0IgKws+OILh2faaDStAV0pqjk1CxfCt98iO0WxcaOKT7e0irSOrApfXtkwmB+sI3C31LC5921Uung7pnOOVpKedx706lW7BlBToypjH34YEhMddi6N5kyhK0U1zWf0aAgPR+TlEhdHi/YiPZ4OrgXcE7+aqwzfYquyErtpDiZrmWM651gP9cw6i3ajEUJClCtjfr7DzqXRtAa0oGtOjcWiQi/FxZixkpysbFIc5VAb43mYsXHbuUYsxLW8gNgtczHUOCBYX0udh/q6dcpdF1Cx9MpKtSlGS8thNZpWhBZ0zemJioKrr4b0dPz9oUcPVUXqqGhdvO8BBvfMYRyf4V18iJ7bvkTYHOdpbjarifkxRUfh4bBhAyxf7rDzaDRnGy3oGvu49FIl7EeO0KWLKsB0RBVpHQMCd9C5q4m7mUVg/m66//W1QxcuPTzUDH3LltpuhVD56Z9+qhZKNZp2gBZ0jX2YzargqKICQ3UVffooYXREKmMdl4duxBjdif/Hi4Rkb+W83f9zqKj7+ChXxoN1dc+urqoE9t13tSujpl2gBV1jP+HhMHYspKfj7ibp3dtxqYx1jOu4gn3hA3mJR4jIWEvUfscZdwqh4ukpKQ2Mx4KDYfdu+Plnh51HozlbaEHXNI1LLlFB9MOHCQtTfl6O3JdZCLg35hcWB93A+9xB1P6lhB/602H9m81qUr5mjbJMRwh1o5o/Hw4ccNh5NJqzgRZ0TdMwGuHvfwebDVFRTmysik+XOS7bEIOQ/L/u3zLb72G+5kq67P6J4MObHda/u7uyMqiPp1ss6iL++1/HxpA0mjOMFnRN0wkOhltugcxMzCZJcrKa7ToyDG0y2Hg69iume73E7wym21/f4p/b9M2AT4aPj7J1SU+vfSEwULky6g2mNW0YLeia5jFgACQnQ0YGPj4QH+/YVEYAV6OVZ+IW8oD7e2wigZ7b5uNT4BhzLSFUOvrGjQ3y0yMi1A5He/Y45BwazZlGC7qmeQihZukuLlBcTFSU0kNHxtMBvMwVTIn/hltc5rJXRhO7dS6eJY5JM6zLT1+7tvbThcmkpu6zZmkDL02bRAu6pvn4+KhUxuxshK2GxETHWgPUEehSzOMJ/+Ma09ccqQmk16Y5uJXlnv6NduDhoW5C27bVfrrw94cjR+CbbxzSv0ZzJtGCrmkZ8fEwciSkp2OxQN++jrUGqCPcLY9JCb/zN8MPlFa70GvzHFwqHfNxwNsb9u5tUF8UHg4//KBMYDSaNoQWdE3LueYa6NABcnPx81POho6OpwOc53mYO+LXMlr8gKy00mvTp5irWl6uajComfr69bXVryYT+PmprBdHf9zQaJyIFnRNy3F1hfHjVS5gZSUxMaqq3tHxdIA4n4NcFbuLv/Et5vIiem3+DGN1y+PdFov6un59rV+Xn5/a8ujrr1vct0ZzptCCrnEMnTrBDTdAejoCyfnnOyeeDnBBwG4G9sjhGhbgUXqEXlvmYqixtrhfDw+l4Tt21L4QEQE//QQ7HZcuqdE4Ey3oGsdx8cXQuzdkZGCxwAUXqDodZ9ikDAveRo+uNdzIp/gUHaDnti9a7NBY55/+11+Qk4NKgfH1VV4vOutF0wbQgq5xHAYD3H67SmUsKsLXFxISnBNPBxgdugG/zn7cw38JzN9Nj+0LEbJl/uYGA7i5qVTGykpU6CUnR4deNG0CLegax+LrCxMmKBGsrqZTJ+W6W1jonNNd33EVFZHdeIhXCM5JpeuO71p893B1VZWvKSm1XYWHw//+p0y8NJpWjBZ0jePp2ROuvBIOHkQgiY9XoYySEuec7o6o3zgQ3p+pTCP0cIpDbHe9vJQTwP79HC04evfd2mm7RtM60YKucQ5XXgndukFWFiaTyk8H5+ihEHBfzM+sCfkbL/MwERlr6bzv1xaJuhAqP33TptpsHX9/OHwYvv/ecQPXaByMFnSNczCZ4J57VFC6uBgPD2X9Ulbm+KIjUA6Nk7t9xw+Bt/I244k8uJJOB1q2vZzJpB711gB1Xi/79jlm0BqNg9GCrnEeAQEqnp6dDdXVhIRAbKyKpztjkdQoJE/2+Io5/vfzEbcQnbaEiIN/tKjPuq3rUlNR6u7trUIv2mZX0wrRgq5xLnFxcNVVat83KenSBTp2dN4iqclgY0rsQt72fZwvuZbz9v5C2KE1LerT21sZMGZloW5SGRlqkVSjaWXYJehCiFFCiB1CiN1CiMdO0S5ZCFEjhLjWcUPUtHmuuEL5AWRmIgQkJiqRdNYiqcVQzbReC3jR+3m+4Qq67v4foZkbmt1fQ2uA8nJU1svXX+sdjjStjtMKuhDCCLwFXAr0BMYJIXqepN2LgN6cUXMsJpNyZXRzg4ICzGZVdCSE85JGXI1Wpsd9yTSvl/mJkXTd+T0hhzc1uz+LRVkCbNwINqNZbXv0/vt6c2lNq8KeGXpfYLeUcq+UsgqYC1zZSLv7gQXAEQeOT9Ne8PGB++9XsZbKSjw8oF8/NeN1lia6m6p4Nn4+j3m+wW8Mpdtf3xB8eEuz+/P0VIkue/cCQUGQlgaLFjlsvBpNS7FH0MOBgw2ep9e+Vo8QIhwYA7xzqo6EEHcLIdYJIdZlZ2c3dayats5556lNMQ4dApuNgADlFFBcXGuI5QQ8TZU8G7+AhzxmsYxBdP/rK4KObGtWX3WpjFu3QkEBKvTy5Zcqpq7RtALsEXTRyGvH5yi8CjwqpTxlQpqUcpaUMklKmRQUFGTnEDXtiiFDYNgwFX+Wko4dVbq6szJfQO16NCNhPpM83mMlA+ixfSGB2anN6stoVOGXtWvBKizK5uCDD5yTi6nRNBF7BD0d6NjgeQRw/JQkCZgrhEgDrgX+I4S4yhED1LQzhFCujDExkJWFENC9u5rsOlPUvc3lTE9YwET3D/iDfvRIbb6ou7sr3/Rt20AGBSt7xqVLHTxijabp2CPoa4EuQohoIYQFuB74tmEDKWW0lDJKShkFzAcmSCm/dvRgNe0EiwXuu099LSjAYFChFz+/Bhs2OwEfcznTExdyr/tH/ElfeqYuaLao+/io+qLMLKHM3z//XOXbazRnkdMKupSyGpiIyl7ZDnwhpdwmhBgvhBjv7AFq2in+/vDQQ6quvrwck0llvri61u4a5CR8zGU8m7iQCR4fsZoL6Jm6gKBmiLoQKpVxwwYos7mq3MaPPnLeYoBGYwd25aFLKX+UUnaVUsZIKZ+rfe0dKeUJi6BSytuklPMdPVBNO6RzZ2UPkJEB1dW4usKFF6pDzrQf9zGXMT1hIfd5fFgbfllA8JGtTe7HYlEhovXrwRbcATZvhlWrnDBijcY+dKWo5uxywQVqT9L9+0FKPD2hf39VWe/M6noVU1/IA54fsIIBdN++sFl56p6eyil49x4BoaHwySeQl+eEEWs0p0cLuubsc8UVampeK+r+/krny8qUL7mz8DJX8EzCAh72msVvDKPbX9/QoYkVpXWpjKmpkFfupkIun3zivNVdjeYUaEHXnH0MBrjjDujaVeWoAyEhkJSk7AGcmRHoaapkesJCnvZ5g18YQfed3xHeRO8Xo1FlL65dC1WBYSoGs3atk0as0ZwcLeia1oGLi6okDQxU5Zgot9q6LeycKepuxiqmxS1ghu+/+Zor6bL7f3Q8sLJpfbipuP+WrQIZHAIffug8BzKN5iRoQde0Hry84B//UFPe/HwAoqOPWu46M4HExVjNlLiFvB7wDJ9zPTH7FtNp35ImhU68vVW9VHq+h1oA+OwzHXrRnFG0oGtaF8HB8MgjyuSlqAghoEsX6NFDlds7U9QthhqejP2GT4In8z53EH1gGTG7f7ZblIVQi6QbN0KJdxj88YfamFSjOUNoQde0Pjp1gocfVgpeWlpfTdqtm/NF3ShsTO7+PT+G3clMHqRjxp90/etbhLTvpGazWhJYt8FATUAwzJ7t3GopTdsjMxN++80pXWtB17ROunWDBx6AI0egogIh1N7TZ0LUDUIy8byf2dJpNE8znbAjKXTfOh+DzT5bSE9PNca/0j1Vqs68eTr0olFYrTBrFqxe7ZTutaBrWi+JiUcLjyor60W9e3fnx9SFgFuillPS5Xzu53VC8rbTc9NnGKvtq3jy9oadO+GwKRyWLVPGLxrNzz+rncedhBZ0TevmwgvhzjshPb1e1Hv0UKJeUOB8k8Mrw9YR0DOEm/gU76J0em38BEvl6UMoBoMy8Vq/0UC5Z6Dah9SZngaa1s/+/bBggXKicxJa0DWtn0GD4O9/V6JeVVUfU4+PVzN1Z28aNCQolaSEKq4xfIW5rJC4DR/hVpZz2ve5uKixbdztja2oRHmna85NqqpUqMXDQy20OAkt6Jq2wZAhcPvtarPp2pn6eedBnz5qzdGZFaUAib77ubr3fq42f0dFlYG4DR/hXXjwtO/z8lJp9XsqwtVCmA69nJt8+60qmgsMdOpptKBr2g7DhsFdd6l/jPJyQCXE1NkEONPQCyDa4wh39dnIWLdvSa8JJW7TpwTmbD/le+qsAbZtN5Bv0qGXc5KdO+G771SlHGqynnP6D3jNQgu6pm0xaBDcey9kZSkVR9mRDxyo4unO1soglyIm9/6N+30/YZ3sTc9tXxJ+8I9TZrEYjcoW+M9Ub6pyi2C+NiM9Zygrg3feUWb/JhM2G2zZ4rwPalrQNW2P/v1VSmN2tvIFQNmrDx6swpNFRc7NEnQ3VfH/4n/mlQ4vsZCr6bL3Fzrv/OmUuequrmpmlnIkHNviX3Xo5VxASvjiC7V67+sLqM2tDh1y3t+nFnRN26RPH3j8cTUDys0FVP734MFK3J2d1mgUNiZ0/ZXlMbfxAo8SmbWGrpu+OGVao5cXpGcaOVhWG3opKXHeADVnn02b1LpJbaglIwO2b1d/B85CC7qm7dK1Kzz1lIppZGUBKrOkf3+1d4azM2CEgDER6zDGxTJBvE1g4R5i132MW1nuSdt7e8PGPd4UZRSr2ZsuOGqf5Oerm3ZwMBgMFBXBunVKzIVw3mm1oGvaNhER8PTT6h/nwAGQEqMR4uLg/PPVJLh2/dRpJPvvoV+SlRss87FVVtFr/Yf45u1ttK3JpG46qw+EU7XodxVQ1bQvbDbltllVBZ6eVFaqwlCTyakZi4AWdE17ICBAhV/69FE7N1dXIwRERalsR4NBzdadORmOdM/l1uRUxvvOY5+tE3FbPqPDgTWNntTNDSqqDGzNCsI2613t9dLeWLZMbTYbFobNpmbmFRWq0MzZaEHXtA/c3GD8eBgzRs3Ua+PTvr4wdKjaHa6gwLkhGE9TJRPiV/Bmx5f4lr/Rfd//6LTtBww1JybJe3lBWq4Xh3aVwaef6tBLeyEjQ+1YFRGBRLBtm7IjcmbcvCFa0DXtB6NRCfo//qEEvTaubrFAcjL07q3WUEtKnJhlICTXd17DX7FXM90wlU65G+i6bg6u5fnHtBMCfHxgfVY4hT//oXc4ag9UVcHbb6uUJhcXDhyAXbvU79mZcfOGaEHXtD8SE2H6dOjQAdLS6kMwnTqp2iQfH+fP1vsH7qFrsi/3uH6MS0UhvdZ+gG/2rmPaGI3g6mZg7f4QKt/5QG8u3dZZsEBVMgcFkZurfPG9vVXI70yhBV3TPgkOhieegEsvVSGY2u3gPD1hwADlA1NWpsLXzpqtd3At4LrkNB4L/oC/ZFcSUz8jeMdyhO2oo5irK5QbPEjdUk3N7I+cm2upcR5btsD//gcdO1JSovY2cXNTC6FnEi3omvaLxQJjxyphl1IJu82GwQAxMXDxxRAUpGbrlZVOGoKhmnE9UvilxwO8J+6iZ9ZvRK37Epfygvo2np6QVhnGwe82qgU1TduioAD++18ICqKqxsjq1SrE4uJy5odil6ALIUYJIXYIIXYLIR5r5PiNQojNtY9VQogExw9Vo2km3bvDjBnKHyAtrX6/Ug8P5QPTr5/6B3RmGObC4L149e3BI25v4FueSdza2Xhk7gZq4+m+gi25YRyZ+alaWNO0DWpq4L33oLISm4cX69cr+wkPj7MznNMKuhDCCLwFXAr0BMYJIXoe12wfMFhKGQ88C8xy9EA1mhbh6ancGp98UsU50tLqXRtDQ9VsPS5O5aw7y2c9xLWQUcm5vBjxJqmyO8k75+C/eQnG6koMBnD1cWXbLguF//qv8+0jNY7hp59g82ZkaBhbtqh1eG/vszcce2bofYHdUsq9UsoqYC5wZcMGUspVUsq6ZfzVQIRjh6nROIhu3eDZZ1UoJjdXLWLV1GA0qjDMiBFqQl9W5pxKU6OQjIjZw+bzb+Ut0wPE5q/gvNWfYM7LwmyGcs9gdv2SRvmX3zn2xBrHs3u3qvbt2JE9ewV79pzZjJbGsCdkHw40NH5OBy44Rfu/A/9r7IAQ4m7gboDIyEg7h6jROBiLRS2W9u+vfKp/+029FhKCi4uR7t0hOlrVKO3erUTdzc2xMdHzvLOp6h/EjB2vc/ORf9Nvy7v8GXg5hh7xZFZ2xH3mN3RLjMXYs5vjTtpUbDZ1ZysrUx9dKipUap7Vqn4odavJQhwtgzSbVQWNu7uKO7i6nl2FcxbFxfDmm+DnR2aOmS1blJifyYyWxrBH0Bv7bTSaFyCEGIoS9IsaOy6lnEVtOCYpKUlXUmjOLr6+cMstcMkl8MMPsGqVEqaQEFxcTHTvrmbtGRnKJa+gQKUaeng45h/XYqhmcI9slnR4EI9ta7g+Zw5pq7axt9tlHKjyx/zIf+gyd4bzqlKkVB9DcnJUymROjtoV6vBh9bygQIlx3aNhOlDd9w1FHdQPpu41m03dKIODVQppVJTafi04WD3OdAqIo7DZ4IMPoKSEPPcI1qxRfxNG49keGAh5mpwtIUR/YJqUcmTt88cBpJT/PK5dPPAVcKmUcufpTpyUlCTXrVvX3HFrNI4nK0vFRJcvV/+0QUH19dpSKo3bv19pns2mJqNubo4Rd6vNyJadLlx7+E3COcQyn78h/HzodE0y0f+6r2WzXCmVOB8+rB779qk1hIyMozElKUEIpIsrNWZXrAYXqg0WrNWC6mq1plBdra7bZlPPG0qH0ah+DgaD0um6h8VQjYuswFRdgSgvO/oGg0E5qMXFqa2noqPVbL4t8OOPMHcuJUHRLF0m6v3u7aaoCAIDGfLLE806vRBivZQyqdFjdgi6CdgJXAwcAtYCN0gptzVoEwn8BtwipVxlz6C0oGtaLUVFKpH4xx/V92azEvdaZ6W6HWcOHFD6CEpv6/KOW6K9WcXuGLdu4rqqzzgkwtnkN5iOk8dS8+K/CVs2j+D4DqfuwGpVteZZWWqAO3cq8a6owIbAWimpMrhQYfCgXLhTVmmktPTYqIrN1vg1HC8VDds0PHb8e6VU+u3hoT5seHuDt0cNXhTjVlOEyVD7pi5dVNpRr15qq7bWGKrZuROef54K/zCWrbZgtTYjo+VsCnptB5cBrwJGYLaU8jkhxHgAKeU7Qoj3gGuA/bVvqT7ZCevQgq5p9dTUqCD6qlVK4Kur1VQ0IKB+Sma1qizII0fUhLd2EyWEUNEGs1m9pSnaJCXs2W9iwIHP6CG3s59IIjjI8i5/Z8jOd482Ki1Vwp2Vhdy9B+tfu6nefwirFaoqocJqoLjGg4JqT4orzCds0Vc7KcdkUmOsezgjDmyzqR9fdbX6mdWdG5TABwfaCLIU4i2KcHVBbUM1dKiyzAwIcPyAmkNBATz9NFZMrNziQ3FxM6NhZ1vQnYEWdE2borIS9uyBlBT488+jJaYWi/qvdndHCgOVler/NT9fJdEUFKgZfZ141c1WDYaj4tkwTF2HlHDRqhdw48SKp3JcOXTpndgKSyivMlBVYaPUaqHc6IXVrMZRJ5hG49HwR1NvLGcCKdXPp7JSfS8leHpIOvkXE+RSgLeHxBDb42heqcVydgZaXQ3//jfVO3ez5mA42dlqEbRZaEHXaFoRUqrt7/bvh9RU9TE8M/OoWtpsSj0tFqTRhBUzFVYjFVWCikpBebmgqsJGZYWN6kob0lqNtFoR1dUYbVZkrbqXVRiR+9PoZ12Ge62wl+LOl+634B0diIurAaNJOHVmfaaRUs3gy8vV9yajpLNvHqFexXiHeWIcNQIuukhtS3UmB/XFF9i+/5H1uVEcyhAtS090oqC30WVmjeYsIsTRTI3kZPVadbUS+brskCNHICcHUVyMpbgYS0UF3nWri1KqWIzJrHIhPT1V3MHHR8Xqvb3VrN/Pj2WDn8Zl+6+U44qFSspx47ayd9iUmsjy0OvoGmPDbHCiy9gZpi5UVTcRr6kR7CkIYGduAG77K+iy/WtC5nyN+6hBiJEjVGjG2axdi+27H9hW0on0QwJf39b3SacOLegajSMwmVTJaWioQ7s1FxxhRex4Ojx9F4ceex3TwX2U+HXk/NxfmZjxJEszh/Bn6JXEdS7DzVjl0HO3BozGo3Hq6mpXthREsiW3hsg9K+m44Hd8hydjuvYqlQ7pDA4eRP53FruKO7Brn7FViznokItG06YoTdnFX7c8RzbBuOWmE5f5M/4yj5/EKP4IvoL46FICXNr35tNSqmycygobQdVZRIVVEXDFhbj+35UQEuK4ExUVIadPJ+2vSjYeCMDX10FhLR1D12g0dRQuWMzOpz4m2zMKL9dqzHu20yNrCT6ykN8Yys++Y4mKEnT3zmjVs0lHYLVCWYkNv6osIkOrCb55BO7XXt7yYiyrFV55hUNLd/FnegQ+Pi0vHDLUWPEtSMP/cCoFYbH0Svm0Wf3oGLpG047wufpiYnbtofKDPyk1ReLSNYHNMT1w35/K+YdWMKxgCRtTEvnM5XaMkeEMCt6Bu6n9hWNALUX4+Bmw1oSxJbcavxd+IXze74RMvA73UYObV40qJcybR+ZvqfyZEYWPbzPFXErcy7Lxz9uDf/4efAr3Y7RVUyOMVPkEN6PD06Nn6BpNW6S8nNx/zGDz73lY/ULqFxENtmp8M1IJOrie0KoDZBDKh9zOtsBB9AnLIsE3DaNov64bNTVQkV+Of1UWIUkRRDx5G5bYLk3r5PffyXr+fVZnReHpbWzSPcFSWYxfwV788vfhl78Xlyq1AXipeyB5fjHk+Z9HocEfW3AHHXLRaDQNOHyY3PunsXabG0Zf77pCVoWU+OXtwefAZiKLtiIR/MDlfGkaR1VwBAODd9LTOx1DOxX36mqw5eThZygg+LohRD58HcLbjjDMtm1k/eMl1h4Kw83X5bRibraW4VOQhl/BPnwL0vAoywHAanIj3y+aPL8Y8v1iqHQ9mrReVVCG1T+Yy3+b3Kxr04Ku0bRX/vqLnMkv8Eda6EkFyLU8n+CMFIIyN+FVU0g2gXzOOH4wXok50IcBQTtJ9N2Hm7H9ebBXVdiw5KTjHexOx6m3EzSi98nTVNLTOXTPdDbt9cIS4NXoz9JSWYxP4QF8C/fjU7gfz9IjANQYzBT4dqLAN4ojPl3YbexGVqU/mRW+HK7wJavuUelLXpUXN0ev4OO9jXoYnhYt6BpNe+a33zjy4gesyozG09tw0lmlkDb88nYTmLmFoLwdmKWVA3TkC/6P7xlNiU84ffzTSPRNo4tnJiZD+9jfVEqoyi/Bs+wIHkP70mPGTbiE+HI4JZPMIdcTtmweQREu7P/7M+zcXoMxKEDFzKUNj9JsfIoO4l10EJ/Cg7hVqG0frAYL6e5d2e6SyFpTP1bZ+nGoMpisCl9yq479JGAUNYS4FNLBtUA9RBaJETncv+aWZl2PFnSNpj0jJcyZw+FPF7EqIwovb3HaUIGxuoLA3B0EHknFP38PRllDLv58z2h+YhQrxCA6+JYT651Od69D9PA+hI+57NSdtnJqqiXGwxlYPC2ET7uTtCdmcVHqLJZ2upnwhGByNqXj5VqNW8kRPAozCCg7iItNGeDkiQDWG5P5XQ7il5pLSCGRalSMy4CNEFcl2CGuBYS65qvvXQoJdc0nwKX42HULnbao0WhOSXU1vPEGmYu2sPpQJF5e9id4GKsr8M/bQ2DuDvxyd2OpKQdgqyGORbaLWc5AVnARwsWFGI8sYjwPE+VxhEi3HCLcc9tMqMYmBQVWdy794+lGPXLqqMJMCon8yQWsoS9ruIBSV3+CXYvqZ9kNZ9yBLsUYRRM+zWhB12g0p6WsDF58kcyULFanheLpybELpfYgbXgVZ+KXvwe//H14F6djtClrgQxDBBtEb5bWXMRGzmcrvThMCIGW4tqZaQHBLoUEuhQR6FKMv7kEH3MZPuYyPEyVDl2AtUlBRY2ZkmpXSqpdKa52o6jajSKrO0VWNwqsHlRV1uBdkYN/VSZh1gN0su2lJ6l0Ywdmjtol1GAgjSj+53Y1Bz17UO4RhL97OSEuhQS7FOJnKXXs4rEWdI1GYxf5+fDssxw+WMUfuwJxd2+ZQaGwVeNVnIlP4QG8ijPwLj6Ea2Vh/fFigw/7jdHs5jxSbd3ZWtOD/XTiIB3JJLQ+LCGQuBsrcTdV4maswsVQjaX2YRQ2DNgwCIkEpBTYENRII9U2A1ZppMpmpqLGTJXNRFmNCzU1kkByCCODMDII5xCRHCCKNDqxnxj2EERO/ThrMJBtCiXbEk6hexgu+Vn0rvmTKixYsPKz5W+4XZCAMJyBSiwt6BqNxm4yMmDGDLILLaxK9cXFxbGbAZmrSvEoPVL7OIx7eS5u5Xm4VJ1oOVBm8KTI6EuR8KVEeFEkvCnGi3LcKJduVEgXbBioxohEYKIaM1bM0oo7ZbhRhgeleFOElyzCWxbiYyvAXZaecK4aYaLM4kulqzeVbr5UuPtT7upPuXsAZW7+SIOKQVVVSlzWLKPCKwiXyy6m8peluJVkYwgLpSooHIObAzePbQwt6BqNpkns2wfPP09+jTertqisiybvrNNEjDVVuFQU4FpZhEtFIZaqYizWMszWUszWckzVFRhrKjFVVyJkDQZbNQZb9TGbFktACiNSGKgxmrEZzNQYLVSbXOsfVrMbVWYPrGYPqly8qLR4UeXiRZXZ47TOWeVlEq+CA0RdHkvEC/fX7/wtbZLt7ywl/7WPqLR4YQhwoj2vts/VaDRNIjoaHn4Yv5deYkiygZUpHhQVKYsTZ/m71BgtlHkEU+bRjLL24zebdjBSQkmxJLDiIN2u7o7/tIn1Yg4gDIKeE4aQnRzFrklvYD2UTk2HcAzGtmWG0w4s8TUaTaN07w6TJuFRnsOgpFJ8faGw8MS9QVsFx2/Z5EBsNijIl0SKAyRccx7+U+4/aQwqKDmKpO+m4Z4ci+XQPmoq25bXvBZ0jaY9k5AADz6Ia3EOFyaU0qmT2n+jum3pVLOxWpWYx/keIPa6nrg/8RC4u5/yPZYAL5I+foCAu67GNfsANUUnxutbK1rQNZr2Tq2omwpySOxSSmIilJRwwqbR7Y2SEhUzv6hjGjFXJ2B66AFwc7PrvcJkpMfjVxH9+j9wsxZiO5LTOj/ZHIcWdI3mXCAhAR56CJGfR7R/IQMHqpdbbQimBdhsKnvTy72GS87bR/Df+iEmTDgmZm4vYZcl0uuLqbgHuCEy0rHVtO4flhZ0jeZcIT4eHn8cyssJIJehQ9WOee0pBFNerm5S3TpXcVHHNNzHjIK7725RMr53j3D6fDMFjz7dMR9Kw2atceCIHYsWdI3mXOK88+Cpp8BgwKXgMMnJcP75qsi0uLjtztZratSNyWyGoReU0dMrHeMtN8G4cS3faggw+3uR9MmD+IwdiSVzPzVlJ7cOOJvYJehCiFFCiB1CiN1CiMcaOS6EEK/XHt8shOjt+KFqNBqHEBEBTz8NgYGIgweI6iS5+GIIDFSiWNWGNjeSUt2ISkqgWzcYEpeLry0PHngARo50aOaMMJuIf34cIU/cgWtBJrbCYof17ShOK+hCCCPwFnAp0BMYJ4ToeVyzS4EutY+7gbcdPE6NRuNIAgPhiSegTx/Ytw8Pl2r69YPkZBV+KShQs97WTHm5GmdgIFw8TNLDKx2TuwWmToWkRutuWo4QdLlzCFFvP4rFWoLMyTn9e84g9szQ+wK7pZR7pZRVwFzgyuPaXAl8LBWrAV8hRKiDx6rRaByJmxuMHw9jxsCBA4iSYiIiYPhwlcJeUqKKGm2tzBa9okIteloscOGF0K93FZ7Z+9Sgp06Fjh2dPobwi3vQ4/OpGN1dMGQeQtpaR6zKHkEPBw42eJ5e+1pT22g0mtaG0agE/ZFHlFJmZGA2Sbp3V8IeGalEvbDw7M7YpVRx/vx8NeQLLoChQyHEnIfIzIDrr4eHHgJv7zM2poC4MM5fOAVbZCdMGQdahajbI+iNBaGOH7k9bRBC3C2EWCeEWJednW3P+DQazZkgLg5mzFCLpvv2QUUF7u6QmAgjRkBMDJSWqhBHZeWZWzytrj56Q/HyUjPyiy+GsOBqDAf3q2n6lClw2WUOWfxsKl4RPvRf8AjVvftiPrT3rMep7PFySQcafoaJADKa0QYp5SxgFihzriaNVKPROBc/P3j4YVi2DD77TC0ohobi7i7o1Qu6doXMTNi9WwmsEKqC3mJxbNV+dbWKj9fUqE06oqNVFMXHp/Y8OTlqJfTyy+Fvf7O7WMhZuHi7MPCTu1n+YADmn76jJjQCaXGyY+NJsEfQ1wJdhBDRwCHgeuCG49p8C0wUQswFLgAKpZSZDh2pRqNxPkajimXExcHHH0NKCgQEgI8PFgt06nQ0DHP4MBw4oL4HJbYuLip10GBnQrSUqjy/qkoJuRDq/R07qhz5wMAGE++SEjhyRA1i8mSIinLCD6B5mFyMDH7zOpY9E4jx0w+RwSHYXJ1sb9nYOE7XQEpZLYSYCPwMGIHZUsptQojxtcffAX4ELgN2A2XA7c4bskajcTqBgSomvWWLmq2npUFQEHh4IISaLfv4QJcuR4t5cnMhO1vp7vELqVI2PouXEjw9VSalvz/4+jbiCFlRAVlZ6oTjx0Pfvvbvr3cGMRgFg58ZxrJAf+Rrb2Dyr6baw+eMjkH7oWs0mlNTXQ1//AHz5yvl9vVtEP84ESnVjLu8XL21ulqFT4RQM3eDQYVpXFzU46Sz+aIiyMtTZlpXXAFDhjh2pw4nISX88ekeyp79N+6egirvoGMbaD90jUZz1jCZYOBA6NdPhWC++UbFWoxGNWs/ziOlLvTSDOsUdSfIzlZ3gaAguOsulVPerM7ODkLAhTfH8KfX0+Q+8TL+tkwqfM9MFrcWdI1GYx9ms6o8SkqCvXth7VpYvlxNxUGlDHp72x9ABxWbKS5WM39QU/fBg1VeYkxM0/pqZVxwVSjrPJ4i/eGZhOUepMw/wnm7i9SiBV2j0TQNIZTYxsTAtdcqcd+1S83e9+492q4ukG40KmG22Y6ufDYUtuhouOQSFZCPimrZrtatjKThfhjeepSdD/2HmJxtlAZ2cur5tKBrNJrmYzKpfMauXVUaodWq4t65uaoKqKxMPSoqVNjE01OlGfr5qYVXf/9WucDpSHoP9MD49iQ2TvqAXjkrKbP44azi2/b9k9RoNGcWsxlCQtRDU09CsgXevJM/HvQkOf0rioOc8/PRgq7RaDRngITeRnj9Bn550IdY90NOOYcWdI1GozlDJCQKeG00u3c5J11cC7pGo9GcQRISICHBOdkubTcnSKPRaDTHoAVdo9Fo2gla0DUajaadoAVdo9Fo2gla0DUajaadoAVdo9Fo2gla0DUajaadoAVdo9Fo2glnbYMLIUQ2sL+Zbw8Echw4nLaAvuZzA33N5wYtueZOUsqgxg6cNUFvCUKIdSfbsaO9oq/53EBf87mBs65Zh1w0Go2mnaAFXaPRaNoJbVXQZ53tAZwF9DWfG+hrPjdwyjW3yRi6RqPRaE6krc7QNRqNRnMcrVrQhRCjhBA7hBC7hRCPNXJcCCFerz2+WQjR+2yM05HYcc031l7rZiHEKiFEwtkYpyM53TU3aJcshKgRQlx7JsfnDOy5ZiHEECFEihBimxBi6Zkeo6Ox42/bRwjxnRBiU+013342xukohBCzhRBHhBBbT3Lc8folpWyVD8AI7AE6AxZgE9DzuDaXAf8DBNAP+PNsj/sMXPOFgF/t95eeC9fcoN1vwI/AtWd73Gfg9+wLpAKRtc+Dz/a4z8A1PwG8WPt9EJAHWM722FtwzYOA3sDWkxx3uH615hl6X2C3lHKvlLIKmAtceVybK4GPpWI14CuECD3TA3Ugp71mKeUqKWV+7dPVQMQZHqOjsef3DHA/sAA4ciYH5yTsueYbgIVSygMAUsq2ft32XLMEvIQQAvBECXr1mR2m45BSLkNdw8lwuH61ZkEPBw42eJ5e+1pT27Qlmno9f0fd4dsyp71mIUQ4MAZ45wyOy5nY83vuCvgJIX4XQqwXQtxyxkbnHOy55jeBHkAGsAWYJKW0nZnhnRUcrl+teU/RxjbdOz4lx542bQm7r0cIMRQl6Bc5dUTOx55rfhV4VEpZoyZvbR57rtkE9AEuBtyAP4QQq6WUO509OCdhzzWPBFKAYUAMsEgIsVxKWeTksZ0tHK5frVnQ04GODZ5HoO7cTW3TlrDreoQQ8cB7wKVSytwzNDZnYc81JwFza8U8ELhMCFEtpfz6jIzQ8dj7t50jpSwFSoUQy4AEoK0Kuj3XfDvwglQB5t1CiH1Ad2DNmRniGcfh+tWaQy5rgS5CiGghhAW4Hvj2uDbfArfUrhb3AwqllJlneqAO5LTXLISIBBYCN7fh2VpDTnvNUspoKWWUlDIKmA9MaMNiDvb9bX8DDBRCmIQQ7sAFwPYzPE5HYs81H0B9IkEIEQJ0A/ae0VGeWRyuX612hi6lrBZCTAR+Rq2Qz5ZSbhNCjK89/g4q4+EyYDdQhrrDt1nsvOYpQADwn9oZa7Vsw8ZGdl5zu8Kea5ZSbhdC/ARsBmzAe1LKRtPf2gJ2/p6fBT4UQmxBhSMelVK2WRdGIcTnwBAgUAiRDkwFzOA8/dKVohqNRtNOaM0hF41Go9E0AS3oGo1G007Qgq7RaDTtBC3oGo1G007Qgq7RaDTtBC3oGo1G007Qgq7RaDTtBC3oGo1G0074/5YBAP07auNZAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device,\n",
        "    randomize_params=False)\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "model.likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "true_noise = model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(25.9502)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.1626]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.0303, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(7.0973, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.6044]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUoUlEQVR4nO3df2ydV33H8c83rtvdFoTL4jHq4qWrtsAgawMeVHhCtPuR0rIROhgwukkIKZq0TTChjBShsWlDDYrYysQ2FHUVQ7DCNooFlJGhha5boQWHlKZQMhUKXZ1Jddd6sMYjjvPdH/fe2L6+9z7nOs+P7+P7fklVE98n9repn4/P/Z7znGPuLgBAXFuqLgAA0B9BDQDBEdQAEBxBDQDBEdQAENx5RXzSrVu3+rZt24r41ACwKR05cuQJdx/v9lohQb1t2zbNzs4W8akBYFMys+/1eo3WBwAER1ADQHAENQAER1ADQHAENQAEV8iqj7zNHJ3TgUPHdWJhUZeMNbR313bt3jlRdVkAUIrwQT1zdE433XFMi0vLkqS5hUXddMcxSSKsAQyF8K2PA4eOnw3ptsWlZR04dLyiigCgXOGD+sTC4kAfB4DNJnxQXzLWGOjjALDZhA/qvbu2qzE6suZjjdER7d21vaKKAKBc4ScT2xOGrPoAMKzCB7XUDGuCGcCwCt/6AIBhR1ADQHAENQAER1ADQHAENQAER1ADQHAENQAER1ADQHAENQAEl/Rkopl9V9IPJC1LOu3uU0UWBQBYMcgj5Fe7+xOFVQIA6IrWBwAElxrULumfzeyIme3pdoGZ7TGzWTObnZ+fz69CABhyqUE97e4vlvQqSb9jZq/ovMDdD7r7lLtPjY+P51okAAyzpKB29xOtfz8u6VOSXlpkUQCAFZlBbWYXmdkz27+W9MuSHiy6MABAU8qqj+dI+pSZta//O3f/fKFVAQDOygxqd/+OpCtKqAUA0AXL8wAgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEguEGO4sKAZo7O6cCh4zqxsKhLxhrau2u7du+cqLosADVDUBdk5uicbrrjmBaXliVJcwuLuumOY5JEWAMYCK2Pghw4dPxsSLctLi3rwKHjFVUEoK4I6oKcWFgc6OMA0AtBXZBLxhoDfRwAeiGoC7J313Y1RkfWfKwxOqK9u7ZXVBEwmJmjc5ref1iX7btT0/sPa+boXNUlDS0mEwvSnjBk1QfqiMnwWAjqAu3eOcE3NWqp32Q439Plo/UBYB0mw2MhqAGsw2R4LAQ1gHWYDI+FHjWAdZgMj4WgBtAVk+Fx0PoAgOAIagAIjqAGgOCSg9rMRszsqJl9tsiCAABrDTKifpukh4oqBADQXVJQm9mlkq6XdGux5QAAOqWOqG+R9AeSzvS6wMz2mNmsmc3Oz8/nURsAQAlBbWavlvS4ux/pd527H3T3KXefGh8fz61AABh2KSPqaUm/ambflfRxSdeY2UcLrQoAcFZmULv7Te5+qbtvk/RGSYfd/cbCKwMASGIdNQCEN9BeH+5+l6S7CqkEANAVmzLlZOboHDuNASgEQZ0DzpcDUCR61Dnod74cAJwrgjoHnC8HoEi0PnJwyVhDc11CufN8uWh97Gj1AOiOEXUOUs6Xa/ex5xYW5VrpY88cnSu52pj1AOiNoM7B7p0TuvmGHZoYa8gkTYw1dPMNO9aMTqP1saPVA6C3oW195P22P+t8uWh97Gj1AOhtKEfUVbzt7+xXZ328aNHqAdDbUAZ1FW/7U/rYZYpWD4DehrL1UcXb/nZbJMoqi2j1AOhtKIM6dTld3rL62GWLVg+A7oay9cHbfgB1MpQjat72A6iToQxqibf9AOpjKFsfAFAnBDUABEdQA0BwBDUABEdQA0BwBDUABEdQA0BwBDUABEdQA0BwBDUABEdQA0BwQ7vXRwScAg4gRWZQm9mPSLpb0gWt6//R3d9TdGGp6hp27ePA2ifNtI8Dk1SL+gGUJ6X18UNJ17j7FZKulHStmV1VaFWJqjj7MC+cAg4gVWZQe9P/tn472vrHC60qUZ3DjlPAAaRKmkw0sxEzu1/S45K+4O73dblmj5nNmtns/Px8zmV2V+ew4xRwAKmSgtrdl939SkmXSnqpmb2oyzUH3X3K3afGx8dzLrO7Oocdx4EBSDXQ8jx3X5B0l6RriyhmUHUOu907J3TzDTs0MdaQSZoYa+jmG3YwkQhgnZRVH+OSltx9wcwakn5R0vsKryxB3c8+5DgwAClS1lE/V9LfmtmImiPwv3f3zxZbVjrCDsBmlxnU7v6ApJ0l1AIA6IJHyAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEgOIIaAIIjqAEguJRtTnGO6npSOoAYCOqCtU9Kbx/C2z4pXRJhDSAJQV2wfiel1zWoeYcAlIugLlidT0rvhncIQPmYTCxYnU9K76bfOwQAxSCoC1bnk9K72WzvEIA6IKgLtnvnhG6+YYcmxhoySRNjDd18w47atgk22zsEoA7oUZdgM52UvnfX9jU9aqne7xCAOiCoMZD2DxxWfQDlIagxsM30DgGoA3rUABAcQQ0AwRHUABAcQQ0AwWVOJprZ8yR9RNKPSzoj6aC7f6DowqJinwsAZUtZ9XFa0jvc/Wtm9kxJR8zsC+7+zYJrCyfPfS4IfACpMlsf7v5f7v611q9/IOkhSUOZKHntc9EO/LmFRblWAn/m6FyO1QLYLAbqUZvZNkk7Jd1XSDXB5bXPBRsbARhEclCb2TMkfVLS2939+11e32Nms2Y2Oz8/n2eNYeS1zwUbGwEYRFJQm9momiH9MXe/o9s17n7Q3afcfWp8fDzPGsPIayc8NjYCMIjMoDYzk/Q3kh5y9z8rvqS48toJb7NtfQqgWCmrPqYl/aakY2Z2f+tj73L3zxVWVWB57HPBxkYABpEZ1O7+75KshFqGChsbAUjFk4kAEBxBDQDBEdQAEBxBDQDBEdQAEBxBDQDBEdQAEByH2wLAOSp622KCGgDOQZ771PdSu6Bmw30AkfTbtniogrodznMLizJJ3vp4ET+5AGAQZWxbHH4ycfVpKNJKSLf12nB/5uicpvcf1mX77tT0/sOcngKgEGVsWxx2RL16FJ2l8ydXGT0jAJCa2xavzhsp/22LQ46oO0fRWTp/cnHUFYCy5LVPfT8hR9TdgraXbj+5OOoKQJmK3rY45Ig6K1Dbm2P3+snFUVcANpOQI+pLxho92x4TCUvyiuoZVbU0kCWJwHALGdS9gja175PXUVerA/JZjVE9feq0lpab6076TVDmGaxMjAIw984Fb+duamrKZ2dnB/5zncFoJi2cXKpkFNkZkL1MjDV0z75r+v65QX7IdJref7jru4vOrwug3szsiLtPdXstzIi6M+AWFpfUGB3Rn7/hykpGjqkTmp399F4rTv74M9/Y0H8HE6MAwkwmRltSlxqEnROUvf7cUyeXNvTQDROjAMIEdbSR49iFo5nXrJ6gbD8J2a+RtJEnKPfu2q7G6EjPrwtg8wvT+ui10qOqkWOv1r21NhtZ3TdP7WfPLSxqev/hs5OMVz9/XJ88Mtd3ojCviVEA9RUmqMt4DHMQ/7O41P0Flx7Zf/2aD6X2s006+8NobmFRH7v30Z57l6wO4qIX0wOILUxQRxs5DjLCT2nPrN71r61XmyTr87GuGhguYYJayh45lhlQg4zwe4X6iJnOuPd9gKebfu0e1lUDwyfMZGKW1Rs1uVYCqqjtSwfZaKXXhN/7f/0KPbL/et2z7xpN9Ahf6/h9Vrsn2uoYAMULNaLup4xTFDql9oZT2ja9Rui/9pIJffFb88nvEqKtjgFQvMygNrPbJL1a0uPu/qLiS+ouekBlhXpePfhoq2MAFC9lRP1hSR+U9JFiS+lvMwRUHqs3oq2OAVC8zB61u98t6ckSaumLBz+aytikHEAsufWozWyPpD2SNDk5mdenPSva8r0qsa4aGC5Ju+eZ2TZJn03tUW909zwAGFb9ds+rzfI8ABhWtVme14mn8wAMi8wRtZndLunLkrab2WNm9tbiy+qv7IdfAKBKmSNqd39TGYUMooqHXwCgKrVqfbTbHb32zYjy8AsA5Kk2QZ2y53OdHn4BgFRhg7pzsvDkqdN9Q3oYH34BMBxCLs/rNln41MkeG/lLuvjCUV1w3hb9/ifu73qcFQDUWcgRdeqJKZJ00fkj+r+lM+zPDGDTChnUg0wKPn1qfaCzAiQd69GB+EK2PvKYFGQFSDbWowP1EDKo85gUZAVINk6LAeohZFDv3jmhiy8cTb5+0OOsopk5Oqfp/Yd12b47S50MjX4YA4CmkEEtSe/5lReu23+6m8boiN581WRt92eusv3Q610H70aAWEJOJkorKzbe/on7e14zsQkmv6p8HJ7TYoB6CDuilpph3ev07hGz2oe0VG37gdNigHoIO6Ju6zbqk6Rl93NaLx1lWVrVZ0FyWgwQX+gRtbQy6huxzinDja9QiLQsjbMgAWQJH9RSM6zP9DgybCMtgkjL0mg/AMgSvvXRlmeLINqyNNoPAPqpxYhayrdFwLI0AHVSm6DOs0VAXxhAndSm9SHl1yJof44Iqz5SRVmlAqB8tQpqae1xXCNmWnbf0IMvdeoLd55uw1auwHCpVVB3BtZyayVI5ODKGgmnjJQ5zBcYbrXpUUv9DxSIuOtb1nrt1PXc0VapAChXrYI6K5iiBVfWeu3U9dysUgGGW62COiuYNhJcRW4xmjUSTh0pd1ulIkknT50u9GnKqrZfBbBWrYK6V2BJ0ugW08lTpwcKlaIfJc8aCaeOlNtLE8caa/fofurkUmGPvlf9mD0/JIAVtQrq1WupJZ3d/2OsMSpZM7gGCZWiHyXPWq89yHru3TsndNEF6+d+i+rNV/mYfdU/JIBoarXqQ+q+rG56/2EtLC6t+VjKqoiiJ+my1msPup67zEnFKicwWeUCrGXeY7OjNReZXSvpA5JGJN3q7vv7XT81NeWzs7MDFbJt350DXY9s05c/W6+fmly37nysMarFpWX98PSZNddPjDV09fPH9cVvzXfdV6Vti0lnvP/BDVnLDt89c0wfu/dRtb/7Ljp/RO99bfNJ08v23alu35Um6ZH912/gb2K9fvXl+XBR0Q8q8SDU5mFmR9x9qttrmSNqMxuR9JeSfknSY5K+amafdvdv5lUgIV2Me779pO759pNnf99ed9757qNtbmFRH7330czPe8ZXru+2fj3rAZ13zxxb93WePrWsd/zD1yUVv0d3v/ok5fZwUdEPKvEg1PBI6VG/VNLD7v4ddz8l6eOSXlNsWaiLbn3rrP727ff9Z9fPtXzGdeDQ8cL3YulXX569+aL7/JG260WxUnrUE5JW31mPSXpZ50VmtkfSHkmanJzMpTjUQ2ffOqu/vdyn3XZiYbHwvVg20n/fSG++6D4/D0INj5SgXn+0ita3EN39oKSDUrNHfY51oUY6WxJZrYt2r7zf5ypyL5as+vJquxTdwqn6GDeUJ6X18Zik5636/aWSThRTDuqmW0siq3Xxppc9T92MbLFStprtV1+ebZeiWzhs1zs8UoL6q5J+yswuM7PzJb1R0qfzLOK7Oc3kD4MtJt141aRuvGqy61ud1aYvf7ZuecOVXdedX3De+v/1E2MN3XjV5Nk9v8cao7r4wuZDNqu/1hZbub7bnuBZe4f/6e4d6+q/6PwRvf/1V5QyCdavvjz3PS/6mDWOcRseqcvzrpN0i5rL825z9/f2u34jy/MAYJid0/I8SXL3z0n6XK5VAQCS1OoRcgAYRgQ1AARHUANAcAQ1AASXtOpj4E9qNi/pexv841slPZFjOUWqU60S9RapTrVK9aq3TrVKG6/3J9x9vNsLhQT1uTCz2V5LVKKpU60S9RapTrVK9aq3TrVKxdRL6wMAgiOoASC4iEF9sOoCBlCnWiXqLVKdapXqVW+dapUKqDdcjxoAsFbEETUAYBWCGgCCqySozexaMztuZg+b2b4ur5uZ/UXr9QfM7MVV1Lmqnqx639yq8wEz+5KZXVFFnavq6Vvvqut+zsyWzex1ZdbXUUNmrWb2SjO738y+YWb/WnaNHbVkfS88y8w+Y2Zfb9X7lirqbNVym5k9bmYP9ng9zH2WUGu0e6xvvauuy+cec/dS/1Fzq9RvS/pJSedL+rqkn+m45jpJ/6TmNshXSbqv7DoHrPflki5u/fpV0etddd1hNXdFfF3UWiWNSfqmpMnW738s8t+tpHdJel/r1+OSnpR0fkX1vkLSiyU92OP1SPdZVq1h7rGUeld9v+Ryj1Uxok45LPc1kj7iTfdKGjOz55ZdaEtmve7+JXd/qvXbe9U8BacqqYcR/56kT0p6vMziOqTU+huS7nD3RyXJ3aPX65KeaWYm6RlqBvXpcstsFeJ+d+vr9xLmPsuqNdg9lvJ3K+V4j1UR1N0Oy+08kiLlmrIMWstb1RylVCWzXjObkPRaSR8qsa5uUv5uf1rSxWZ2l5kdMbPfKq269VLq/aCkF6h5XN0xSW9z9zPllDewSPfZIKq+xzLlfY8lHRyQs5TDcpMO1C1Jci1mdrWa30Q/X2hF/aXUe4ukd7r7slnWgV6FSqn1PEkvkfQLkhqSvmxm97r7fxRdXBcp9e6SdL+kayRdLukLZvZv7v79gmvbiEj3WZIg91iKW5TjPVZFUKcclhvpQN2kWszsZyXdKulV7v7fJdXWTUq9U5I+3voG2irpOjM77e4zpVS4IvV74Ql3f1rS02Z2t6QrJFUR1Cn1vkXSfm82KR82s0ckPV/SV8opcSCR7rNMge6xFPneYxU04c+T9B1Jl2llQuaFHddcr7WTHF+pcNIgpd5JSQ9LenlVdQ5Sb8f1H1Z1k4kpf7cvkPQvrWsvlPSgpBcFrvevJf1R69fPkTQnaWuF3w/b1HuCLsx9llBrmHsspd6O6875Hit9RO3up83sdyUd0sphud8ws99uvf4hNWdJr2v9jzmp5iilEon1/qGkH5X0V62foKe9ot2+EusNIaVWd3/IzD4v6QFJZyTd6u59l0RVWa+kP5H0YTM7pmYAvtPdK9mi08xul/RKSVvN7DFJ75E0uqrWMPdZQq1h7jEpqd58v14r8QEAQfFkIgAER1ADQHAENQAER1ADQHAENQAER1ADQHAENQAE9/9g4RCzOcK1hwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 100)\n",
        "function_samples_dataset.save('test')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([25, 6]) torch.Size([25])\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([16, 6]) torch.Size([16])\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "torch.Size([36, 6]) torch.Size([36])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "torch.Size([22, 6]) torch.Size([22])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.7515, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2738,  0.1005, -0.0165, -1.3715, -0.3896, -0.5113]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(23.0031, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0501, -1.2738, -0.3901, -1.5378, -0.3554, -0.9313]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.4107, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.1873, -1.0822, -0.9720,  0.3895, -1.8195, -0.7942]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.4552, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8715, -0.7563, -1.9962,  0.3406, -1.3481, -1.3639]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.7275, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7267, -0.0601, -0.3362, -0.0522, -0.4599,  0.0694]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.8934, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.1963,  0.8783, -1.1001, -2.2270, -1.0603, -1.4609]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(2.9053, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.5863, -0.8679,  0.8952, -0.3738, -1.4301, -1.2107]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(3.8494, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.1173, -1.5392, -2.3209, -1.9974, -0.4123,  0.4334]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.0844, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4966, -1.4197, -0.4233, -0.1163, -1.5528, -1.2228]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(29.5562, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8981, -0.0556,  0.7221, -0.7472, -1.0052,  0.0350]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(26.4354, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.7095,  1.0966, -0.4885, -0.6091, -1.4057, -0.3684]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.1059, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0928, -0.8568, -1.9886, -0.8789, -0.3097, -1.2336]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.7868, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.3215, -1.9727, -0.9548, -0.9040, -0.6960, -0.6197]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "13 13\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m aq1\u001b[38;5;241m.\u001b[39mget_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#           hist_mask if hist_mask is None else hist_mask.shape,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#           cand_mask if cand_mask is None else cand_mask.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     print([type(model) for model in models])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     print()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = TrainAcquisitionFunctionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
