{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000],\n",
              "        [0.5000],\n",
              "        [1.0000],\n",
              "        [1.5000],\n",
              "        [2.0000]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.linspace(0, 2, 5).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3890],\n",
              "        [0.2284],\n",
              "        [0.2776],\n",
              "        [0.0168],\n",
              "        [0.9678]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5187,  0.6291],\n",
            "        [ 0.9814, -0.4486],\n",
            "        [-0.6453,  2.0720]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(-0.3704, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0.0909, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.2546]], requires_grad=True)\n",
            "\n",
            "True:   l=0.693, sigma^2=0.693, noise=0\n",
            "Fitted: l=0.574, sigma^2=0.74, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device,\n",
        "    randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=True, device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0.]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fba130f4ee0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7216, 0.5588, 0.0163],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.8445, 0.7417, 0.1469],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.8424, 0.6213, 0.9883],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460]])\n",
            "tensor([2, 4, 0, 6, 7, 1, 3, 5])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163]])\n",
            "tensor([[0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.4122, -9.7531, -9.2286, -9.5989, -9.1321, -9.4680, -9.3031, -9.7429,\n",
              "        -9.3805, -9.6507, -9.0406, -9.3168, -9.1272, -9.9820, -9.1291, -9.4314,\n",
              "        -9.7203, -9.4293, -9.0302, -9.4230])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.]),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.]], requires_grad=True)}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.),\n",
              " 'covar_module.raw_outputscale': tensor(0.),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.]])}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:04<00:00, 237.86it/s]\n"
          ]
        }
      ],
      "source": [
        "fixed_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3770e-01, 5.9728e-01, 1.3027e-01, 8.7175e-01, 1.3623e-01],\n",
              "        [2.8008e-01, 5.2939e-01, 7.4921e-01, 6.7475e-01, 7.0635e-01],\n",
              "        [3.8596e-04, 1.7254e-01, 9.1312e-01, 5.6526e-01, 8.1478e-01],\n",
              "        [4.3732e-01, 4.3083e-01, 3.0867e-01, 7.7489e-01, 8.4643e-01],\n",
              "        [6.1417e-01, 7.0303e-01, 8.9406e-02, 6.5903e-01, 9.4700e-01],\n",
              "        [1.3595e-01, 2.9692e-01, 8.0865e-01, 3.6557e-01, 8.0262e-02],\n",
              "        [5.5435e-01, 2.0977e-01, 9.9751e-01, 2.5552e-01, 2.0415e-01],\n",
              "        [9.2425e-01, 4.8544e-01, 7.1970e-01, 3.0899e-01, 4.5466e-02],\n",
              "        [4.7055e-01, 6.2878e-01, 3.4137e-01, 1.5561e-01, 2.4682e-01],\n",
              "        [5.0904e-01, 5.2614e-01, 5.8093e-01, 3.4311e-02, 5.9625e-01],\n",
              "        [2.4432e-02, 3.5175e-01, 1.1442e-01, 4.1488e-01, 2.4443e-01],\n",
              "        [1.9026e-01, 5.0099e-01, 8.4974e-01, 9.3262e-01, 9.7229e-01],\n",
              "        [6.5269e-01, 1.5853e-01, 5.4473e-01, 3.1906e-01, 5.2323e-01],\n",
              "        [3.3650e-01, 5.1750e-01, 7.4551e-01, 5.5767e-01, 2.9194e-01],\n",
              "        [9.8836e-01, 4.7839e-01, 9.2729e-01, 5.5478e-02, 3.0561e-01],\n",
              "        [5.3924e-01, 5.8842e-02, 8.9266e-01, 9.7812e-01, 5.7267e-01],\n",
              "        [3.1673e-01, 2.5540e-01, 2.3361e-01, 5.1155e-01, 1.0439e-01],\n",
              "        [9.1125e-01, 9.1233e-01, 2.4270e-01, 6.6415e-01, 5.5721e-01],\n",
              "        [7.4868e-01, 8.5152e-01, 9.0714e-01, 2.8652e-01, 1.8544e-01],\n",
              "        [6.2989e-01, 1.9168e-02, 2.5467e-02, 8.0095e-01, 6.3958e-01]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = ListMapFunctionSamplesDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([1], [1]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([2], [2]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([3], [3]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([4], [4]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([5], [5]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([6], [6]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([7], [7]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([8], [8]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([9], [9]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([10], [10]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([11], [11]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([12], [12]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([13], [13]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([14], [14]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([15], [15]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([16], [16]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([17], [17]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([18], [18]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([19], [19]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "([12, 13], [33]) <class 'function_samples_dataset.GPDatasetItem'>\n"
          ]
        }
      ],
      "source": [
        "# test_dataset = ListMapFunctionSamplesDataset([\n",
        "#     ([i], [i]) for i in range(20)\n",
        "# ] + [([12, 13], [33], SingleTaskGP(torch.zeros(2, 1), torch.zeros(2, 1), likelihood=likelihood, covar_module=kernel))])\n",
        "\n",
        "test_dataset = ListMapFunctionSamplesDataset([\n",
        "    ([i], [i]) for i in range(20)\n",
        "] + [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = ListMapFunctionSamplesDataset(\n",
        "#     [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x, type(x))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')\n",
        " # \"Generating GP realizations:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/123 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 123/123 [00:00<00:00, 291.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating and saving realizations from GaussianProcessRandomDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 94/94 [00:00<00:00, 285.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5, dataset_size=94)\n",
        "function_samples_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 123)\n",
        "function_samples_dataset = function_samples_dataset[:20]\n",
        "function_samples_dataset.save('fixed', 17)\n",
        "rand_dataset.save('random')\n",
        "loaded_dataset = ListMapFunctionSamplesDataset.load('fixed')\n",
        "print(len(loaded_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 17)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 100/100 [00:00<00:00, 191.19it/s]\n"
          ]
        }
      ],
      "source": [
        "function_samples_dataset_2 = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:00<00:00, 151.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([20, 6]) torch.Size([20])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "torch.Size([40, 6]) torch.Size([40])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 20/20 [00:00<00:00, 150.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dataset_with_models.MapFunctionSamplesSubset'>\n",
            "<class 'dataset_with_models.MapFunctionSamplesSubset'> 12\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.0183, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5937, -0.7234, -0.7051, -0.3100,  0.2769, -0.5216]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(24.7716, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3166,  0.5050, -0.4871, -0.4972,  0.1745,  0.8940]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.7187, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3906, -0.7809, -1.0721, -0.8058, -0.3789, -1.7219]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([16, 6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([16])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.5066, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.6178, -1.3973, -0.9966,  0.0687, -0.8019, -0.7827]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(19.7305, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3467, -3.4180, -0.4457,  0.0798,  0.7735, -2.3735]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(30.5852, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3173, -0.1330, -0.6055, -1.2983,  0.1788, -1.1704]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.1442, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.4117,  0.7357,  0.2728, -0.0876,  0.0997, -1.9339]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.1815, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.4540, -1.2818, -0.0256, -0.7721, -0.2421, -0.2774]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.8933, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5878,  0.3725, -1.0817, -0.9872, -0.2428, -0.3045]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.7568, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.0724, -0.6240,  0.2163,  1.1081, -1.6193, -0.1446]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([27, 6]) torch.Size([27])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.9243, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4186, -1.4162, -0.9122, -0.3766, -0.8241, -1.9416]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.8280, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.9496, -1.6693, -1.7773,  0.0875, -1.2961, -0.7184]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "17 14 12 12\n",
            "\n",
            "\n",
            "torch.Size([3, 17, 6]) torch.Size([3, 17]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 17]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 19, 6]) torch.Size([3, 19]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 19]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 30, 6]) torch.Size([3, 30]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 30]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 18, 6]) torch.Size([3, 18]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 18]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "dataset = dataset[:-3]\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1), len(train_subset_1))\n",
        "# train_subset_1 = train_subset_1[:4]\n",
        "# print(type(train_subset_1), len(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = ListMapFunctionSamplesDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(dataset), len(train_dataset), len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = FunctionSamplesAcquisitionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function_samples_dataset.GaussianProcessRandomDataset at 0x7fba1761b850>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient w.r.t x (Approach a): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradient w.r.t x (Approach b): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradients w.r.t x are equal: True\n",
            "Gradient w.r.t y (Approach a): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradient w.r.t y (Approach b): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradients w.r.t y are equal: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=True)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=True)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data:\n",
            " tensor([[[ 0.,  1.,  2.,  3.],\n",
            "         [ 4.,  5.,  6.,  7.],\n",
            "         [ 8.,  9., 10., 11.]],\n",
            "\n",
            "        [[12., 13., 14., 15.],\n",
            "         [16., 17., 18., 19.],\n",
            "         [20., 21., 22., 23.]]], dtype=torch.float32)\n",
            "mask: torch.bool\n",
            " tensor([[[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]],\n",
            "\n",
            "        [[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]]])\n",
            "data masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "data2 masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "stacked_masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 43.,   0.,   0.,   0.,   0.,   0.,  35.,   0.,   0.,   0.,  31.,\n",
              "          0.,   0.,  36.,   0.,  30.,   0.,  36.,   0.,  38.,  36.,  44.,\n",
              "         37.,  28.,  23.,  59.,  39.,  69.,  71.,  67.,  77., 106.,  66.,\n",
              "        106., 144., 149., 130., 136., 198., 145., 243., 230., 236., 285.,\n",
              "        289., 381., 376., 404., 513., 531., 587., 625., 717., 777., 863.,\n",
              "        964.]),\n",
              " array([0.        , 0.10185326, 0.20370652, 0.30555978, 0.40741303,\n",
              "        0.50926629, 0.61111955, 0.71297281, 0.81482607, 0.91667933,\n",
              "        1.01853258, 1.12038584, 1.2222391 , 1.32409236, 1.42594562,\n",
              "        1.52779888, 1.62965214, 1.73150539, 1.83335865, 1.93521191,\n",
              "        2.03706517, 2.13891843, 2.24077169, 2.34262494, 2.4444782 ,\n",
              "        2.54633146, 2.64818472, 2.75003798, 2.85189124, 2.9537445 ,\n",
              "        3.05559775, 3.15745101, 3.25930427, 3.36115753, 3.46301079,\n",
              "        3.56486405, 3.66671731, 3.76857056, 3.87042382, 3.97227708,\n",
              "        4.07413034, 4.1759836 , 4.27783686, 4.37969011, 4.48154337,\n",
              "        4.58339663, 4.68524989, 4.78710315, 4.88895641, 4.99080967,\n",
              "        5.09266292, 5.19451618, 5.29636944, 5.3982227 , 5.50007596,\n",
              "        5.60192922, 5.70378247]),\n",
              " <BarContainer object of 56 artists>)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD6CAYAAABNu5eFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPG0lEQVR4nO3dcchdd33H8fdnqVatiil9WmISlwwyt1TYdA/BrSDDurVbxfSfQgRdGB2Bkbm6DTTZP7I/AmEMccI6COoWURqCOhrUObNoEUEbn7R1msaswWbts2TN48Rp90ddsu/+eM7wkj5Pk+eem3uf3N/7BeGe87u/c8/3EPK5v/zOueekqpAkteHnJl2AJGl8DH1JaoihL0kNMfQlqSGGviQ1xNCXpIZcMfSTfCLJhSTfHWi7OcnRJE91r2sH3tub5EyS00nuGmj/tSTf6d77aJKM/nAkSS8lV7pOP8nbgOeBT1bVm7q2vwR+WFX7k+wB1lbVB5NsBR4CtgGvB/4Z+MWqupTkOPAA8E3gi8BHq+ofr1TgLbfcUps2bRr6ACWpRSdOnPhBVc1c3n7DlTasqq8l2XRZ83bgN7vlg8AjwAe79kNV9QLwdJIzwLYkZ4HXVtU3AJJ8ErgXuGLob9q0ibm5uSt1kyQNSPJvS7UPO6d/W1WdB+heb+3a1wPPDvSb79rWd8uXt0uSxmjUJ3KXmqevl2hf+kOSXUnmkswtLCyMrDhJat2wof9cknUA3euFrn0e2DjQbwNwrmvfsET7kqrqQFXNVtXszMyLpqQkSUMaNvSPADu75Z3AwwPtO5LcmGQzsAU43k0B/STJW7urdn5vYBtJ0phc8URukodYPGl7S5J54EPAfuBwkvuBZ4D7AKrqZJLDwJPARWB3VV3qPuoPgb8HXsniCdwrnsSVJI3WFS/ZnLTZ2dny6h1JWpkkJ6pq9vJ2f5ErSQ0x9CWpIYa+JDXkiidyJUnX1qY9X3hR29n991yTfTnSl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ3wwuiSNyVIPQB83R/qS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQXqGf5E+SnEzy3SQPJXlFkpuTHE3yVPe6dqD/3iRnkpxOclf/8iVJKzF06CdZD/wxMFtVbwLWADuAPcCxqtoCHOvWSbK1e/924G7gwSRr+pUvSVqJvtM7NwCvTHID8CrgHLAdONi9fxC4t1veDhyqqheq6mngDLCt5/4lSSswdOhX1b8DfwU8A5wH/quqvgzcVlXnuz7ngVu7TdYDzw58xHzXJkkakz7TO2tZHL1vBl4P3JTkPS+1yRJttcxn70oyl2RuYWFh2BIlSZfpM73zDuDpqlqoqv8BPgf8BvBcknUA3euFrv88sHFg+w0sTge9SFUdqKrZqpqdmZnpUaIkaVCf0H8GeGuSVyUJcCdwCjgC7Oz67AQe7paPADuS3JhkM7AFON5j/5KkFRr6ISpV9WiSzwCPAReBx4EDwKuBw0nuZ/GL4b6u/8kkh4Enu/67q+pSz/olSSvQ68lZVfUh4EOXNb/A4qh/qf77gH199ilJGp6PS5Ska2A1PBpxKd6GQZIaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8YZrktTTar252lIc6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN8Rm5knSVrqdn4S6n10g/yeuSfCbJ95KcSvLrSW5OcjTJU93r2oH+e5OcSXI6yV39y5ckrUTf6Z2/Br5UVb8E/ApwCtgDHKuqLcCxbp0kW4EdwO3A3cCDSdb03L8kaQWGDv0krwXeBnwcoKp+WlU/ArYDB7tuB4F7u+XtwKGqeqGqngbOANuG3b8kaeX6jPR/AVgA/i7J40k+luQm4LaqOg/Qvd7a9V8PPDuw/XzXJkkakz6hfwPwFuBvq+rNwH/TTeUsI0u01ZIdk11J5pLMLSws9ChRkjSoT+jPA/NV9Wi3/hkWvwSeS7IOoHu9MNB/48D2G4BzS31wVR2oqtmqmp2ZmelRoiRp0NChX1X/ATyb5I1d053Ak8ARYGfXthN4uFs+AuxIcmOSzcAW4Piw+5ckrVzf6/TfB3w6ycuB7wO/z+IXyeEk9wPPAPcBVNXJJIdZ/GK4COyuqks99y9J18Q0XJO/lF6hX1VPALNLvHXnMv33Afv67FOSNDxvwyBJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIT4jV1LTpvUeO8txpC9JDTH0Jakhhr4kNcQ5fUnNaG3+fimO9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SG9A79JGuSPJ7k8936zUmOJnmqe1070HdvkjNJTie5q+++JUkrM4qR/gPAqYH1PcCxqtoCHOvWSbIV2AHcDtwNPJhkzQj2L0m6Sr1CP8kG4B7gYwPN24GD3fJB4N6B9kNV9UJVPQ2cAbb12b8kaWVu6Ln9R4APAK8ZaLutqs4DVNX5JLd27euBbw70m+/aJGmkNu35wqRLWLWGHukneSdwoapOXO0mS7TVMp+9K8lckrmFhYVhS5QkXabP9M4dwLuSnAUOAW9P8inguSTrALrXC13/eWDjwPYbgHNLfXBVHaiq2aqanZmZ6VGiJGnQ0KFfVXurakNVbWLxBO1Xquo9wBFgZ9dtJ/Bwt3wE2JHkxiSbgS3A8aErlyStWN85/aXsBw4nuR94BrgPoKpOJjkMPAlcBHZX1aVrsH9J0jJGEvpV9QjwSLf8n8Cdy/TbB+wbxT4ltWW5k7Nn998z5kqub9dipC9JY+OVOivjbRgkqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXExyVKWnV8BOK1Y+hLmigDfryc3pGkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xB9nSRracj+sOrv/njFXoqtl6EsaC395uzoY+pJGzoBfvZzTl6SGGPqS1JChQz/JxiRfTXIqyckkD3TtNyc5muSp7nXtwDZ7k5xJcjrJXaM4AEnS1esz0r8I/FlV/TLwVmB3kq3AHuBYVW0BjnXrdO/tAG4H7gYeTLKmT/GSpJUZOvSr6nxVPdYt/wQ4BawHtgMHu24HgXu75e3Aoap6oaqeBs4A24bdvyRp5UYyp59kE/Bm4FHgtqo6D4tfDMCtXbf1wLMDm813bZKkMel9yWaSVwOfBd5fVT9OsmzXJdpqmc/cBewCeMMb3tC3REkr4A+upluvkX6Sl7EY+J+uqs91zc8lWde9vw640LXPAxsHNt8AnFvqc6vqQFXNVtXszMxMnxIlSQP6XL0T4OPAqar68MBbR4Cd3fJO4OGB9h1JbkyyGdgCHB92/5KkleszvXMH8F7gO0me6Nr+HNgPHE5yP/AMcB9AVZ1Mchh4ksUrf3ZX1aUe+5ckrdDQoV9VX2fpeXqAO5fZZh+wb9h9SpL68Re5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSE+OUuaMt5GQS/F0JeuY+N8LKGPQJwOTu9IUkMc6UsNc/TeHkNfaoQBL3B6R5KaYuhLUkMMfUlqiKEvSQ3xRK40ISv5EZUnYTUqjvQlqSGGviQ1xNCXpIYY+pLUEENfkhri1TvSGHj1jVYLR/qS1BBH+tJVcKSuaWHoS6uMXzC6lgx9NWupcPWRgpp2zulLUkMMfUlqiNM7WvWchpFGZ6pD37DQSnkSVdNuqkN/NVitXzzXoq5x3ip4JfuS9DOG/nVonIFnuErTxdDXVFmt/7OSVgtDX1PPeXrpZ8Z+yWaSu5OcTnImyZ5x71+SWjbW0E+yBvgb4HeArcC7k2wdZw2S1LJxj/S3AWeq6vtV9VPgELB9zDVIUrPGHfrrgWcH1ue7NknSGKSqxrez5D7grqr6g279vcC2qnrfZf12Abu61TcCp4fc5S3AD4bcdrWaxmOC6Twuj+n6MY3H9fNVNXN547iv3pkHNg6sbwDOXd6pqg4AB/ruLMlcVc32/ZzVZBqPCabzuDym68e0HtdSxj298y1gS5LNSV4O7ACOjLkGSWrWWEf6VXUxyR8B/wSsAT5RVSfHWYMktWzsP86qqi8CXxzT7npPEa1C03hMMJ3H5TFdP6b1uF5krCdyJUmT5UNUJKkhUxn603irhySfSHIhyXcnXcuoJNmY5KtJTiU5meSBSdc0CklekeR4km93x/UXk65pVJKsSfJ4ks9PupZRSHI2yXeSPJFkbtL1jMPUTe90t3r4V+C3WLxE9FvAu6vqyYkW1lOStwHPA5+sqjdNup5RSLIOWFdVjyV5DXACuHcK/q4C3FRVzyd5GfB14IGq+uaES+styZ8Cs8Brq+qdk66nryRngdmqmrZr9Jc1jSP9qbzVQ1V9DfjhpOsYpao6X1WPdcs/AU4xBb/QrkXPd6sv6/5c96OrJBuAe4CPTboWDW8aQ99bPVyHkmwC3gw8OuFSRqKbBnkCuAAcrappOK6PAB8A/nfCdYxSAV9OcqK7E8DUm8bQzxJt1/0oa5oleTXwWeD9VfXjSdczClV1qap+lcVfnW9Lcl1PySV5J3Chqk5MupYRu6Oq3sLinX93d9OoU20aQ/+qbvWg1aGb8/4s8Omq+tyk6xm1qvoR8Ahw92Qr6e0O4F3dHPgh4O1JPjXZkvqrqnPd6wXgH1icHp5q0xj63urhOtGd8Pw4cKqqPjzpekYlyUyS13XLrwTeAXxvokX1VFV7q2pDVW1i8d/UV6rqPRMuq5ckN3UXEJDkJuC3gam5Om45Uxf6VXUR+P9bPZwCDk/DrR6SPAR8A3hjkvkk90+6phG4A3gvi6PGJ7o/vzvpokZgHfDVJP/C4iDkaFVNxSWOU+Y24OtJvg0cB75QVV+acE3X3NRdsilJWt7UjfQlScsz9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jasj/ATl46cN05o0JAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([479,  61, 736, 798,  30, 101,   1, 207, 625,  55, 805,   2, 456, 702,\n",
            "        554, 463, 154,  42,  80,  63, 324, 101,  34,  31, 401,  58, 893, 635,\n",
            "        533,  19, 598, 977, 753,  74, 293,  14, 125, 583,  10, 754,  15, 326,\n",
            "          5, 111, 422,  43,  80, 139, 185, 349, 108,  42,  37, 765, 146, 121,\n",
            "          2,  57,  34,  19,  22,  36,  63, 365,  21,  13, 911,  31, 913,  36,\n",
            "         17,  14, 299,   5,   7,  52,   6,  93,  50,  28,  31,   6, 168,  39,\n",
            "         10, 405,   6, 133,  79,  24,   6,  98,  12, 202, 736,   8, 238, 179,\n",
            "         19, 130, 193,  66, 371, 167, 484, 162, 935,  11,  20, 145,  17,  99,\n",
            "          3, 177,  10, 776,  94, 524, 266, 316,  51,  45,  33,  20, 133,   2,\n",
            "        845, 219,   9,  61, 353,  28,   9,  70, 187, 409, 740, 638,  28,  18,\n",
            "        191,  35, 148, 618, 394,  70, 381,   5, 411, 394,   1,  31, 318, 237,\n",
            "         39, 284, 312,  47, 158, 105,  44,  99, 133, 908,  39, 273, 134,  18,\n",
            "          5, 716, 279, 115,  44,  46, 106,  53,  26, 646,  18, 986, 994,  61,\n",
            "        218, 963,  17, 156,  47, 605,   4,  50,  58, 244, 729,  38, 993,  74,\n",
            "         21,  22,   6, 166, 798,   2, 312, 561,  53,  80, 235, 163, 159,  39,\n",
            "        155, 180, 252,   9, 818, 388,  18,  14,  64,   9,  42,  24, 416,   4,\n",
            "        734,  60,  15, 295, 232, 578, 235, 330, 272, 209, 275,  51,   2, 573,\n",
            "         14,  42, 109,   5,  79,  23, 119, 988,  90, 426, 182,  65, 132, 235,\n",
            "         68,  26,  63, 330,  25, 296, 372, 127,  49,  12,  40, 124, 169, 224,\n",
            "        238,  16,  19, 648, 107, 516, 614,  94, 737,  35,  35, 161,  11,  68,\n",
            "        742,  16, 348,  21, 346, 699,  21,   2,   3,  35,  10, 179,  13,  30,\n",
            "        114,  60,  24, 242, 258, 119,  48, 181,  15, 104,  23, 527,   7, 443,\n",
            "         21,   6,  49,  19, 927,   9, 604, 317, 519, 128, 178, 177, 555,  61,\n",
            "        177, 561, 160,  69,  34, 396, 849,  25, 311,  35,  13, 418, 895,  46,\n",
            "         82, 688, 436, 840,  50, 280, 810,  96,   1, 647,  76,  61,  69,  34,\n",
            "        722,   5,   1, 606,  39,  66, 354, 228, 108,   1,   5,  81,  28,  15,\n",
            "        375,  13, 343, 154, 475, 975, 475,   1,  17, 271,  51, 482, 491, 782,\n",
            "        390, 448,  58, 465, 100,  59,  42, 186,  19, 192,  37, 251,  51, 493,\n",
            "         15,   2,   8, 629, 105, 257,  50, 266, 100, 283,  35, 217, 192,  14,\n",
            "         16, 213, 107, 253,  96, 212, 703,  11, 355,  40,  80,  28, 415,   3,\n",
            "         94, 165,  47,   7, 138,  32, 137,  14, 893,  16,  42, 459, 663, 147,\n",
            "         43,  10, 308, 563, 382,  65,  10,  66,   8,   5, 131,   3, 100,  82,\n",
            "        253, 943, 370,  15,  41,  10,  13,  81,  23, 658,   7, 303, 803, 108,\n",
            "        899, 904, 791, 649, 327, 208, 312,   6, 153,  66, 306, 393,  17,   6,\n",
            "         22, 105,  37, 598, 101,  10, 981,  56, 114,  12,  21,   1,  48, 133,\n",
            "        311, 695, 195, 709, 793,  19,  65, 414, 648, 382,  61,  94, 325, 591,\n",
            "         53,  22, 390, 103, 267, 150, 162, 877,  74,  30, 813,  52,  29, 268,\n",
            "        162,   4,  25, 699, 241, 133,  26,  54,  82,  76,  35,   4,  44,  16,\n",
            "        713, 203, 405, 962, 149, 776, 364, 213,  54,  20,  88,  59, 115, 341,\n",
            "        315,  98, 349,  48,  23, 199,   7, 682, 948, 490, 179,  77,  66,  97,\n",
            "        183, 234,  49,  40,  34, 137, 159, 504, 289, 664, 622,  32,  82,  13,\n",
            "        243,   4, 100, 222,   4,  97,  30,  86,  75, 271, 108,   1, 630, 850,\n",
            "        820, 681, 255,   7,  63, 104,   2, 175, 499,  16,  95, 125,   8,  83,\n",
            "         28,  47,  38, 115, 461,  90, 237,  34,   1,  58,  62,  11, 919,  66,\n",
            "        705,  29,  10,  28, 459,  45,  46, 620,   2,   1, 102,   8,   9, 378,\n",
            "        587, 453, 280, 667, 286, 235,  48,   5,  11, 151, 188, 472, 479, 879,\n",
            "        163, 213, 689,  30, 446, 901,  55, 346,  37,  57,  19,  79,   2, 157,\n",
            "          2,  70,  27, 227,  12, 533, 220,  28, 335,  66,  37,  34,  79,  62,\n",
            "         27, 249,   4, 134, 177, 383,  12,  53,  74,  86,  53,  77,  59, 941,\n",
            "         11,  19,  47, 144,  56, 219, 763, 155, 122,  18, 518,  37, 287,  89,\n",
            "          2, 579, 428,  28,  59, 150, 648,  46, 574, 477, 127,  13, 975,   3,\n",
            "          4, 617, 148, 206, 109, 989, 334, 787,  47, 297,   2, 936, 512, 110,\n",
            "        527, 197,  77, 185, 188,  33,  57, 400,  14, 492, 839, 569,   3,  16,\n",
            "         18, 696, 101,  15, 237,  40,  57,  67, 250, 111, 107, 112, 849,  58,\n",
            "         29, 368, 526, 385, 269, 795,  51,  90, 128, 338, 508,  31, 504,  76,\n",
            "          5, 969,  29, 271,  29,  17,   6,  35,  20,  13, 384,  40, 519,  72,\n",
            "        514, 564, 156, 342,   2, 120, 355, 369,  45, 246, 435, 178, 237, 312,\n",
            "          2, 354,  69,  77, 137, 933,  85,   8, 242,   8, 272, 114, 255, 355,\n",
            "        294,  35, 159,   3, 110,  35, 321,  58,   2, 290,  76, 192, 190, 137,\n",
            "        115, 167,  51, 584, 926,  10, 843, 111, 929, 197,  53, 268,  22, 108,\n",
            "        940, 189, 208,  33,  25,  18, 200, 334, 811, 638, 931,  34,  19, 931,\n",
            "        216,   4, 837,   8, 135, 998,  56,  27, 743,  85,   4, 213,   9, 526,\n",
            "         21, 563, 291,   4,  29, 691, 668,   1, 915, 129,  45,  11, 131,  34,\n",
            "        170,  15, 112,  58,  66,   1,  10,  24, 260,  12, 295, 299,  19, 101,\n",
            "         17,  61, 615,  33,  13, 459,  99,  17,  76,  39,   2, 335,  14, 227,\n",
            "        885, 160, 106,  23, 412,  23, 124,  62,  20,  22, 454, 662,  11,   4,\n",
            "        338, 160, 243, 385,  98,   3, 120, 135,  16, 535, 843, 538, 244, 108,\n",
            "         30, 962, 776, 108,  44, 763,  57, 161,   8,  72,  21,  93,   1, 232,\n",
            "        295, 209, 118, 516, 994,  19,  29, 569,  51,  87,  89,  44,  24, 350,\n",
            "         56, 104, 234,  38,   2,  83,  86,   9, 470,  23, 129, 150,  16, 290,\n",
            "        306,   4, 510, 371, 106,  42,  15, 152, 556,  22, 143,  13,  19, 131,\n",
            "        255, 604, 186, 223,   9, 571], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
