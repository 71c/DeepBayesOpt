{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([1.0000e-06])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(13.0167, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.7210]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(2.3340, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(9.0423, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.5187]], requires_grad=True)\n",
            "\n",
            "True:   l=0.396, sigma^2=13, noise=1e-06\n",
            "Fitted: l=0.467, sigma^2=9.04, noise=1e-06\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=7, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device)\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "model.likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "true_noise = model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(25.9502)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.1626]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.0303, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(7.0973, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.6044]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 100)\n",
        "function_samples_dataset.save('test')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([25, 6]) torch.Size([25])\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([16, 6]) torch.Size([16])\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "torch.Size([36, 6]) torch.Size([36])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "torch.Size([22, 6]) torch.Size([22])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.7515, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2738,  0.1005, -0.0165, -1.3715, -0.3896, -0.5113]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(23.0031, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0501, -1.2738, -0.3901, -1.5378, -0.3554, -0.9313]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.4107, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.1873, -1.0822, -0.9720,  0.3895, -1.8195, -0.7942]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.4552, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8715, -0.7563, -1.9962,  0.3406, -1.3481, -1.3639]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.7275, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7267, -0.0601, -0.3362, -0.0522, -0.4599,  0.0694]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.8934, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.1963,  0.8783, -1.1001, -2.2270, -1.0603, -1.4609]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(2.9053, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.5863, -0.8679,  0.8952, -0.3738, -1.4301, -1.2107]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(3.8494, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.1173, -1.5392, -2.3209, -1.9974, -0.4123,  0.4334]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.0844, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4966, -1.4197, -0.4233, -0.1163, -1.5528, -1.2228]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(29.5562, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8981, -0.0556,  0.7221, -0.7472, -1.0052,  0.0350]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(26.4354, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.7095,  1.0966, -0.4885, -0.6091, -1.4057, -0.3684]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.1059, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0928, -0.8568, -1.9886, -0.8789, -0.3097, -1.2336]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.7868, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.3215, -1.9727, -0.9548, -0.9040, -0.6960, -0.6197]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "13 13\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m aq1\u001b[38;5;241m.\u001b[39mget_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#           hist_mask if hist_mask is None else hist_mask.shape,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#           cand_mask if cand_mask is None else cand_mask.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     print([type(model) for model in models])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     print()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = TrainAcquisitionFunctionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
