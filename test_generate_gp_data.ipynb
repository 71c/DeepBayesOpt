{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5853, -2.2724],\n",
            "        [ 0.4816,  0.1837],\n",
            "        [-0.7448, -0.5636]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(-0.3617, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(-3.3777, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-1.0170]], requires_grad=True)\n",
            "\n",
            "True:   l=0.693, sigma^2=0.693, noise=0\n",
            "Fitted: l=0.309, sigma^2=0.0336, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device,\n",
        "    randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=True, device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "can't set attribute",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v\n\u001b[1;32m      9\u001b[0m c \u001b[38;5;241m=\u001b[39m Foo(\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m c\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m c\u001b[38;5;241m.\u001b[39mv\n",
            "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
          ]
        }
      ],
      "source": [
        "class Foo:\n",
        "    def __init__(self, v):\n",
        "        self._v = v\n",
        "    \n",
        "    @property\n",
        "    def v(self):\n",
        "        return self._v\n",
        "\n",
        "c = Foo(6)\n",
        "c.v = 5\n",
        "c.v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(25.9502)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.1626]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.0303, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(7.0973, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.6044]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 100)\n",
        "function_samples_dataset.save('test')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([25, 6]) torch.Size([25])\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([16, 6]) torch.Size([16])\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "torch.Size([36, 6]) torch.Size([36])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "torch.Size([22, 6]) torch.Size([22])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.7515, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2738,  0.1005, -0.0165, -1.3715, -0.3896, -0.5113]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(23.0031, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0501, -1.2738, -0.3901, -1.5378, -0.3554, -0.9313]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.4107, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.1873, -1.0822, -0.9720,  0.3895, -1.8195, -0.7942]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.4552, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8715, -0.7563, -1.9962,  0.3406, -1.3481, -1.3639]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.7275, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7267, -0.0601, -0.3362, -0.0522, -0.4599,  0.0694]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.8934, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.1963,  0.8783, -1.1001, -2.2270, -1.0603, -1.4609]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(2.9053, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.5863, -0.8679,  0.8952, -0.3738, -1.4301, -1.2107]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(3.8494, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.1173, -1.5392, -2.3209, -1.9974, -0.4123,  0.4334]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.0844, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4966, -1.4197, -0.4233, -0.1163, -1.5528, -1.2228]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(29.5562, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8981, -0.0556,  0.7221, -0.7472, -1.0052,  0.0350]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(26.4354, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.7095,  1.0966, -0.4885, -0.6091, -1.4057, -0.3684]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.1059, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0928, -0.8568, -1.9886, -0.8789, -0.3097, -1.2336]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.7868, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.3215, -1.9727, -0.9548, -0.9040, -0.6960, -0.6197]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "13 13\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m aq1\u001b[38;5;241m.\u001b[39mget_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#           hist_mask if hist_mask is None else hist_mask.shape,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#           cand_mask if cand_mask is None else cand_mask.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     print([type(model) for model in models])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     print()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = TrainAcquisitionFunctionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
