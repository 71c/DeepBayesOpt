{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, FunctionSamplesAcquisitionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "class Foo:\n",
        "    def __iter__(self):\n",
        "        pass\n",
        "\n",
        "isinstance(Foo(), Iterable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000],\n",
              "        [0.5000],\n",
              "        [1.0000],\n",
              "        [1.5000],\n",
              "        [2.0000]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.linspace(0, 2, 5).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0224],\n",
              "        [0.4601],\n",
              "        [0.5239],\n",
              "        [0.7331],\n",
              "        [0.0724]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5853, -2.2724],\n",
            "        [ 0.4816,  0.1837],\n",
            "        [-0.7448, -0.5636]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0.1518, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(-0.2809, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.5983]], requires_grad=True)\n",
            "\n",
            "True:   l=0.693, sigma^2=0.693, noise=0\n",
            "Fitted: l=0.438, sigma^2=0.563, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device,\n",
        "    randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=True, device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "can't set attribute",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v\n\u001b[1;32m      9\u001b[0m c \u001b[38;5;241m=\u001b[39m Foo(\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m c\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m c\u001b[38;5;241m.\u001b[39mv\n",
            "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
          ]
        }
      ],
      "source": [
        "class Foo:\n",
        "    def __init__(self, v):\n",
        "        self._v = v\n",
        "    \n",
        "    @property\n",
        "    def v(self):\n",
        "        return self._v\n",
        "\n",
        "c = Foo(6)\n",
        "c.v = 5\n",
        "c.v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(7.0973)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.6044]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0303)), ('covar_module.raw_outputscale', tensor(25.9502)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.1626]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.0303, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(7.0973, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.6044]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')\n",
        " # \"Generating GP realizations:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into FunctionSamplesMapDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123/123 [00:00<00:00, 211.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating and saving realizations from GaussianProcessRandomDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 94/94 [00:00<00:00, 281.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5, dataset_size=94)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 123)\n",
        "function_samples_dataset = function_samples_dataset[:20]\n",
        "function_samples_dataset.save('fixed', 17)\n",
        "rand_dataset.save('random')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('fixed')\n",
        "print(len(loaded_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating GP realizations:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 33.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([20, 6]) torch.Size([20])\n",
            "torch.Size([21, 6]) torch.Size([21])\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([37, 6]) torch.Size([37])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([9, 6]) torch.Size([9]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([25, 6]) torch.Size([25]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([5, 6]) torch.Size([5]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, FunctionSamplesAcquisitionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "Generating GP realizations:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 178.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method FunctionSamplesMapDatasetBase._resize_iterable_dataset of <class 'generate_gp_data.FunctionSamplesMapDataset'>>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'> 12\n",
            "torch.Size([21, 6]) torch.Size([21])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.5610, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3877, -0.0363, -0.1053, -1.5243, -0.9036, -0.3979]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.4849, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0091, -0.0928, -0.5532, -0.2657, -0.4310,  1.2274]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(9.5126, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2033, -0.7404,  0.2591, -0.0700, -1.5731, -0.4257]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.3722, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.9279, -0.6191,  0.4358, -0.3567, -1.0461,  0.2384]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([37, 6]) torch.Size([37])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.9579, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.1352, -0.8541, -1.4454, -1.8027, -0.7142, -0.9220]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(27.3889, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7664, -0.9930, -1.2243, -0.6402, -0.4049, -2.2043]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.8773, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0883, -0.9112,  0.2173,  0.1569, -1.0211,  0.0142]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([23, 6]) torch.Size([23])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(14.8155, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.3281, -0.7494, -0.8896, -0.8497, -1.2025, -0.0897]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(17.3748, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.2005, -1.4982,  0.1955, -1.4081, -2.2650, -1.1515]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([33, 6]) torch.Size([33])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.1191, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.6652, -0.9901, -0.2770, -2.1329, -0.6184, -1.2254]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(55.6962, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0652,  0.1252, -1.1494,  0.6976, -0.8017,  0.6695]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(17.4057, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.1816, -0.8676, -0.9807,  0.4478, -0.7256, -0.7130]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "17 14 12 12\n",
            "\n",
            "\n",
            "torch.Size([3, 25, 6]) torch.Size([3, 25]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 25]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 9, 6]) torch.Size([3, 9]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 9]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 17, 6]) torch.Size([3, 17]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 17]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 19, 6]) torch.Size([3, 19]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 19]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "print(FunctionSamplesMapDataset._resize_iterable_dataset)\n",
        "\n",
        "dataset = dataset[:-3]\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1), len(train_subset_1))\n",
        "# train_subset_1 = train_subset_1[:4]\n",
        "# print(type(train_subset_1), len(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(dataset), len(train_dataset), len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = FunctionSamplesAcquisitionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
