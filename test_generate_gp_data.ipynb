{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 1., 0.]])\n",
            "tensor([[0.0000, 0.0000, 0.5000, 0.5000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with multiple maximum values\n",
        "x = torch.tensor([[1.0, 2.0, 3.0, 3.0]], requires_grad=True)\n",
        "\n",
        "# Using max\n",
        "max_value = torch.max(x, dim=-1).values\n",
        "max_value.backward(torch.ones_like(max_value))\n",
        "print(x.grad)  # Gradient is propagated to a single maximum value\n",
        "\n",
        "# Reset the gradient\n",
        "x.grad.zero_()\n",
        "\n",
        "# Using amax\n",
        "amax_value = torch.amax(x, dim=-1)\n",
        "amax_value.backward(torch.ones_like(amax_value))\n",
        "print(x.grad)  # Gradient is evenly distributed among the maximum values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=30, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create a sequential model\n",
        "# model = nn.Sequential(*[nn.Linear(i, i+1) for i in range(5)])\n",
        "model = nn.Sequential()\n",
        "\n",
        "# Append another linear layer to the model using the + operator\n",
        "model.append(nn.Linear(20, 30))\n",
        "\n",
        "# Print the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient w.r.t x (Approach a): tensor([[  6.2730],\n",
            "        [ -2.9015],\n",
            "        [ 11.4646],\n",
            "        [ -2.6715],\n",
            "        [ -0.9317],\n",
            "        [  1.7839],\n",
            "        [  0.6122],\n",
            "        [ -0.0902],\n",
            "        [  6.5308],\n",
            "        [ -7.1380],\n",
            "        [ 15.9845],\n",
            "        [-19.6427],\n",
            "        [ -6.0633],\n",
            "        [  3.3765],\n",
            "        [-13.5466],\n",
            "        [  6.2712],\n",
            "        [  7.5487],\n",
            "        [ -0.8567],\n",
            "        [ -3.7739],\n",
            "        [  0.9376]])\n",
            "Gradient w.r.t x (Approach b): tensor([[  6.2730],\n",
            "        [ -2.9015],\n",
            "        [ 11.4646],\n",
            "        [ -2.6715],\n",
            "        [ -0.9317],\n",
            "        [  1.7839],\n",
            "        [  0.6122],\n",
            "        [ -0.0902],\n",
            "        [  6.5308],\n",
            "        [ -7.1380],\n",
            "        [ 15.9845],\n",
            "        [-19.6427],\n",
            "        [ -6.0633],\n",
            "        [  3.3765],\n",
            "        [-13.5466],\n",
            "        [  6.2711],\n",
            "        [  7.5487],\n",
            "        [ -0.8567],\n",
            "        [ -3.7739],\n",
            "        [  0.9376]])\n",
            "Gradients w.r.t x are equal: True\n",
            "Gradient w.r.t y (Approach a): tensor([[ 0.0147,  0.0147,  0.0147,  ...,  0.0147,  0.0147,  0.0147],\n",
            "        [-0.1418, -0.1418, -0.1418,  ..., -0.1418, -0.1418, -0.1418],\n",
            "        [-0.1543, -0.1543, -0.1543,  ..., -0.1543, -0.1543, -0.1543],\n",
            "        ...,\n",
            "        [-0.0844, -0.0844, -0.0844,  ..., -0.0844, -0.0844, -0.0844],\n",
            "        [-0.2652, -0.2652, -0.2652,  ..., -0.2652, -0.2652, -0.2652],\n",
            "        [-0.0977, -0.0977, -0.0977,  ..., -0.0977, -0.0977, -0.0977]])\n",
            "Gradient w.r.t y (Approach b): tensor([[ 0.0147,  0.0147,  0.0147,  ...,  0.0147,  0.0147,  0.0147],\n",
            "        [-0.1418, -0.1418, -0.1418,  ..., -0.1418, -0.1418, -0.1418],\n",
            "        [-0.1543, -0.1543, -0.1543,  ..., -0.1543, -0.1543, -0.1543],\n",
            "        ...,\n",
            "        [-0.0844, -0.0844, -0.0844,  ..., -0.0844, -0.0844, -0.0844],\n",
            "        [-0.2652, -0.2652, -0.2652,  ..., -0.2652, -0.2652, -0.2652],\n",
            "        [-0.0977, -0.0977, -0.0977,  ..., -0.0977, -0.0977, -0.0977]])\n",
            "Gradients w.r.t y are equal: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=True)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=True)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"tuple\") to list",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
          ]
        }
      ],
      "source": [
        "[1] + (2,4,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient using torch.max:\n",
            " tensor([[0., 0., 1., 0.]])\n",
            "Gradient using MaxPool1d:\n",
            " tensor([[0., 0., 1., 0.]])\n",
            "Are gradients equal? True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create a tensor with multiple maximum values\n",
        "x = torch.tensor([[1.0, 2.0, 3.0, 3.0]], requires_grad=True)\n",
        "\n",
        "# Using torch.max\n",
        "max_value, _ = torch.max(x, dim=-1)\n",
        "max_value.sum().backward()\n",
        "max_grad = x.grad.clone()\n",
        "print(\"Gradient using torch.max:\\n\", max_grad)\n",
        "\n",
        "# Reset the gradient\n",
        "x.grad.zero_()\n",
        "\n",
        "# Using MaxPool1d\n",
        "x_reshaped = x.unsqueeze(1)  # MaxPool1d expects a 3D tensor (N, C, L)\n",
        "maxpool = nn.MaxPool1d(kernel_size=x.size(-1))\n",
        "maxpool_value = maxpool(x_reshaped).squeeze()\n",
        "maxpool_value.sum().backward()\n",
        "maxpool_grad = x.grad.clone()\n",
        "print(\"Gradient using MaxPool1d:\\n\", maxpool_grad)\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Are gradients equal?\", torch.equal(max_grad, maxpool_grad))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([1.0000e-06])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(17.1638, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.8312]], requires_grad=True)\n",
            "\n",
            "True:   l=1.19, sigma^2=17.2, noise=0\n",
            "Fitted: l=1.08, sigma^2=15.4, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=7, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device)\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "true_noise = model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 100)\n",
        "function_samples_dataset.save('test')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([25, 6]) torch.Size([25])\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([16, 6]) torch.Size([16])\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "torch.Size([36, 6]) torch.Size([36])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "torch.Size([22, 6]) torch.Size([22])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.7515, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2738,  0.1005, -0.0165, -1.3715, -0.3896, -0.5113]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(23.0031, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0501, -1.2738, -0.3901, -1.5378, -0.3554, -0.9313]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.4107, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.1873, -1.0822, -0.9720,  0.3895, -1.8195, -0.7942]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.4552, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8715, -0.7563, -1.9962,  0.3406, -1.3481, -1.3639]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.7275, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7267, -0.0601, -0.3362, -0.0522, -0.4599,  0.0694]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.8934, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.1963,  0.8783, -1.1001, -2.2270, -1.0603, -1.4609]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(2.9053, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.5863, -0.8679,  0.8952, -0.3738, -1.4301, -1.2107]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(3.8494, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.1173, -1.5392, -2.3209, -1.9974, -0.4123,  0.4334]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.0844, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4966, -1.4197, -0.4233, -0.1163, -1.5528, -1.2228]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(29.5562, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8981, -0.0556,  0.7221, -0.7472, -1.0052,  0.0350]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(26.4354, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.7095,  1.0966, -0.4885, -0.6091, -1.4057, -0.3684]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.1059, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0928, -0.8568, -1.9886, -0.8789, -0.3097, -1.2336]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.7868, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.3215, -1.9727, -0.9548, -0.9040, -0.6960, -0.6197]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "13 13\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m aq1\u001b[38;5;241m.\u001b[39mget_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#           hist_mask if hist_mask is None else hist_mask.shape,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#           cand_mask if cand_mask is None else cand_mask.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     print([type(model) for model in models])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     print()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = TrainAcquisitionFunctionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
