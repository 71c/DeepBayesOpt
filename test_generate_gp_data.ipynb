{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset, LazyMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor, remove_priors, Exp, get_gp\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.float64)\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.sampling.pathwise import draw_kernel_feature_paths\n",
        "from gpytorch.kernels import MaternKernel, RBFKernel, ScaleKernel\n",
        "from random_gp_function import RandomGPFunction\n",
        "from botorch.models.transforms.outcome import Log, Power\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(False, True, False),\n",
              " (True, True, False),\n",
              " (False, False, True),\n",
              " (True, True, True)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "[(b, not a or b, a) for a, b in itertools.product([False,True],[False,True])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3325388913236545215,  359254775711865947, 8544873655684927415,\n",
            "        4149298557807026509, 7751388342971580999, 8954549493601685272,\n",
            "         235764352298686044, 8990419267740540669, 8149894233483022126])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "\n",
        "n = 9  # number of random integers to generate\n",
        "low = 0  # lower bound (inclusive)\n",
        "high = 2**63-1  # upper bound (exclusive)\n",
        "\n",
        "random_integers = torch.randint(low, high, size=(n,), dtype=torch.int64)\n",
        "print(random_integers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8898423420600124682"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "torch.seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'a=(b=4,g=[1,2,(df=9)]),c=80,m=mother'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from utils import dict_to_str\n",
        "dict_to_str({\n",
        "    'm': 'mother',\n",
        "    'a': {'b': 4, 'g': [1,2, {'df': 9}]},\n",
        "    'c': 80\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 39.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "dataset[0].model.covar_module.raw_outputscale=Parameter containing:\n",
            "tensor(12.1518, requires_grad=True)\n",
            "dataset[0].model.covar_module.base_kernel.raw_lengthscale=Parameter containing:\n",
            "tensor([[-0.9093, -0.5196, -2.3122]], requires_grad=True)\n",
            "dataset[1].model.covar_module.raw_outputscale=Parameter containing:\n",
            "tensor(13.0525, requires_grad=True)\n",
            "dataset[1].model.covar_module.base_kernel.raw_lengthscale=Parameter containing:\n",
            "tensor([[ 0.9613, -0.0857, -0.9030]], requires_grad=True)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(103)\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    n_datapoints=3, dimension=3, dataset_size=2,\n",
        "    randomize_params=True).fix_samples(lazy=False)\n",
        "print(dataset[0].model)\n",
        "print(f'{dataset[0].model.covar_module.raw_outputscale=}')\n",
        "print(f'{dataset[0].model.covar_module.base_kernel.raw_lengthscale=}')\n",
        "print(f'{dataset[1].model.covar_module.raw_outputscale=}')\n",
        "print(f'{dataset[1].model.covar_module.base_kernel.raw_lengthscale=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.MyModel'>\n",
            "(10,)\n",
            "{'param2': 20}\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import os\n",
        "\n",
        "\n",
        "def save_json(data, fname, **kwargs):\n",
        "    with open(fname, 'w') as json_file:\n",
        "        json.dump(data, json_file, **kwargs)\n",
        "\n",
        "\n",
        "def load_json(fname, **kwargs):\n",
        "    with open(fname, 'r') as json_file:\n",
        "        return json.load(json_file)\n",
        "\n",
        "\n",
        "CLASSES = {}\n",
        "\n",
        "# Define the new __init_subclass__ method\n",
        "def _init_subclass(cls, **kwargs):\n",
        "    print(cls)\n",
        "    # Preserve the original __init__ method\n",
        "    original_init = cls.__init__\n",
        "    \n",
        "    # Define the new __init__ method\n",
        "    def new_init(self, *args, **kwargs):\n",
        "        self._init_args = args\n",
        "        self._init_kwargs = kwargs\n",
        "        original_init(self, *args, **kwargs)\n",
        "    \n",
        "    # Replace the __init__ method with the new one\n",
        "    cls.__init__ = new_init\n",
        "\n",
        "    CLASSES[cls.__name__] = cls\n",
        "    \n",
        "    # Call the original __init_subclass__ method\n",
        "    super(nn.Module, cls).__init_subclass__(**kwargs)\n",
        "\n",
        "# Override the __init_subclass__ method of nn.Module\n",
        "setattr(nn.Module, '__init_subclass__', classmethod(_init_subclass))\n",
        "\n",
        "\n",
        "def save_model(model: nn.Module, folder: str):\n",
        "    model_info = {\n",
        "        \"class_name\": model.__class__.__name__,\n",
        "        \"args\": model._init_args,\n",
        "        \"kwargs\": model._init_kwargs\n",
        "    }\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    save_json(model_info, os.path.join(folder, \"model_info.json\"))\n",
        "    torch.save(model.state_dict(), os.path.join(folder, \"model.pth\"))\n",
        "\n",
        "def load_model(folder: str):\n",
        "    model_info = load_json(os.path.join(folder, \"model_info.json\"))\n",
        "    model_class = CLASSES[model_info[\"class_name\"]]\n",
        "    model = model_class(*model_info[\"args\"], **model_info[\"kwargs\"])\n",
        "    model.load_state_dict(torch.load(os.path.join(folder, \"model.pth\")))\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, param1, param2):\n",
        "        super().__init__()\n",
        "        self.param1 = param1\n",
        "        self.param2 = param2\n",
        "\n",
        "# Instantiate the model\n",
        "model = MyModel(10, param2=20)\n",
        "\n",
        "# Check stored init arguments\n",
        "print(model._init_args)     # Output: (10, 20)\n",
        "print(model._init_kwargs)   # Output: {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 317.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.model_sampler.initial_models[0]=SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "Original item: FunctionSamplesItem(tensor([[0.2360],\n",
            "        [0.2867]]), tensor([[-0.5584],\n",
            "        [-0.6038]]), SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "Posterior mean: -0.5817\n",
            "Posterior std: 0.00248\n",
            "dataset_tr.model_sampler.initial_models[0]=SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "tensor([[-0.5811]]) tensor([[-0.5278]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from math import exp\n",
        "\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    n_datapoints=2, dimension=1, dataset_size=2,\n",
        "    randomize_params=False).fix_samples(lazy=False)\n",
        "\n",
        "# model = get_gp(\n",
        "#     dimension=1,\n",
        "#      outcome_transform=Standardize(m=1),\n",
        "#      observation_noise=False)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     n_datapoints=2, dataset_size=1, models=[model], dimension=1,\n",
        "#     randomize_params=False).fix_samples(lazy=False)\n",
        "\n",
        "print(f'{dataset.model_sampler.initial_models[0]=}')\n",
        "\n",
        "original_item = dataset[0]\n",
        "print(\"Original item:\", original_item)\n",
        "\n",
        "x_midpoint = (original_item.x_values[0, 0].item() + original_item.x_values[1, 0].item()) / 2\n",
        "\n",
        "model = copy.deepcopy(original_item.model)\n",
        "model.set_train_data_with_transforms(\n",
        "    original_item.x_values, original_item.y_values, strict=False, train=False)\n",
        "posterior = model.posterior(torch.tensor([[x_midpoint]]))\n",
        "original_mean = posterior.mean\n",
        "print(f\"Posterior mean: {original_mean.item():.4f}\")\n",
        "print(f\"Posterior std: {posterior.variance.sqrt().item():.5f}\")\n",
        "\n",
        "\n",
        "# dataset_tr = dataset.standardize_outcomes().transform_outcomes(Exp())\n",
        "# dataset_tr = dataset.transform_outcomes(Exp())\n",
        "# dataset_tr = dataset.transform_outcomes(Exp()).standardize_outcomes()\n",
        "dataset_tr = dataset.standardize_outcomes()\n",
        "print(f'{dataset_tr.model_sampler.initial_models[0]=}')\n",
        "\n",
        "print(dataset_tr[0].model.outcome_transform._original_transform.means,\n",
        "      dataset_tr[1].model.outcome_transform._original_transform.means)\n",
        "\n",
        "# # Do the same thing for the transformed:\n",
        "# transformed_item = dataset_tr[0]\n",
        "# transformed_item.model.eval()\n",
        "# print(\"Transformed item:\", dataset_tr[0])\n",
        "\n",
        "# model_tr = copy.deepcopy(transformed_item.model)\n",
        "\n",
        "# model_tr.set_train_data_with_transforms(\n",
        "#     transformed_item.x_values, transformed_item.y_values, strict=False, train=False)\n",
        "# posterior_tr = model_tr.posterior(torch.tensor([[x_midpoint]]))\n",
        "# tr_mean = posterior_tr.mean\n",
        "# print(f\"Posterior mean: {tr_mean.item():.4f}\")\n",
        "# print(f\"Posterior std: {posterior_tr.variance.sqrt().item():.5f}\")\n",
        "\n",
        "# expected_transformed_mean, _ = model_tr.outcome_transform.untransform(original_mean)\n",
        "# print(f\"Expected transformed mean: {expected_transformed_mean.item():.4f}\")\n",
        "\n",
        "# # print(dataset.model_sampler.initial_models[0].state_dict())\n",
        "# # print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n",
        "# print(f\"{model_tr.state_dict()=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 211.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 569.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.7186e-20,  8.5170e-02,\n",
            "          1.9758e-93,  1.0364e-80,  3.4127e-04,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, 1.5187e-204,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.2263e-08,  0.0000e+00, 6.6943e-118,  2.2489e-01, 2.6425e-152,\n",
            "          0.0000e+00,  2.2871e-05,  1.1340e-01,  0.0000e+00,  1.3600e-01],\n",
            "        [ 0.0000e+00,  2.2919e-04,  9.3640e-04,  0.0000e+00,  0.0000e+00,\n",
            "          9.0613e-12,  0.0000e+00,  0.0000e+00,  4.1826e-02,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, 3.0445e-305,  0.0000e+00]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  9.7186e-20,  8.5170e-02,\n",
            "          1.9758e-93,  1.0364e-80,  3.4127e-04,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, 1.5187e-204,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.2263e-08,  0.0000e+00, 6.6943e-118,  2.2489e-01, 2.6425e-152,\n",
            "          0.0000e+00,  2.2871e-05,  1.1340e-01,  0.0000e+00,  1.3600e-01],\n",
            "        [ 0.0000e+00,  2.2919e-04,  9.3640e-04,  0.0000e+00,  0.0000e+00,\n",
            "          9.0613e-12,  0.0000e+00,  0.0000e+00,  4.1826e-02,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, 3.0445e-305,  0.0000e+00]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "tensor(3.1671e-05, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from utils import calculate_batch_improvement\n",
        "from predict_EI_simple import calculate_EI_GP_padded_batch\n",
        "from train_acquisition_function_net import mse_loss\n",
        "\n",
        "def get_improvements_ei(seed, standardize_outcomes):\n",
        "    torch.manual_seed(seed)\n",
        "    dataset = GaussianProcessRandomDataset(\n",
        "        n_datapoints=20, dimension=1, dataset_size=20,\n",
        "        randomize_params=False).fix_samples(lazy=False)\n",
        "\n",
        "    if standardize_outcomes:\n",
        "        dataset = dataset.standardize_outcomes()\n",
        "\n",
        "    acq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "        dataset, n_candidate_points=10, give_improvements=False)\n",
        "    dataloader = acq_dataset.get_dataloader(batch_size=5)\n",
        "    batch = next(iter(dataloader))\n",
        "    x_hist, y_hist, x_cand, y_cand, hist_mask, cand_mask = batch.tuple_no_model\n",
        "    batch_models = batch.model\n",
        "    improvements = calculate_batch_improvement(\n",
        "        y_hist, y_cand, hist_mask, cand_mask).squeeze(-1)\n",
        "    ei_values_true_model = calculate_EI_GP_padded_batch(\n",
        "        x_hist, y_hist, x_cand, hist_mask, cand_mask, batch_models)\n",
        "    return improvements, ei_values_true_model, batch_models, cand_mask\n",
        "\n",
        "seed = 11\n",
        "improvements, ei_vals, batch_models, cand_mask = get_improvements_ei(seed, False)\n",
        "\n",
        "improvements_st, ei_vals_st, batch_models_st, cand_mask = get_improvements_ei(seed, True)\n",
        "\n",
        "means = torch.stack([\n",
        "    m.outcome_transform._original_transform.means.squeeze(-1)\n",
        "     for m in batch_models_st\n",
        "])\n",
        "stdvs = torch.stack([\n",
        "    m.outcome_transform._original_transform.stdvs.squeeze(-1)\n",
        "    for m in batch_models_st\n",
        "])\n",
        "improvements_st_manual = improvements / stdvs\n",
        "# print(improvements_st_manual)\n",
        "# print(improvements_st)\n",
        "\n",
        "ei_vals_st_manual = ei_vals / stdvs\n",
        "print(ei_vals_st_manual)\n",
        "print(ei_vals_st)\n",
        "print(mse_loss(ei_vals, improvements, cand_mask, reduction='mean'))\n",
        "\n",
        "\n",
        "# mse = mse_loss(ei_values_true_model, improvements, cand_mask, reduction='mean')\n",
        "\n",
        "# print(batch_models[0].outcome_transform._original_transform.means, \"old\")\n",
        "# print(batch_models[0].outcome_transform._original_transform.means, \"alon\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 6463/10009 [00:14<00:08, 423.75it/s]/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
            "  warnings.warn(\n",
            "100%|██████████| 10009/10009 [00:21<00:00, 468.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from FunctionSamplesAcquisitionDataset into ListMapAcquisitionDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10009/10009 [00:01<00:00, 7386.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from FunctionSamplesAcquisitionDataset into ListMapAcquisitionDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10009/10009 [00:01<00:00, 9572.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_hist=13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Padding: 100%|██████████| 10009/10009 [00:00<00:00, 30935.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding took 0.326494 seconds\n",
            "max_hist=13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Padding: 100%|██████████| 10009/10009 [00:00<00:00, 33634.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding took 0.300056 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2002/2002 [00:47<00:00, 41.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 47.889229 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2002/2002 [00:49<00:00, 40.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time: 49.402633 seconds\n",
            "GP MSE: 8.838029159958789e-05\n",
            "GP MSE standardized: 0.0026355975175581356\n",
            "\n",
            "8.838029159958784e-05\n",
            "0.002635597517558133\n",
            "\n",
            "8.8380291599588e-05\n",
            "0.00263559751755813\n",
            "\n",
            "8.8380291599588e-05\n",
            "0.0026355975121370883\n"
          ]
        }
      ],
      "source": [
        "from train_acquisition_function_net import train_or_test_loop\n",
        "from utils import calculate_batch_improvement\n",
        "from predict_EI_simple import calculate_EI_GP_padded_batch, calculate_EI_GP\n",
        "from train_acquisition_function_net import mse_loss\n",
        "\n",
        "\n",
        "def get_gp_improvements_mse(dataloader):\n",
        "    total_mse = 0.0\n",
        "    total_size = 0\n",
        "    for batch in dataloader:\n",
        "        x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models = batch\n",
        "        improvements = vals_cand if batch.give_improvements else \\\n",
        "            calculate_batch_improvement(y_hist, vals_cand, hist_mask, cand_mask)\n",
        "        improvements = improvements.squeeze(-1)\n",
        "        ei_values_true_model = calculate_EI_GP_padded_batch(\n",
        "            x_hist, y_hist, x_cand, hist_mask, cand_mask, models)\n",
        "        mse = mse_loss(ei_values_true_model, improvements, cand_mask, reduction='sum')\n",
        "        total_mse += mse.item()\n",
        "        total_size += x_hist.size(0)\n",
        "    return total_mse / total_size\n",
        "\n",
        "def get_gp_improvements_mse_2(acq_dataset):\n",
        "    total_mse = 0.0\n",
        "    total_size = 0\n",
        "    for item in acq_dataset:\n",
        "        x_hist, y_hist, x_cand, vals_cand, model = item\n",
        "        improvements = vals_cand if item.give_improvements else \\\n",
        "            torch.nn.functional.relu(\n",
        "                    vals_cand - y_hist.amax(0, keepdim=True))\n",
        "        improvements = improvements.squeeze(-1).unsqueeze(0)\n",
        "        ei_values_true_model = calculate_EI_GP(model, x_hist, y_hist, x_cand).unsqueeze(0)\n",
        "        mse = mse_loss(ei_values_true_model, improvements, None, reduction='mean') # doesn't matter\n",
        "\n",
        "        # print(improvements)\n",
        "        # print(ei_values_true_model)\n",
        "        # print()\n",
        "\n",
        "        total_mse += mse.item()\n",
        "        total_size += 1\n",
        "    return total_mse / total_size\n",
        "\n",
        "\n",
        "def get_gp_improvements_mse_3(acq_dataset):\n",
        "    total_mse = 0.0\n",
        "    total_size = 0\n",
        "    for item in acq_dataset:\n",
        "        x_hist, y_hist, x_cand, vals_cand, model = item\n",
        "        \n",
        "        \n",
        "        has_outcome_transform = hasattr(model, \"outcome_transform\")\n",
        "\n",
        "        if has_outcome_transform:\n",
        "            # print(model.outcome_transform._original_transform.training,\n",
        "            #       model.outcome_transform._original_transform.training)\n",
        "            means = model.outcome_transform._original_transform.means.item()\n",
        "            stdvs = model.outcome_transform._original_transform.stdvs.item()\n",
        "            # print(stdvs)\n",
        "\n",
        "            y_hist = means + stdvs * y_hist\n",
        "            if item.give_improvements:\n",
        "                vals_cand = stdvs * vals_cand\n",
        "            else:\n",
        "                vals_cand = means + stdvs * vals_cand\n",
        "            \n",
        "            del model.outcome_transform\n",
        "\n",
        "        improvements = vals_cand if item.give_improvements else \\\n",
        "            torch.nn.functional.relu(\n",
        "                    vals_cand - y_hist.amax(0, keepdim=True))\n",
        "        improvements = improvements.squeeze(-1).unsqueeze(0)\n",
        "        ei_values_true_model = calculate_EI_GP(model, x_hist, y_hist, x_cand).unsqueeze(0)\n",
        "\n",
        "        # print(vals_cand)\n",
        "        # print(ei_values_true_model)\n",
        "        # print()\n",
        "\n",
        "        mse = mse_loss(ei_values_true_model, improvements, None, reduction='mean') # doesn't matter\n",
        "\n",
        "        if has_outcome_transform:\n",
        "            mse = mse / stdvs**2\n",
        "\n",
        "        total_mse += mse.item()\n",
        "        total_size += 1\n",
        "    return total_mse / total_size\n",
        "\n",
        "\n",
        "seed = 1031\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "fn_dataset = GaussianProcessRandomDataset(\n",
        "    n_datapoints=19, dimension=1, dataset_size=10009,\n",
        "    randomize_params=False).fix_samples(lazy=False)\n",
        "\n",
        "fn_dataset_st = fn_dataset.standardize_outcomes()\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "acq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    fn_dataset, n_candidate_points=6, give_improvements=False\n",
        "    ).fix_samples(lazy=False)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "acq_dataset_st = FunctionSamplesAcquisitionDataset(\n",
        "    fn_dataset_st, n_candidate_points=6, give_improvements=False\n",
        "    ).fix_samples(lazy=False)\n",
        "\n",
        "dataloader = acq_dataset.get_dataloader(batch_size=5, drop_last=False)\n",
        "dataloader_st = acq_dataset_st.get_dataloader(batch_size=5, drop_last=False)\n",
        "\n",
        "stats = train_or_test_loop(dataloader)\n",
        "stats_st = train_or_test_loop(dataloader_st)\n",
        "print('GP MSE:', stats['true_gp_mse'])\n",
        "print('GP MSE standardized:', stats_st['true_gp_mse'])\n",
        "print()\n",
        "print(get_gp_improvements_mse(dataloader))\n",
        "print(get_gp_improvements_mse(dataloader_st))\n",
        "print()\n",
        "print(get_gp_improvements_mse_2(acq_dataset))\n",
        "print(get_gp_improvements_mse_2(acq_dataset_st))\n",
        "print()\n",
        "print(get_gp_improvements_mse_3(acq_dataset))\n",
        "print(get_gp_improvements_mse_3(acq_dataset_st))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6009, 2.4679], grad_fn=<SqueezeBackward1>)\n",
            "tensor([0.6013, 2.4679], grad_fn=<SqueezeBackward1>)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dim = 1\n",
        "train_X = torch.rand(10, dim, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model = get_gp(\n",
        "    dimension=dim,\n",
        "     # train_X, train_Y,\n",
        "     covar_module=ScaleKernel(MaternKernel(ard_num_dims=dim, nu=0.5)),\n",
        "     outcome_transform=Standardize(m=1),\n",
        "    #  input_transform=Normalize(d=dim),\n",
        "     observation_noise=False)\n",
        "model.outcome_transform=Log()\n",
        "model.eval()\n",
        "# model.train_inputs = None\n",
        "# model.train_targets = None\n",
        "\n",
        "# print(model.covar_module.base_kernel.lengthscale)\n",
        "# model.initialize(**{'covar_module.base_kernel.lengthscale': 0.05})\n",
        "# model.covar_module.base_kernel.lengthscale = 0.1\n",
        "# print(model.covar_module.base_kernel.lengthscale)\n",
        "\n",
        "sample_path = draw_kernel_feature_paths(model, sample_shape=torch.Size(), num_features=4096)\n",
        "# sample_path = RandomGPFunction(model, observation_noise=False)\n",
        "\n",
        "test_x = torch.linspace(-4.9, -4.9+2.3, 200).unsqueeze(-1)\n",
        "test_y = sample_path(test_x).detach()\n",
        "plt.plot(test_x.squeeze(-1), test_y)\n",
        "\n",
        "print(sample_path(torch.tensor([[-4.9], [0.1]], dtype=torch.float64)))\n",
        "\n",
        "# model.initialize(**{'covar_module.base_kernel.lengthscale': 0.06})\n",
        "\n",
        "# print(sample_path(torch.tensor([[0.0, 0.0], [1.2, 3.4]], dtype=torch.float64)))\n",
        "# print(sample_path(torch.tensor([[1.2, 3.4]], dtype=torch.float64)))\n",
        "\n",
        "test_x = torch.linspace(-4.9, -4.9+2.3, 200).unsqueeze(-1)\n",
        "test_y = sample_path(test_x).detach()\n",
        "\n",
        "# print(sample_path(torch.tensor([[-4.9], [0.1]], dtype=torch.float64)))\n",
        "print(sample_path(torch.tensor([[-4.9+1e-4], [0.1]], dtype=torch.float64)))\n",
        "\n",
        "plt.plot(test_x.squeeze(-1), test_y)\n",
        "# plt.scatter(train_X.squeeze(-1), train_Y.squeeze(-1))\n",
        "plt.xlabel('test_x')\n",
        "plt.ylabel('y_samples')\n",
        "plt.title('GP realization')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dictionaries: {'a': 1, 'b': 5, 'c': 3, 'd': 4, 'e': 6}\n",
            "\n",
            "Dictionary product:\n",
            "{'x': 1, 'y': 'a', 'z': True}\n",
            "{'x': 1, 'y': 'a', 'z': False}\n",
            "{'x': 1, 'y': 'b', 'z': True}\n",
            "{'x': 1, 'y': 'b', 'z': False}\n",
            "{'x': 2, 'y': 'a', 'z': True}\n",
            "{'x': 2, 'y': 'a', 'z': False}\n",
            "{'x': 2, 'y': 'b', 'z': True}\n",
            "{'x': 2, 'y': 'b', 'z': False}\n",
            "\n",
            "Dictionary product with overlapping keys:\n",
            "{'a': 1, 'b': 5, 'd': 6}\n",
            "{'a': 1, 'b': 2, 'c': 7, 'e': 8}\n",
            "{'a': 3, 'c': 4, 'b': 5, 'd': 6}\n",
            "{'a': 3, 'c': 7, 'e': 8}\n"
          ]
        }
      ],
      "source": [
        "from utils import dict_product, combine_dicts\n",
        "\n",
        "# Test combine_dicts\n",
        "dict_list = [{'a': 1, 'b': 2}, {'c': 3, 'd': 4}, {'b': 5, 'e': 6}]\n",
        "combined = combine_dicts(dict_list)\n",
        "print(\"Combined dictionaries:\", combined)\n",
        "\n",
        "# Test dict_product\n",
        "list1 = [{'x': 1}, {'x': 2}]\n",
        "list2 = [{'y': 'a'}, {'y': 'b'}]\n",
        "list3 = [{'z': True}, {'z': False}]\n",
        "\n",
        "product = dict_product(list1, list2, list3)\n",
        "print(\"\\nDictionary product:\")\n",
        "for item in product:\n",
        "    print(item)\n",
        "\n",
        "# Test with overlapping keys\n",
        "list4 = [{'a': 1, 'b': 2}, {'a': 3, 'c': 4}]\n",
        "list5 = [{'b': 5, 'd': 6}, {'c': 7, 'e': 8}]\n",
        "\n",
        "product_overlap = dict_product(list4, list5)\n",
        "print(\"\\nDictionary product with overlapping keys:\")\n",
        "for item in product_overlap:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('a', 'a'), ('a', 'c'), ('b', 'a'), ('b', 'c')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "list(itertools.product(*list4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['3.4', '23', 'bi'], dtype='<U32')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [3.4, 23, 'bi']\n",
        "import numpy as np\n",
        "np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1, 2}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set((1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial model:\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "\n",
            "model priors:\n",
            "[('likelihood.noise_covar.noise_prior', HomoskedasticNoise(\n",
            "  (noise_prior): GammaPrior()\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "), GammaPrior(), <bound method _HomoskedasticNoiseBase._noise_param of HomoskedasticNoise(\n",
            "  (noise_prior): GammaPrior()\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            ")>, <bound method _HomoskedasticNoiseBase._noise_closure of HomoskedasticNoise(\n",
            "  (noise_prior): GammaPrior()\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            ")>), ('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n",
            "\n",
            "model with priors removed:\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "\n",
            "model priors:\n",
            "[]\n",
            "\n",
            "model with priors added back:\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "      (noise_prior): GammaPrior()\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "    )\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "    (outputscale_prior): GammaPrior()\n",
            "  )\n",
            ")\n",
            "\n",
            "model priors:\n",
            "[('likelihood.noise_covar.noise_prior', HomoskedasticNoise(\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "  (noise_prior): GammaPrior()\n",
            "), GammaPrior(), <bound method _HomoskedasticNoiseBase._noise_param of HomoskedasticNoise(\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "  (noise_prior): GammaPrior()\n",
            ")>, <bound method _HomoskedasticNoiseBase._noise_closure of HomoskedasticNoise(\n",
            "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "  (noise_prior): GammaPrior()\n",
            ")>), ('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "  )\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "  (outputscale_prior): GammaPrior()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "  )\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "  (outputscale_prior): GammaPrior()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "  )\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "  (outputscale_prior): GammaPrior()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "  (lengthscale_prior): GammaPrior()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "  (lengthscale_prior): GammaPrior()\n",
            ")>)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.4247]), std = tensor([0.5279])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        }
      ],
      "source": [
        "from botorch.test_functions import Hartmann\n",
        "from utils import remove_priors, add_priors\n",
        "objective = Hartmann(negate=True)\n",
        "x = torch.rand(20, 6, device=device, dtype=torch.float64)\n",
        "y = objective(x).unsqueeze(-1)  # add output dimension\n",
        "\n",
        "model = get_gp(x, y, observation_noise=True)\n",
        "\n",
        "print(\"initial model:\")\n",
        "print(model)\n",
        "\n",
        "print(\"\\nmodel priors:\")\n",
        "print(list(model.named_priors()))\n",
        "\n",
        "named_priors_tuple_list = remove_priors(model)\n",
        "\n",
        "print(\"\\nmodel with priors removed:\")\n",
        "print(model)\n",
        "print(\"\\nmodel priors:\")\n",
        "print(list(model.named_priors()))\n",
        "\n",
        "add_priors(named_priors_tuple_list)\n",
        "\n",
        "print(\"\\nmodel with priors added back:\")\n",
        "print(model)\n",
        "print(\"\\nmodel priors:\")\n",
        "print(list(model.named_priors()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 6, 2])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "dim = 2\n",
        "bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
        "n_initial_samples = 6\n",
        "draw_sobol_samples(bounds=bounds, n=5, q=n_initial_samples).shape\n",
        "# torch.rand(n_initial_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.1981]), std = tensor([0.2508])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True TRAINING\n",
            "INITIAL: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n",
            "True TRAINING\n",
            "FITTING\n",
            "FIT: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.1712, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(-3.0060, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-5.7663e-01,  4.9056e+03, -1.0409e+00, -1.4963e+00,  2.1436e+03,\n",
            "          3.8301e+03]], requires_grad=True))]\n",
            "INITIAL: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n",
            "tensor([[0.0000, 0.2671, 0.0000, 0.0000, 0.1182, 0.5919]])\n",
            "tensor(0.2644)\n"
          ]
        }
      ],
      "source": [
        "from botorch.test_functions import Hartmann\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.acquisition import ExpectedImprovement\n",
        "from botorch.optim import optimize_acqf\n",
        "\n",
        "objective = Hartmann(negate=True)\n",
        "x = torch.rand(20, 6, device=device, dtype=torch.float64)\n",
        "y = objective(x).unsqueeze(-1)  # add output dimension\n",
        "\n",
        "\n",
        "best = [y.max()] # This will store the best value\n",
        "\n",
        "n_dims = x.shape[-1]\n",
        "bounds = torch.tensor([[0.0] * n_dims, [1.0] * n_dims])\n",
        "\n",
        "\n",
        "kernel = ScaleKernel(\n",
        "    base_kernel=RBFKernel(\n",
        "        ard_num_dims=n_dims,\n",
        "    )\n",
        ")\n",
        "\n",
        "# model = SingleTaskGP(x, y, torch.full_like(y, 1e-5),\n",
        "#                          covar_module=kernel,\n",
        "#                         )\n",
        "# print(list(model.named_parameters()))\n",
        "# mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "# fit_gpytorch_mll(mll)\n",
        "# print(list(model.named_parameters()))\n",
        "\n",
        "import copy\n",
        "model = SingleTaskGP(x, y, torch.full_like(y, 1e-5),\n",
        "                         covar_module=kernel,\n",
        "                        )\n",
        "print(model.training, \"TRAINING\")\n",
        "print(\"INITIAL:\", list(model.named_parameters()))\n",
        "model_fit = copy.deepcopy(model)\n",
        "mll = ExactMarginalLogLikelihood(model_fit.likelihood, model_fit)\n",
        "fit_gpytorch_mll(mll)\n",
        "print(model.training, \"TRAINING\")\n",
        "print(\"FITTING\")\n",
        "print(\"FIT:\", list(model_fit.named_parameters()))\n",
        "print(\"INITIAL:\", list(model.named_parameters()))\n",
        "\n",
        "\n",
        "BoTorch_EI = ExpectedImprovement(model=model, best_f=y.max())\n",
        "new_point, new_point_EI = optimize_acqf(\n",
        "        acq_function=BoTorch_EI,\n",
        "        bounds=bounds,\n",
        "        q=1,\n",
        "        num_restarts=100,\n",
        "        raw_samples=500,\n",
        "        options={},\n",
        "    )\n",
        "print(new_point)\n",
        "print(new_point_EI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.1798]), std = tensor([0.2306])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FIT1: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.1722, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(-3.0826, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.8575e+00,  1.1294e+03,  1.0966e+04, -1.7604e+00,  2.8340e-03,\n",
            "          1.9293e-01]], requires_grad=True))]\n",
            "FIT2 with warm start after initial fit: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.3120, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(-1.6184, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 1.0885e+04,  1.1294e+03,  1.0966e+04, -2.2300e+00, -1.7695e+00,\n",
            "          4.1100e+03]], requires_grad=True))]\n",
            "FIT2 with no warm start: [('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.3790, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(-1.3248, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-4.4086e-01, -6.0468e-01,  1.4503e+03, -3.6007e-01, -1.1572e+00,\n",
            "          1.2651e+03]], requires_grad=True))]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.2602]), std = tensor([0.4106])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        }
      ],
      "source": [
        "objective = Hartmann(negate=True)\n",
        "x = torch.rand(20, 6, device=device, dtype=torch.float64)\n",
        "y = objective(x).unsqueeze(-1)  # add output dimension\n",
        "n_dims = x.shape[-1]\n",
        "\n",
        "x2 = torch.rand(20, 6, device=device, dtype=torch.float64)\n",
        "y2 = objective(x2).unsqueeze(-1)  # add output dimension\n",
        "\n",
        "model = SingleTaskGP(x, y, torch.full_like(y, 1e-5),\n",
        "                         covar_module=ScaleKernel(base_kernel=RBFKernel(ard_num_dims=n_dims)))\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "print(\"FIT1:\", list(model.named_parameters()))\n",
        "\n",
        "model.set_train_data(x2, y2.squeeze(-1), strict=False)\n",
        "fit_gpytorch_mll(mll)\n",
        "print(\"FIT2 with warm start after initial fit:\", list(model.named_parameters()))\n",
        "\n",
        "model2 = SingleTaskGP(x2, y2, torch.full_like(y, 1e-5),\n",
        "                         covar_module=ScaleKernel(base_kernel=RBFKernel(ard_num_dims=n_dims)))\n",
        "mll2 = ExactMarginalLogLikelihood(model2.likelihood, model2)\n",
        "fit_gpytorch_mll(mll2)\n",
        "print(\"FIT2 with no warm start:\", list(model2.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "objective = Hartmann(negate=True)\n",
        "x = torch.rand(20, 6, device=device, dtype=torch.float64)\n",
        "y = objective(x).unsqueeze(-1)  # add output dimension\n",
        "n_dims = x.shape[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1981]]) tensor([[0.2508]])\n",
            "model.training=True, model.outcome_transform.training=True\n",
            "tensor([[0.1981]]) tensor([[0.2508]])\n",
            "model.training=False, model.outcome_transform.training=False\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.0162], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(-0.0500, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0.1866, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7757, -0.1961, -0.9707, -0.9451, -0.6710, -0.3694]],\n",
            "       requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from botorch.models.transforms.outcome import Standardize\n",
        "\n",
        "model = SingleTaskGP(x, y, outcome_transform=Standardize(m=1))\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(model.outcome_transform.means, model.outcome_transform.stdvs)\n",
        "    print(f\"{model.training=}, {model.outcome_transform.training=}\")\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(model.outcome_transform.means, model.outcome_transform.stdvs)\n",
        "    print(f\"{model.training=}, {model.outcome_transform.training=}\")\n",
        "print(list(model.named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [False],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [False],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]]])\n",
            "tensor([[[False],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]],\n",
            "\n",
            "        [[ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True],\n",
            "         [ True]]])\n",
            "tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]],\n",
            "\n",
            "        [[0.3962],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]],\n",
            "\n",
            "        [[0.0000],\n",
            "         [0.0000],\n",
            "         [0.2383],\n",
            "         [0.3791],\n",
            "         [0.0000]],\n",
            "\n",
            "        [[0.0000],\n",
            "         [0.0902],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.7228]]])\n"
          ]
        }
      ],
      "source": [
        "from utils import calculate_batch_improvement\n",
        "import torch\n",
        "\n",
        "# Example Usage\n",
        "batch_size = 4\n",
        "max_n_hist = 10\n",
        "max_n_cand = 5\n",
        "\n",
        "# Example y_hist_batch with padding and hist_mask\n",
        "y_hist_batch = torch.randn(batch_size, max_n_hist, 1)\n",
        "hist_mask = (torch.rand(batch_size, max_n_hist, 1) > 0.1)  # Random hist_mask for example\n",
        "print(hist_mask)\n",
        "\n",
        "# Example y_cand_batch with padding and cand_mask\n",
        "y_cand_batch = torch.randn(batch_size, max_n_cand, 1)\n",
        "cand_mask = (torch.rand(batch_size, max_n_cand, 1) > 0.1)  # Random cand_mask for example\n",
        "print(cand_mask)\n",
        "\n",
        "improvement_values_batch = calculate_batch_improvement(y_hist_batch, y_cand_batch, hist_mask, cand_mask)\n",
        "print(improvement_values_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "example_illegal_name_______.txtwithspacfuckes\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def sanitize_file_name(file_name: str) -> str:\n",
        "    # Define a dictionary of characters to replace\n",
        "    replacements = {\n",
        "        '/': '_',\n",
        "        '\\\\': '_',\n",
        "        ':': '_',\n",
        "        '*': '_',\n",
        "        '?': '_',\n",
        "        '\"': '_',\n",
        "        '<': '_',\n",
        "        '>': '_',\n",
        "        '|': '_',\n",
        "    }\n",
        "\n",
        "    # Replace the characters based on the replacements dictionary\n",
        "    sanitized_name = ''.join(replacements.get(c, c) for c in file_name)\n",
        "\n",
        "    # Remove characters that are non-printable or not allowed\n",
        "    sanitized_name = re.sub(r'[^\\x20-\\x7E]', '', sanitized_name)\n",
        "\n",
        "    # Remove all whitespace characters\n",
        "    sanitized_name = re.sub(r'\\s+', '', sanitized_name)\n",
        "\n",
        "    return sanitized_name\n",
        "\n",
        "# Example usage\n",
        "proposed_file_name = \"example/illegal\\\\name:*?\\\"<>|.txt with spac\\nfuck\\nes\"\n",
        "sanitized_file_name = sanitize_file_name(proposed_file_name)\n",
        "print(sanitized_file_name)  # Output: example_illegal_name_.txt_with_spaces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "FunctionSamplesItem(tensor([[0.8516, 0.2163],\n",
            "        [0.5338, 0.5516],\n",
            "        [0.1333, 0.9557]]), tensor([[0.5394],\n",
            "        [1.2450],\n",
            "        [3.9864]]), SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "\n",
            "-----Transforming outcomes with Exp------\n",
            "FunctionSamplesItem(tensor([[0.8516, 0.2163],\n",
            "        [0.5338, 0.5516],\n",
            "        [0.1333, 0.9557]]), tensor([[ 1.7150],\n",
            "        [ 3.4729],\n",
            "        [53.8614]]), SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            "  (outcome_transform): Log()\n",
            "))\n",
            "\n",
            "-----Standardizing outcomes------\n",
            "Unstandardize(\n",
            "  (_original_transform): Standardize()\n",
            ")\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from botorch.models.transforms.outcome import Power\n",
        "from utils import Exp\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    n_datapoints=3, observation_noise=False,\n",
        "    dimension=2, randomize_params=True)\n",
        "# u = next(dataset)\n",
        "# a = u.model\n",
        "# v = next(dataset)\n",
        "# b = v.model\n",
        "\n",
        "q = dataset.fix_samples(1, lazy=False)\n",
        "print(q[0]._model is dataset.model_sampler._models[0])\n",
        "print(q.model_sampler is dataset.model_sampler)\n",
        "print(q.model_sampler._models is dataset.model_sampler._models)\n",
        "print(q.model_sampler._models[0] is dataset.model_sampler._models[0])\n",
        "# print(q[0]._model)\n",
        "# print(dataset.model_sampler._models[0])\n",
        "\n",
        "# print(list(dataset.model_sampler._models[0].named_parameters()))\n",
        "for w in q:\n",
        "    print(w)\n",
        "\n",
        "print(\"\\n-----Transforming outcomes with Exp------\")\n",
        "q = q.transform_outcomes(Exp())\n",
        "\n",
        "for w in q:\n",
        "    print(w)\n",
        "\n",
        "print(\"\\n-----Standardizing outcomes------\")\n",
        "q = q.standardize_outcomes()\n",
        "\n",
        "for w in q:\n",
        "    print(w.model_params['outcome_transform'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "cannot delete function call (1259788926.py, line 12)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    del getattr(inferred_noise_model, \"outcome_transform\")\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot delete function call\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "\n",
        "\n",
        "train_X = torch.rand(20, 2, dtype=torch.float64)\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
        "outcome_transform = Standardize(m=1)\n",
        "inferred_noise_model = SingleTaskGP(\n",
        "     train_X, train_Y, outcome_transform=outcome_transform,\n",
        " )\n",
        "# list(inferred_noise_model.named_parameters())\n",
        "del getattr(inferred_noise_model, \"outcome_transform\")\n",
        "inferred_noise_model.outcome_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([ 0.3948, -1.7935, -0.8180,  0.3494, -0.2001,  0.1001, -0.2954,  0.4537,\n",
            "         2.0997, -0.2908], dtype=torch.float64)\n",
            "Calling model on some data\n",
            "model.training=False\n",
            "model._has_transformed_inputs=True\n",
            "model.train_inputs=(tensor([[0.7102, 0.1549],\n",
            "        [0.7035, 1.0000],\n",
            "        [1.0000, 0.3079],\n",
            "        [0.7362, 0.0025],\n",
            "        [0.2533, 0.9342],\n",
            "        [0.8057, 0.0000],\n",
            "        [0.3650, 0.8843],\n",
            "        [0.7010, 0.1131],\n",
            "        [0.0000, 0.2348],\n",
            "        [0.5883, 0.6833]], dtype=torch.float64),)\n",
            "Conditioning model on observations\n",
            "conditioned_model.training=False\n",
            "conditioned_model._has_transformed_inputs=True\n",
            "conditioned_model.train_inputs=[tensor([[ 7.1019e-01,  1.5492e-01],\n",
            "        [ 7.0347e-01,  1.0000e+00],\n",
            "        [ 1.0000e+00,  3.0792e-01],\n",
            "        [ 7.3619e-01,  2.4605e-03],\n",
            "        [ 2.5326e-01,  9.3416e-01],\n",
            "        [ 8.0567e-01,  0.0000e+00],\n",
            "        [ 3.6505e-01,  8.8430e-01],\n",
            "        [ 7.0097e-01,  1.1313e-01],\n",
            "        [ 0.0000e+00,  2.3482e-01],\n",
            "        [ 5.8832e-01,  6.8334e-01],\n",
            "        [-3.1587e+00, -4.6962e+00],\n",
            "        [-3.8841e+00, -2.6259e+00],\n",
            "        [-4.0152e+00, -2.8635e+00],\n",
            "        [-3.0429e+00, -4.7722e+00],\n",
            "        [-3.7615e+00, -3.8339e+00],\n",
            "        [-4.8684e+00, -3.8188e+00]], dtype=torch.float64)]\n",
            "conditioned_model.train_targets=tensor([ 0.3948, -1.7935, -0.8180,  0.3494, -0.2001,  0.1001, -0.2954,  0.4537,\n",
            "         2.0997, -0.2908,  0.0784, -1.8108, -1.1104, -0.1874,  0.5365,  1.4317],\n",
            "       dtype=torch.float64)\n",
            "conditioned_model._original_train_inputs=tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64)\n",
            "Putting conditioned_model into train mode\n",
            "conditioned_model.train_inputs=(tensor([[-3.3207, -4.5048],\n",
            "        [-3.3313, -3.1436],\n",
            "        [-2.8605, -4.2584],\n",
            "        [-3.2794, -4.7504],\n",
            "        [-4.0462, -3.2497],\n",
            "        [-3.1691, -4.7543],\n",
            "        [-3.8687, -3.3300],\n",
            "        [-3.3353, -4.5721],\n",
            "        [-4.4484, -4.3761],\n",
            "        [-3.5142, -3.6537]], dtype=torch.float64),)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Calling model on some data\")\n",
        "test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "posterior = model.posterior(test_X, observation_noise=False)\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "\n",
        "print(\"Conditioning model on observations\")\n",
        "new_X = torch.rand(6, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "new_Y = torch.sin(new_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "conditioned_model = model.condition_on_observations(new_X, new_Y)\n",
        "\n",
        "print(f\"{conditioned_model.training=}\")\n",
        "print(f\"{conditioned_model._has_transformed_inputs=}\")\n",
        "print(f\"{conditioned_model.train_inputs=}\")\n",
        "print(f\"{conditioned_model.train_targets=}\")\n",
        "print(f\"{conditioned_model._original_train_inputs=}\")\n",
        "\n",
        "print(\"Putting conditioned_model into train mode\")\n",
        "conditioned_model.train()\n",
        "print(f\"{conditioned_model.train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64),)\n",
            "model.train_targets=tensor([-0.5637,  1.2837, -1.0384,  1.2481,  0.6752,  0.7921,  0.0285, -1.7573,\n",
            "        -0.2946, -0.3735], dtype=torch.float64)\n",
            "Conditioning model with fantasize\n",
            "conditioned_model.training=False\n",
            "conditioned_model._has_transformed_inputs=True\n",
            "conditioned_model.train_inputs=[tensor([[0.8044, 0.7015],\n",
            "        [0.0000, 0.5023],\n",
            "        [0.6317, 0.9911],\n",
            "        [0.6101, 0.0509],\n",
            "        [0.8198, 0.0000],\n",
            "        [0.5076, 0.5067],\n",
            "        [0.9905, 0.2678],\n",
            "        [1.0000, 0.8923],\n",
            "        [0.1314, 1.0000],\n",
            "        [0.5693, 0.8297],\n",
            "        [0.8321, 0.0569],\n",
            "        [0.9675, 0.3989],\n",
            "        [0.6555, 0.0056],\n",
            "        [0.3748, 0.1025]], dtype=torch.float64)]\n",
            "conditioned_model.train_targets=tensor([-0.5637,  1.2837, -1.0384,  1.2481,  0.6752,  0.7921,  0.0285, -1.7573,\n",
            "        -0.2946, -0.3735,  1.3920,  2.8240,  2.2946,  0.6888],\n",
            "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "conditioned_model._original_train_inputs=tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64)\n",
            "Putting conditioned_model into train mode\n",
            "conditioned_model.train_inputs=(tensor([[-3.3326, -3.3023],\n",
            "        [-4.8419, -3.7348],\n",
            "        [-3.6567, -2.6734],\n",
            "        [-3.6973, -4.7147],\n",
            "        [-3.3038, -4.8252],\n",
            "        [-3.8895, -3.7252],\n",
            "        [-2.9836, -4.2437],\n",
            "        [-2.9657, -2.8881],\n",
            "        [-4.5955, -2.6542],\n",
            "        [-3.7737, -3.0240]], dtype=torch.float64),)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Conditioning model with fantasize\")\n",
        "test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "sampler = SobolQMCNormalSampler(sample_shape=torch.Size([]))\n",
        "conditioned_model = model.fantasize(test_X, sampler)\n",
        "\n",
        "print(f\"{conditioned_model.training=}\")\n",
        "print(f\"{conditioned_model._has_transformed_inputs=}\")\n",
        "print(f\"{conditioned_model.train_inputs=}\")\n",
        "print(f\"{conditioned_model.train_targets=}\")\n",
        "print(f\"{conditioned_model._original_train_inputs=}\")\n",
        "\n",
        "print(\"Putting conditioned_model into train mode\")\n",
        "conditioned_model.train()\n",
        "print(f\"{conditioned_model.train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 6.9473],\n",
            "        [ 3.7036],\n",
            "        [ 8.6021],\n",
            "        [ 7.4870],\n",
            "        [10.6643],\n",
            "        [ 7.5800],\n",
            "        [ 6.7033],\n",
            "        [12.0351],\n",
            "        [10.8833],\n",
            "        [10.0405]])\n",
            "None\n",
            "model.input_transform.training=True\n",
            "model.outcome_transform.training=True\n",
            "model.outcome_transform._is_trained=tensor(True)\n",
            "model.training=True\n",
            "model._has_transformed_inputs=False\n",
            "model.train_inputs=(tensor([[-2.6268, -3.9095],\n",
            "        [-2.7134, -2.7343],\n",
            "        [-4.2767, -2.9533],\n",
            "        [-2.6951, -4.0735],\n",
            "        [-4.1204, -3.7049],\n",
            "        [-2.9049, -3.8290],\n",
            "        [-3.0950, -3.3150],\n",
            "        [-4.2788, -4.2275],\n",
            "        [-3.8524, -4.0360],\n",
            "        [-3.8234, -3.7105]]),)\n",
            "model.train_targets=tensor([-0.6097, -1.9129,  0.0552, -0.3928,  0.8838, -0.3554, -0.7077,  1.4346,\n",
            "         0.9718,  0.6332])\n",
            "model.outcome_transform.means=tensor([[8.4646]])\n",
            "model.outcome_transform.stdvs=tensor([[2.4889]])\n",
            "Setting the train data\n",
            "model.outcome_transform.means=tensor([[9.7376]])\n",
            "model.outcome_transform.stdvs=tensor([[2.6786]])\n",
            "model.outcome_transform.training=False\n",
            "model.outcome_transform._is_trained=tensor(True)\n",
            "model.training=False\n",
            "model._has_transformed_inputs=True\n",
            "model.train_inputs=(tensor([[0.1058, 0.4542],\n",
            "        [0.4191, 0.0000],\n",
            "        [1.0000, 0.6576],\n",
            "        [0.7393, 0.9456],\n",
            "        [0.7571, 1.0000],\n",
            "        [0.0000, 0.2154]]),)\n",
            "model.train_targets=tensor([ 0.8295,  0.8104, -0.7785, -0.8920, -1.0461,  1.0767])\n",
            "Putting in eval mode\n",
            "model.training=False\n",
            "model._has_transformed_inputs=True\n",
            "model.train_inputs=(tensor([[0.1058, 0.4542],\n",
            "        [0.4191, 0.0000],\n",
            "        [1.0000, 0.6576],\n",
            "        [0.7393, 0.9456],\n",
            "        [0.7571, 1.0000],\n",
            "        [0.0000, 0.2154]]),)\n",
            "model._original_train_inputs=tensor([[-4.5328, -4.0438],\n",
            "        [-4.0188, -4.8936],\n",
            "        [-3.0658, -3.6633],\n",
            "        [-3.4935, -3.1246],\n",
            "        [-3.4643, -3.0228],\n",
            "        [-4.7064, -4.4906]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from utils import *\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "print(train_Y)\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2))\n",
        "print(model._original_train_inputs)\n",
        "# model.eval()\n",
        "print(f\"{model.input_transform.training=}\")\n",
        "print(f\"{model.outcome_transform.training=}\")\n",
        "print(f\"{model.outcome_transform._is_trained=}\")\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "# print(\"Calling model on some data\")\n",
        "# test_X = torch.rand(4, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "# posterior = model.posterior(test_X, observation_noise=False)\n",
        "# print(f\"{model.input_transform.training=}\")\n",
        "# print(f\"{model.outcome_transform.training=}\")\n",
        "# print(f\"{model.training=}\")\n",
        "# print(f\"{model._has_transformed_inputs=}\")\n",
        "# print(f\"{model.train_inputs=}\")\n",
        "\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(f\"{model.outcome_transform.means=}\")\n",
        "    print(f\"{model.outcome_transform.stdvs=}\")\n",
        "\n",
        "print(\"Setting the train data\")\n",
        "model.eval()\n",
        "new_X = torch.rand(6, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "new_Y = torch.sin(new_X).sum(dim=1, keepdim=True) * 3.2 + 6.3\n",
        "model.set_train_data_with_transforms(new_X, new_Y, strict=False, train=True)\n",
        "\n",
        "\n",
        "if hasattr(model, \"outcome_transform\"):\n",
        "    print(f\"{model.outcome_transform.means=}\")\n",
        "    print(f\"{model.outcome_transform.stdvs=}\")\n",
        "    print(f\"{model.outcome_transform.training=}\")\n",
        "    print(f\"{model.outcome_transform._is_trained=}\")\n",
        "\n",
        "# model.set_train_data(new_X, new_Y, strict=False)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model.train_targets=}\")\n",
        "\n",
        "print(\"Putting in eval mode\")\n",
        "model.eval()\n",
        "\n",
        "print(f\"{model.training=}\")\n",
        "print(f\"{model._has_transformed_inputs=}\")\n",
        "print(f\"{model.train_inputs=}\")\n",
        "print(f\"{model._original_train_inputs=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 4, 5, 7])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X = torch.rand(3, 1, 5, 7)\n",
        "num_outputs = 4\n",
        "train_X = train_X.unsqueeze(-3).expand(\n",
        "        train_X.shape[:-2] + torch.Size([num_outputs]) + train_X.shape[-2:]\n",
        "    ).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\", \"input_transform._coefficient\", \"input_transform._offset\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m SingleTaskGP(\n\u001b[1;32m     13\u001b[0m      train_X, train_Y,\n\u001b[1;32m     14\u001b[0m      outcome_transform\u001b[38;5;241m=\u001b[39mStandardize(m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m      input_transform\u001b[38;5;241m=\u001b[39mNormalize(d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     16\u001b[0m      train_Yvar\u001b[38;5;241m=\u001b[39mtrain_Yvar)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# model = SingleTaskGP(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#      train_X, train_Y,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#      covar_module=ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1])),\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#      train_Yvar=train_Yvar)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m LogNEI \u001b[38;5;241m=\u001b[39m \u001b[43mLogNoisyExpectedImprovement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/acquisition/analytic.py:634\u001b[0m, in \u001b[0;36mLogNoisyExpectedImprovement.__init__\u001b[0;34m(self, model, X_observed, num_fantasies, maximize, posterior_transform)\u001b[0m\n\u001b[1;32m    632\u001b[0m batch_X_observed \u001b[38;5;241m=\u001b[39m X_observed\u001b[38;5;241m.\u001b[39mexpand(num_fantasies, \u001b[38;5;241m*\u001b[39mX_observed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;66;03m# The fantasy model will operate in batch mode\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m fantasy_model \u001b[38;5;241m=\u001b[39m \u001b[43m_get_noiseless_fantasy_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_X_observed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_X_observed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_fantasized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_fantasized\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mfantasy_model, posterior_transform\u001b[38;5;241m=\u001b[39mposterior_transform)\n\u001b[1;32m    638\u001b[0m best_f, _ \u001b[38;5;241m=\u001b[39m Y_fantasized\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m Y_fantasized\u001b[38;5;241m.\u001b[39mmin(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/acquisition/analytic.py:1088\u001b[0m, in \u001b[0;36m_get_noiseless_fantasy_model\u001b[0;34m(model, batch_X_observed, Y_fantasized)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# load hyperparameters from original model\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m deepcopy(model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m-> 1088\u001b[0m \u001b[43mfantasy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fantasy_model\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\", \"input_transform._coefficient\", \"input_transform._offset\". "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.acquisition.analytic import LogNoisyExpectedImprovement\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "\n",
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
        "train_Yvar = torch.full_like(train_Y, 1e-3)\n",
        "\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y,\n",
        "     outcome_transform=Standardize(m=1),\n",
        "     input_transform=Normalize(d=2),\n",
        "     train_Yvar=train_Yvar)\n",
        "\n",
        "# model = SingleTaskGP(\n",
        "#      train_X, train_Y,\n",
        "#      covar_module=ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1])),\n",
        "#      train_Yvar=train_Yvar)\n",
        "\n",
        "\n",
        "LogNEI = LogNoisyExpectedImprovement(model, train_X)\n",
        "\n",
        "\n",
        "# print(model.state_dict())\n",
        "# print(f\"{model.training=}\")\n",
        "# print(f\"{model._has_transformed_inputs=}\")\n",
        "# print(f\"{model.train_inputs=}\")\n",
        "\n",
        "# print(LogNEI.model)\n",
        "# nei = LogNEI(test_X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "ename": "BotorchTensorDimensionError",
          "evalue": "An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBotorchTensorDimensionError\u001b[0m               Traceback (most recent call last)",
            "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.3\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4.9\u001b[39m\n\u001b[1;32m      2\u001b[0m train_Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(train_X)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTaskGP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/models/gp_regression.py:161\u001b[0m, in \u001b[0;36mSingleTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, train_Yvar, likelihood, covar_module, mean_module, outcome_transform, input_transform)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outcome_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     train_Y, train_Yvar \u001b[38;5;241m=\u001b[39m outcome_transform(train_Y, train_Yvar)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tensor_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformed_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Yvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ignore_X_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ignore_X_dims_scaling_check\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m validate_input_scaling(\n\u001b[1;32m    164\u001b[0m     train_X\u001b[38;5;241m=\u001b[39mtransformed_X,\n\u001b[1;32m    165\u001b[0m     train_Y\u001b[38;5;241m=\u001b[39mtrain_Y,\n\u001b[1;32m    166\u001b[0m     train_Yvar\u001b[38;5;241m=\u001b[39mtrain_Yvar,\n\u001b[1;32m    167\u001b[0m     ignore_X_dims\u001b[38;5;241m=\u001b[39mignore_X_dims,\n\u001b[1;32m    168\u001b[0m )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/botorch/models/gpytorch.py:99\u001b[0m, in \u001b[0;36mGPyTorchModel._validate_tensor_args\u001b[0;34m(X, Y, Yvar, strict)\u001b[0m\n\u001b[1;32m     93\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected X and Y to have the same number of dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got X with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y with dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BotorchTensorDimensionError(message)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-strict enforcement of botorch tensor conventions. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing error would have been raised with strict enforcement: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    107\u001b[0m     )\n",
            "\u001b[0;31mBotorchTensorDimensionError\u001b[0m: An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1)."
          ]
        }
      ],
      "source": [
        "train_X = torch.rand(10, 2, dtype=torch.float64) * 2.3 - 4.9\n",
        "train_Y = torch.sin(train_X).sum(dim=1, keepdim=False)\n",
        "\n",
        "model = SingleTaskGP(\n",
        "     train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 5)\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "class MyClass:\n",
        "    @staticmethod\n",
        "    def test(bla, bd):\n",
        "        return bla, bd\n",
        "\n",
        "# Create the partial function using the static method from the class\n",
        "partial_test = partial(MyClass.test, 3)\n",
        "\n",
        "# Call the partial function\n",
        "result = partial_test(bd=5)\n",
        "print(result)  # Output: (3, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2828]], grad_fn=<SoftplusBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.1478,  5.0348])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from random_gp_function import RandomGPFunction\n",
        "\n",
        "model = GaussianProcessRandomDataset(\n",
        "    n_datapoints=1, observation_noise=False,\n",
        "    dimension=1, randomize_params=True)._model_sampler.sample()\n",
        "print(model.covar_module.base_kernel.lengthscale)\n",
        "f = RandomGPFunction(model, observation_noise=False)\n",
        "f(torch.tensor([[1.3], [0.1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                lazy_dataset[0].y_values: tensor([-0.9738, -8.1376, -5.5296,  1.1879, -3.6971, -3.0373,  0.1646])\n",
            "            lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Made transformed dataset\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[0].y_values: tensor([9.4822e-01, 6.6221e+01, 3.0576e+01, 1.4112e+00, 1.3668e+01, 9.2250e+00,\n",
            "        2.7100e-02])\n",
            "                lazy_dataset[2].y_values: tensor([-3.5430, 16.7996, -4.0666, -9.9256, -6.6908,  6.6380,  2.7995])\n",
            "            lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[2].y_values: tensor([ 12.5526, 282.2257,  16.5370,  98.5173,  44.7665,  44.0632,   7.8373])\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    transformed_lazy_dataset[-1].y_values: tensor([ 28.5056,  35.2907,   0.7458,  28.3431,   0.3593, 157.7786,   6.0825])\n",
            "            lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "            lazy_dataset.data_is_loaded(): False\n",
            "transformed_lazy_dataset.data_is_loaded(): False\n",
            "Evaluating all items\n",
            "            lazy_dataset evaluated items: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "transformed_lazy_dataset evaluated items: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "            lazy_dataset.data_is_loaded(): True\n",
            "transformed_lazy_dataset.data_is_loaded(): True\n",
            "transformed_gp_dataset: OutcomeTransformedFunctionSamplesIterableDataset(\n",
            "  GaussianProcessRandomDataset(\n",
            "    n_datapoints=7,\n",
            "    n_datapoints_random_gen=None,\n",
            "    observation_noise=False,\n",
            "    xvalue_distribution=Independent(Uniform(low: torch.Size([3]), high: torch.Size([3])), 1),\n",
            "    models=[SingleTaskGP(\n",
            "      (likelihood): GaussianLikelihood(\n",
            "        (noise_covar): HomoskedasticNoise(\n",
            "          (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "        )\n",
            "      )\n",
            "      (mean_module): ConstantMean()\n",
            "      (covar_module): ScaleKernel(\n",
            "        (base_kernel): MaternKernel(\n",
            "          (lengthscale_prior): GammaPrior()\n",
            "          (raw_lengthscale_constraint): Positive()\n",
            "        )\n",
            "        (outputscale_prior): GammaPrior()\n",
            "        (raw_outputscale_constraint): Positive()\n",
            "      )\n",
            "    )],\n",
            "    model_probabilities=tensor([1.]),\n",
            "    set_random_model_train_data=False,\n",
            "    dataset_size=15,\n",
            "    randomize_params=True\n",
            "  ),\n",
            "  Power()\n",
            ")\n",
            "FunctionSamplesItem(tensor([[0.1263, 0.6740, 0.2122],\n",
            "        [0.6192, 0.5454, 0.2939],\n",
            "        [0.4166, 0.7264, 0.6728],\n",
            "        [0.5016, 0.1548, 0.7987],\n",
            "        [0.6692, 0.6335, 0.4488],\n",
            "        [0.6474, 0.1837, 0.2562],\n",
            "        [0.1997, 0.2802, 0.8447]]), tensor([43.2417,  0.9727, 30.0391,  1.8355, 37.7149,  9.9940, 19.0214]))\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset\n",
        "from botorch.models.transforms.outcome import Power\n",
        "\n",
        "gp_dataset = GaussianProcessRandomDataset(\n",
        "    dataset_size=15,\n",
        "    n_datapoints=7, observation_noise=False, dimension=3, randomize_params=True)\n",
        "lazy_dataset = gp_dataset.fix_samples(lazy=True)\n",
        "print(\"                lazy_dataset[0].y_values:\", lazy_dataset[0].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "\n",
        "square_transform = Power(2)\n",
        "transformed_lazy_dataset = lazy_dataset.transform_outcomes(square_transform)\n",
        "print(\"Made transformed dataset\")\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "print(\"    transformed_lazy_dataset[0].y_values:\", transformed_lazy_dataset[0].y_values)\n",
        "\n",
        "print(\"                lazy_dataset[2].y_values:\", lazy_dataset[2].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "print(\"    transformed_lazy_dataset[2].y_values:\", transformed_lazy_dataset[2].y_values)\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "\n",
        "print(\"    transformed_lazy_dataset[-1].y_values:\", transformed_lazy_dataset[-1].y_values)\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "print(\"            lazy_dataset.data_is_loaded():\", lazy_dataset.data_is_loaded())\n",
        "print(\"transformed_lazy_dataset.data_is_loaded():\", transformed_lazy_dataset.data_is_loaded())\n",
        "\n",
        "\n",
        "print(\"Evaluating all items\")\n",
        "for i in range(len(lazy_dataset)):\n",
        "    lazy_dataset[i]\n",
        "print(\"            lazy_dataset evaluated items:\", [int(x is not None) for x in lazy_dataset._data])\n",
        "print(\"transformed_lazy_dataset evaluated items:\", [int(x is not None) for x in transformed_lazy_dataset._data])\n",
        "\n",
        "print(\"            lazy_dataset.data_is_loaded():\", lazy_dataset.data_is_loaded())\n",
        "print(\"transformed_lazy_dataset.data_is_loaded():\", transformed_lazy_dataset.data_is_loaded())\n",
        "\n",
        "transformed_gp_dataset = gp_dataset.transform_outcomes(square_transform)\n",
        "print(\"transformed_gp_dataset:\", transformed_gp_dataset)\n",
        "print(next(iter(transformed_gp_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.0432,  3.3867,  0.5625,  0.4680])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.rand(4, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([1, 2, [999, 3]], [1, 2, [999, 3]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l=[1,2,[2,3]]\n",
        "v = l.copy()\n",
        "v[2][0] = 999\n",
        "l, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# f.model._clear_cache()\n",
        "print(f.model.prediction_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 2])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.model.train_inputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8689, 0.0254, 0.7824],\n",
              "        [0.6075, 0.9092, 0.8809],\n",
              "        [0.5809, 0.7194, 0.0127],\n",
              "        [0.3432, 0.9606, 0.5279],\n",
              "        [0.9266, 0.4266, 0.9935]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.rand(5, 3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[ 1.3000,  4.2000],\n",
              "         [ 0.1000, -0.1000],\n",
              "         [ 0.0000,  3.2000]])]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.model.train_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "f.model._clear_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.1577)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([0.0, 0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-1.3204)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([1.0, 0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1577, -0.1577])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, 0.0], [0.0, 0.0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0529])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, -0.1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0529, -0.1577,  0.0159, -0.1577, -0.6754])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(torch.tensor([[0.0, -0.1],\n",
        "                [0.0, 0.0],\n",
        "                [8.3, 9.1],\n",
        "                [0.0, 0.0],\n",
        "                [-20.0, 50.3]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[1.4000, 8.9000],\n",
            "        [8.2000, 3.1000],\n",
            "        [2.4000, 1.1000]]), [[0, 2], [1], [3]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "def get_unique(x):\n",
        "    unique_indices_list = []\n",
        "    for input_index in range(x.size(0)):\n",
        "        input_point = x[input_index]\n",
        "        \n",
        "        found_matching_point = False\n",
        "        for unique_point_index, original_indices in enumerate(unique_indices_list):\n",
        "            unique_point = x[original_indices[0]]\n",
        "            if torch.equal(input_point, unique_point):\n",
        "                unique_indices_list[unique_point_index].append(input_index)\n",
        "                found_matching_point = True\n",
        "        \n",
        "        if not found_matching_point:\n",
        "            unique_indices_list.append([input_index])\n",
        "    \n",
        "    return x[[inds[0] for inds in unique_indices_list]], unique_indices_list\n",
        "\n",
        "u = torch.tensor([\n",
        "    [1.4, 8.9],\n",
        "    [8.2, 3.1],\n",
        "    [1.4, 8.9],\n",
        "    [2.4, 1.1]\n",
        "])\n",
        "print(get_unique(u))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function mygen at 0x7fd5c1b0b430>\n",
            "<generator object mygen at 0x7fd5c1b64430>\n",
            "<generator object mygen at 0x7fd5c1b64430>\n"
          ]
        }
      ],
      "source": [
        "def mygen():\n",
        "    while True:\n",
        "        yield 1\n",
        "\n",
        "print(mygen)\n",
        "print(mygen())\n",
        "print(iter(mygen()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(False), False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from botorch.models.transforms.outcome import Standardize\n",
        "s = Standardize(1)\n",
        "s.eval()\n",
        "s._is_trained, s.training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([10.,  2.,  3.], requires_grad=True), tensor([10.,  2.,  3.]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x.detach()\n",
        "y[0] = 10.\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "float"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "type(x.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.to(None) is x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = (torch.tensor([1.2, 3.4]), torch.tensor(9.))\n",
        "b = tuple(x for x in a)\n",
        "a == b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "{'items_list': [1, 2, 3], 'model_index': 0, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}}\n",
            "TESTING_______\n",
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "TupleWithModel(4, 5, 6)\n",
            "All tests passed!\n",
            "MORE TESTING_______\n",
            "4 2\n",
            "{'x_hist': 1, 'y_hist': 2, 'x_cand': 3, 'vals_cand': 4, 'model_index': 2, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}, 'give_improvements': 2} <class 'dict'>\n",
            "AcquisitionDatasetModelItem(1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "), give_improvements=2)\n",
            "ERROR! (as expected): AcquisitionDatasetModelItem.__init__: model should be a SingleTaskGP or ModelsWithParamsList instance.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3577]), std = tensor([0.7010])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n",
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.4534]), std = tensor([0.8826])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from gpytorch.kernels import RBFKernel\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "\n",
        "from dataset_with_models import RandomModelSampler, TupleWithModel\n",
        "\n",
        "# Create a dummy SingleTaskGP model\n",
        "class DummyGP(SingleTaskGP):\n",
        "    def __init__(self, train_X, train_Y):\n",
        "        super().__init__(train_X, train_Y)\n",
        "        self.mean_module = ConstantMean()\n",
        "        self.covar_module = RBFKernel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# Create dummy data\n",
        "train_X = torch.rand(10, 1)\n",
        "train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "# Initialize dummy models\n",
        "model1 = DummyGP(train_X, train_Y)\n",
        "model2 = DummyGP(train_X, train_Y)\n",
        "model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "\n",
        "# Initialize RandomModelSampler\n",
        "sampler = RandomModelSampler(models)\n",
        "\n",
        "# Example usage of TupleWithModel\n",
        "tuple_with_model = TupleWithModel(1, 2, 3, model=model1)\n",
        "\n",
        "print(tuple_with_model)\n",
        "print(tuple_with_model.to_dict())\n",
        "\n",
        "\n",
        "def test_tuple_with_model():\n",
        "    # Create dummy data\n",
        "    train_X = torch.rand(10, 1)\n",
        "    train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "    # Initialize dummy models\n",
        "    model1 = DummyGP(train_X, train_Y)\n",
        "    model2 = DummyGP(train_X, train_Y)\n",
        "    model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "    models = [model1, model2, model3]\n",
        "    sampler = RandomModelSampler(models)\n",
        "\n",
        "    # Initialize TupleWithModel instances\n",
        "    twm1 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    twm2 = TupleWithModel(1, 2, 3, model=model2)\n",
        "    twm3 = TupleWithModel(4, 5, 6)\n",
        "\n",
        "    assert TupleWithModel(*twm1._tuple) == twm1\n",
        "\n",
        "    # Test __len__\n",
        "    assert len(twm1) == 4\n",
        "    assert len(twm3) == 3\n",
        "\n",
        "    # Test __getitem__\n",
        "    assert twm1[0] == 1\n",
        "    assert twm1[1] == 2\n",
        "    assert twm1[2] == 3\n",
        "    assert twm1[3] == model1\n",
        "\n",
        "    # Test __repr__\n",
        "    print(twm1)\n",
        "    print(twm3)\n",
        "\n",
        "    # Test __eq__\n",
        "    twm4 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    assert twm1 == twm4\n",
        "    assert twm1 != twm2\n",
        "    assert twm1 != twm3\n",
        "\n",
        "    # Test to_dict and from_dict\n",
        "    twm_dict = twm1.to_dict()\n",
        "    twm_reconstructed = TupleWithModel.from_dict(twm_dict, model_sampler=sampler)\n",
        "    assert twm1 == twm_reconstructed\n",
        "\n",
        "    # Test initialization with kwargs\n",
        "    twm5 = TupleWithModel(a=1, b=2, c=3)\n",
        "    assert twm5.tuple_no_model == tuple()\n",
        "    assert twm5._kwargs == {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "    twm6 = TupleWithModel(4, 1, ba=3, s=\"df\")\n",
        "    assert twm6.tuple_no_model == (4, 1)\n",
        "    assert twm6._kwargs == {'ba': 3, 's': \"df\"}\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "print(\"TESTING_______\")\n",
        "test_tuple_with_model()\n",
        "\n",
        "from acquisition_dataset import AcquisitionDatasetModelItem\n",
        "\n",
        "print(\"MORE TESTING_______\")\n",
        "\n",
        "x = AcquisitionDatasetModelItem(1, 2, 3, 4, give_improvements=2, model=model3)\n",
        "print(x.vals_cand, x.give_improvements)\n",
        "d = x.to_dict()\n",
        "print(d, type(d))\n",
        "y = AcquisitionDatasetModelItem.from_dict(d, model_sampler=sampler)\n",
        "print(y)\n",
        "\n",
        "v = AcquisitionDatasetModelItem(*y._tuple, **y._kwargs)\n",
        "assert v == y\n",
        "\n",
        "w = AcquisitionDatasetModelItem(*v._tuple + (v.model_params,), **v._kwargs)\n",
        "assert w == y\n",
        "\n",
        "x = AcquisitionDatasetModelItem(*v._tuple, model_params=v.model_params, **v._kwargs)\n",
        "assert x == y\n",
        "\n",
        "try:\n",
        "    q = AcquisitionDatasetModelItem(*v._tuple[:-1] + (v.model_params, v.model), **v._kwargs)\n",
        "    assert False\n",
        "except ValueError as e:\n",
        "    print(\"ERROR! (as expected):\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x_hist': 777,\n",
              " 'y_hist': 2,\n",
              " 'x_cand': -19,\n",
              " 'vals_cand': 4,\n",
              " 'model_index': 2,\n",
              " 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]),\n",
              "  'mean_module.raw_constant': tensor(0.),\n",
              "  'covar_module.raw_lengthscale': tensor([[0.]])},\n",
              " 'give_improvements': 78888}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = AcquisitionDatasetModelItem(1, 2, 3, 4, give_improvements=2, model=model3)\n",
        "x.x_hist = 777\n",
        "x.give_improvements = 78888\n",
        "x[2] = -19\n",
        "assert AcquisitionDatasetModelItem(*x._tuple, **x._kwargs) == x\n",
        "x.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': -100, 'b': 5, 'c': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {'a': 4, 'b': 5}\n",
        "dict(d, c=0, a=-100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000],\n",
              "        [0.5000],\n",
              "        [1.0000],\n",
              "        [1.5000],\n",
              "        [2.0000]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.linspace(0, 2, 5).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3890],\n",
              "        [0.2284],\n",
              "        [0.2776],\n",
              "        [0.0168],\n",
              "        [0.9678]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5187,  0.6291],\n",
            "        [ 0.9814, -0.4486],\n",
            "        [-0.6453,  2.0720]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ScaleKernel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# randint_gen = get_uniform_randint_generator(4, 20)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dataset = GaussianProcessRandomDataset(\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     device=device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# torch.manual_seed(1703)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m OBSERVATION_NOISE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mScaleKernel\u001b[49m(RBFKernel())\n\u001b[1;32m     11\u001b[0m kernel\u001b[38;5;241m.\u001b[39minitialize(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_kernel.lengthscale\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.2\u001b[39m)})\n\u001b[1;32m     12\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m GaussianLikelihood(\n\u001b[1;32m     13\u001b[0m     noise_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize(),\n\u001b[1;32m     14\u001b[0m     noise_constraint\u001b[38;5;241m=\u001b[39mGreaterThan(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;241m0.0\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ScaleKernel' is not defined"
          ]
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    device=device, randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "model.set_train_data(x_values, y_values, strict=False)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mLazyMapFunctionSamplesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:624\u001b[0m, in \u001b[0;36mLazyMapDatasetWithModels.__init__\u001b[0;34m(self, dataset, n_realizations)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_realizations \u001b[38;5;241m=\u001b[39m n_realizations\n\u001b[0;32m--> 624\u001b[0m items_generator, size \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_items_generator_and_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_realizations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items_generator \u001b[38;5;241m=\u001b[39m items_generator\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m size\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:329\u001b[0m, in \u001b[0;36mDatasetWithModels._get_items_generator_and_size\u001b[0;34m(self, n_samples, verbose, verbose_message)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iterable_is_finite(dataset):\n\u001b[0;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt store an infinite-sized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if n_samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not specified. Either specify n_samples or use a finite-sized dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# The dataset is finite and we want to save all of it\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     new_data_iterable \u001b[38;5;241m=\u001b[39m dataset\n",
            "\u001b[0;31mValueError\u001b[0m: Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset."
          ]
        }
      ],
      "source": [
        "# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "# LazyMapFunctionSamplesDataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0.]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fba130f4ee0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWXUlEQVR4nO3dfYxcV3nH8d/jzbhMEmBTvEVkwXWgrXkLjtMtSnGFSFJqklTgokRAoVVRJasSRUCRi4OqAm0RrlalUEFBVqAIlQIFEgvCi4saKAWawBo7cUwwCgkv3rRk02YFxCuyXj/9Y2bs3fW9M+fO3Jdz73w/khV75nr8nPHkN8fnPvdcc3cBAOK1oeoCAAD9EdQAEDmCGgAiR1ADQOQIagCI3HlFvOimTZt8y5YtRbw0ADTSoUOHHnL3qaTnCgnqLVu2aG5uroiXBoBGMrMfpD3H0gcARI6gBoDIEdQAEDmCGgAiR1ADQOQK6foo04HD85o9eFwPLC7p4sm29uzcql3bp6suCwByU+ugPnB4XjfefFRLyyuSpPnFJd1481FJIqwBNEatlz5mDx4/E9I9S8srmj14vKKKACB/tQ7qBxaXMj0OAHVU66C+eLKd6XEAqKNaB/WenVvVbk2seazdmtCenVsrqggA8lfrk4m9E4Z0fQBosloHtdQJa4IZQJMNXPows61mdmTVj5+Y2etLqA0AoIAZtbsfl3SZJJnZhKR5SbcUWxYAoCfrycSrJX3P3VP3TQUA5CtrUL9c0keTnjCz3WY2Z2ZzCwsLo1cGAJCUIajNbKOkF0v6RNLz7r7f3WfcfWZqKvFuMgCAIWSZUV8j6Vvu/uOiigEAnCtLUL9CKcseAIDiBAW1mZ0v6YWSbi62HADAekEXvLj7SUlPKLgWAECCWu/1AQDjgKAGgMgR1AAQOYIaACJHUANA5AhqAIgcQQ0AkSOoASByBDUARI6gBoDIEdQAEDmCGgAiR1ADQOQIagCIHEENAJEjqAEgcgQ1AESOoAaAyIXeM3HSzD5pZt8xs3vM7DeLLgwA0BF0z0RJ75b0BXe/3sw2Sjq/wJoAAKsMDGoze5yk50v6I0ly90clPVpsWQCAnpClj6dKWpD0T2Z22MxuMrML1h9kZrvNbM7M5hYWFnIvFADGVUhQnyfpcknvc/ftkh6RtHf9Qe6+391n3H1mamoq5zIBYHyFBPUJSSfc/Y7urz+pTnADAEowMKjd/X8k/cjMtnYfulrStwutCgBwRmjXx2slfaTb8XGfpFcXVxIAYLWgoHb3I5Jmii0FAJCEKxMBIHIENQBEjqAGgMgR1AAQOYIaACJHUANA5AhqAIgcQQ0AkSOoASByBDUARI6gBoDIEdQAEDmCGgAiR1ADQOQIagCIHEENAJEjqAEgcgQ1AEQu6FZcZvZ9ST+VtCLplLtzWy4AKEnozW0l6Up3f6iwSgAAiVj6AIDIhQa1S/o3MztkZruTDjCz3WY2Z2ZzCwsL+VUIAGMuNKh3uPvlkq6R9Boze/76A9x9v7vPuPvM1NRUrkUCwDgLCmp3f6D73wcl3SLpuUUWBQA4a2BQm9kFZvbY3s8l/Y6ku4suDADQEdL18URJt5hZ7/h/cfcvFFoVAOCMgUHt7vdJ2lZCLQCABLTnAUDkCGoAiBxBDQCRI6gBIHIENQBELsumTGPpwOF5zR48rgcWl3TxZFt7dm7Vru3TVZcFYIwQ1H0cODyvG28+qqXlFUnS/OKSbrz5qCQR1gBKw9JHH7MHj58J6Z6l5RXNHjxeUUUAxhFB3ccDi0uZHgeAIhDUfVw82c70OAAUgaDuY8/OrWq3JtY81m5NaM/OrRVVBGAccTKxj94JQ7o+AFSJoB5g1/ZpghlApVj6AIDIEdQAEDmCGgAiR1ADQOQIagCIXHBQm9mEmR02s1uLLAgAsFaW9rzXSbpH0uMKqgUAolT1LppBQW1mT5Z0naS3S/qzQitC7VT9IQaKFMMumqFLH++S9OeSTqcdYGa7zWzOzOYWFhbyqA010PsQzy8uyXX2Q3zg8HzVpQG5iGEXzYFBbWa/K+lBdz/U7zh33+/uM+4+MzU1lVuBiFsMH2KgSDHsohkyo94h6cVm9n1JH5N0lZn9c6FVoTZi+BADRYphF82BQe3uN7r7k919i6SXS7rN3V9VeGWohRg+xECRYthFkz5qjCSGDzFQpF3bp/WOl16q6cm2TNL0ZFvveOmlpZ4wN3fP/UVnZmZ8bm4u99dFnOj6AEZnZofcfSbpObY5xcjYChYoFksfABA5ghoAIjcWSx+soQKos8YHdQyXfwLAKBof1P2unIslqJnxA+in8UEd+5VzzPgBDNL4k4mxXznHXhkABml8UMd+5VzsM34A1Wt8UMdw+Wc/sc/4AVSv8WvUUtxXzu3ZuXXNGrUU14wfQPXGIqhj1vsCoesDQBqCOgIxz/gBVK/xa9QAUHcENQBEjqAGgMgR1AAQOYIaACI3MKjN7DFm9g0zu9PMjpnZ28ooDADQEdKe93NJV7n7z8ysJemrZvZ5d7+94NoAAAoIau/c/fZn3V+2uj/yvyMuACBR0AUvZjYh6ZCkX5H0Xne/I+GY3ZJ2S9LmzZvzrLFy7BedjvcGKJ51JsyBB5tNSrpF0mvd/e6042ZmZnxubm706kowKGjW7xctdfbiiGljp6rw3tQfX7TxMLND7j6T9Fymrg93X5T0ZUkvGr2s6vWCZn5xSa6zm/YfODx/5hj2i07He1NvIZ9/xCGk62OqO5OWmbUl/bak7xRcVylCgob9otPx3tQbX7T1ETKjfpKkL5nZXZK+KemL7n5rsWWVIyRo2C86He9NvfFFWx8Dg9rd73L37e7+HHd/trv/VRmFlSEkaGK/Q0yVeG/qjS/a+hjrKxNDgib2O8RUifem3viirY9MXR+hmtT1UdZrAFXgsxuPfl0fYx/Uo6JFDUAecmvPw7k4cw6gaAT1iDhzDqBoBPWIOHMOoGgE9Yg4cw6gaNyFfES9E4acOQdQFII6B7u2T+cezLRNDcZ7hHFBUEdofctfb7McSQRRF+8Rxglr1BGi5W8w3iOME4I6QrT8DcZ7hHFCUEeIlr/BeI8wTgjqCNHyNxjvEcYJJxMjRMvfYLxHGCdsylSBYdvKaEcDmqvfpkzMqFcpIwiHbSujHQ0YX6xRd5V1o89h28poRwPGV8jNbZ9iZl8ys3vM7JiZva6MwpIcODyvHftu0yV7P6sd+27LNUTLCsJh28poRwPGV8iM+pSkN7r7MyRdIek1ZvbMYss6V9Ez3rKCcNi2MtrRgPEVcnPb/3b3b3V//lNJ90gqfVE0bcb7ts8cy2WWXVYQDttWRjsaML4ynUw0sy2Stku6o5Bq+kib2T58clkPn1yWlP0E2+qTh49vt9SaMC2vnO2CKSIIh20rox0NGF/BQW1mF0r6lKTXu/tPEp7fLWm3JG3evDm3AnsunmxrPmAZoreuPCjA1ndRLC4tq7XBdNH5LS2eXB4pCJO6R6TRQ7aIXfoAxC+oj9rMWpJulXTQ3d856PhR+qjTWuSSbiKbWq+k+/dd1/eYHftuSwz+6cm2vrb3qqFql5JvdtuaMMml5dNrZ+vcABdAz0h91GZmkj4g6Z6QkB5FSK/w6hB/5OentLi0fM7rbDDTJXs/23fmWtTJw6S19NXLKT2hM38ACFn62CHpDyQdNbMj3cfe7O6fy7uYfi1yvX/2rw62tFn2SvdfCf3WrNOWUkY9eZgl6GmtKwZXcKJpQro+vuru5u7PcffLuj9yD2kp+yx31/ZpveOll2p6si2TNGF2zjFpvdBFdVFkCXpa6/JX1oVLQJmiujJxmBa5Xdun9bW9V+n+fdfpdMp6e1LQrw/56cl2LmvGSV8ArQlTa8PaLxFa64rBFZxooqj2+tizc+s5SxlZAi3rckYRXRRpbXRJj/HP8fxxBSeaKKqgHrVXeNSgz0vaFwDBXLyizj0AVYoqqKXRZrlcFIJYvqyBPEUX1KPiopDxxpc1mqhRQd2UtqymjKMqfFmjaRoT1E3ZWL8p4wCQn6ja84Z14PC83vivdzaiLavK9rIi9/sGMLzaz6h7M9CVDD3UMauqvYyZPBCv2s+ok2agq9WtLauqGwRwoQgQr9oHdb+ZZh3bsqq6QQAXigDxqn1Qp800J8xquY1oUZe2D8KtvoB41X6NOu0ChzqGdE8V7WVcKALEq/ZBzQUOybL2YvM+AvEKusNLVqPc4SUP437BSNI+3XX/VwbQdP3u8FL7Ner12I+YDg6gaRoX1IQUHRxA09RqjTpkSYOQYqtPoGlqE9ShV85lCamQ4K/jejcdHECzDFz6MLMPmtmDZnZ3GQWlCV3SCL1gJGQte5j17hj2y6iqFxtAMUJm1B+S9B5JHy62lP7Sli7Wz56T2syufPqUZg8e1xs+fuTMrHhQ8M8ePJ44M199V/T1htkvo6gZO1t9As0R1J5nZlsk3eruzw550SLa83bsuy0xOE3S37/ssr5BmLQM0G9/kEHPm6T7910XXOP0ZFtf23tVcG3MfoHxU0p7npntNrM5M5tbWFjI62XP2LNzqyzhcZf6dnSkzZyTXkvqXHreL6Sl9JNyWU9k0qECIERuQe3u+919xt1npqam8nrZM3Ztn1ba3L9fR0fac0mv1dpgqdul9pg6SxpJ689Z98ugQwVAiFr0UfdO0KXp13aWpSXtwsecp+k+x5vOBnzSicWsO9+xERKAENEH9erOiySD2s6SwjPN4snl1LCdbLfOmYWvX6bI2m1R1ZamAOplYNeHmX1U0gskbTKzE5Le4u4fKLqwnn43BpjOuNnQ/OKSJix9eePiyXbq5kRv+PiRxN+zfpkiS7cFGyEBCDEwqN39FWUUkiZtvdakxE6KJL3gW99hsdrqmWxS2Ka16426TEEbHYBBol/6yGsdd9DMfFBLHMsUAKoS/SXkeV0OPerMvK7LFHW8BB7AWtEH9aCADA2iPDYqqtsyBXcWB5oh+qCW0gMySxCN40ZF/S6oIaiB+qhFUKfJEkR5LV3UaSmBC2qAZqh1UGcNolGXLuq2lMC+1EAzRN/10U/ZV/bVbW8OOlWAZqh1UJcdRHVbSmBfaqAZar30UXbLXB2XEurWqQLgXLUO6kHyvtXWnp1bteeTd2p55ewl6K0JYykBQKFqHdT9Tu5JGnjib6iTg+u3CRl834VadYpg/PD5jF+tg3rQyb1BrXtZ+4xnDx7X8um1ybx82vv2Jf/FgaP6yO0/PGd7VCnOTpEqEBTVqVsn07iq9cnEfif3Qk78ZT05mPXxA4fn14R0T8ydImUb5gbCyE/dOpnGVa2Dul97XkjrXtb2vqyPzx48PtRdacYJQVGtunUyjataB3W/9ryQ1r2s7X1Zj+/3YY+5U6RMBEW1uMtQPdQ6qPv1CYf0EGftM856fNqH3SQ6RboIimpxUVQ9mA+4meswZmZmfG5uLvfXrZv1J2qkTki/8orN+ptdl1ZXWESS3qN2a4ILc0rEydw4mNkhd59Jeq7WXR+xK+KCnDL/pyrjz6rrPt9NwkVR8QuaUZvZiyS9W9KEpJvcfV+/44eZUW/Z+9lMx8fqgo0TuvAXJvTjnz5adSmJJtstvfXFz5Ikve0zx/TwyeUzz20w6bQr9b6Svbuw957v/Xd6sq0rnz6lL31nYc19KVc/nxa+SV8G0rnBnfRYWrgcODyvt376mBaXzo6tN+6QQMrjCyrPL7nQ96jMGvMaX1Nm83mMo9+MemBQm9mEpO9KeqGkE5K+KekV7v7ttN+TNaibEtJ1sUGSbTCtnM5/2StN0nJG0rJHa8Ik15p+9dYGk0xrrghNWx45cHheez5x5zn97r3Xmb1hW9//gfJYislzOSf0PSqzxrzG15Rlr7zG0S+oQ04mPlfSve5+n7s/Kuljkl4S/KcjOqelUkNaSm65S2rNW17xxIuKVod02uv1XjMppHuvM6jtL492wTxbDkPfozJrzGt8TWnNLGMcIUE9LelHq359ovvYGma228zmzGxuYWEhr/rQIOtb7kZtwUv6/YNec9jns9SaZ8thHn9ulmNDXiOv8TWlNbOMcYQEtSU8ds6Uxd33u/uMu89MTU2NXhkaZ33L3agteEm/f9BrDvt8llrzbDnM48/NcmzIa+Q1vqa0ZpYxjpCgPiHpKat+/WRJD+RWAUq3QdLEhqTv3+Ik9eYm9fC2JqyzJr36sQ3WWZcd8Hq911z/+1e/zqD+4Dz6ivPsTQ59j8qsMa/xNaWHu4xxhAT1NyX9qpldYmYbJb1c0qdzq0DS9/ddl+fLVeqCjRN64mM3Fv7nTLZb2vG0X9SEZQvcyXZL73zZZfq7G7bpovNba57r/b/fe83ef6cn23rVFZs13Z0hDPN80omVpAuIZq/fptkbtq197IZtmr1+W9CFRru2T2v2hm2abK8d22S7NfBEYlpNWU8K5XnDhtD3qMwa8xpfU25sUcY4QtvzrpX0LnXa8z7o7m/vdzwXvABANiNf8OLun5P0uVyrAgAEqfVeHwAwDghqAIgcQQ0AkSOoASByhWxzamYLkn4w5G/fJOmhHMupGuOJG+OJW5PGM2gsv+zuiVcLFhLUozCzubQWlTpiPHFjPHFr0nhGGQtLHwAQOYIaACIXY1Dvr7qAnDGeuDGeuDVpPEOPJbo1agDAWjHOqAEAqxDUABC5SoLazF5kZsfN7F4z25vwvJnZP3Sfv8vMLq+izlAB43lldxx3mdnXzWxbFXWGGjSeVcf9hpmtmNn1ZdaXVch4zOwFZnbEzI6Z2X+UXWMWAZ+3x5vZZ8zszu54Xl1FnaHM7INm9qCZ3Z3yfN3yYNB4sueBu5f6Q52tUr8n6amSNkq6U9Iz1x1zraTPq3N3mSsk3VF2nTmP53mSLur+/Jq6j2fVcbeps6vi9VXXPeLfz6Skb0va3P31L1Vd94jjebOkv+3+fErS/0naWHXtfcb0fEmXS7o75fna5EHgeDLnQRUz6pCb5b5E0oe943ZJk2b2pLILDTRwPO7+dXd/uPvL29W5S06sQm9m/FpJn5L0YJnFDSFkPL8v6WZ3/6EkuXvMYwoZj0t6rJmZpAvVCepT5ZYZzt2/ok6NaeqUBwPHM0weVBHUITfLDbqhbiSy1vrH6swOYjVwPGY2Len3JL2/xLqGFfL382uSLjKzL5vZITP7w9Kqyy5kPO+R9Ax1bpl3VNLr3P10OeUVok55kFVQHgTdOCBnITfLDbqhbiSCazWzK9X5i/mtQisaTch43iXpTe6+YhlvBVaBkPGcJ+nXJV0tqS3pv8zsdnf/btHFDSFkPDslHZF0laSnSfqimf2nu/+k4NqKUqc8CJYlD6oI6pCb5dbphrpBtZrZcyTdJOkad//fkmobRsh4ZiR9rBvSmyRda2an3P1AKRVmE/p5e8jdH5H0iJl9RdI2STEGdch4Xi1pn3cWQe81s/slPV3SN8opMXd1yoMgmfOggoX28yTdJ+kSnT0Z8qx1x1yntScPvlH1CYIRx7NZ0r2Snld1vXmMZ93xH1LcJxND/n6eIenfu8eeL+luSc+uuvYRxvM+SW/t/vyJkuYlbaq69gHj2qL0k2+1yYPA8WTOg9Jn1O5+ysz+VNJBnb1Z7jEz+5Pu8+9Xp5Pg2u5gTqozQ4hS4Hj+UtITJP1jdxZ6yiPdESxwPLURMh53v8fMviDpLkmnJd3k7omtVVUL/Pv5a0kfMrOj6oTbm9w92q1Czeyjkl4gaZOZnZD0FkktqX55IAWNJ3MecAk5AESOKxMBIHIENQBEjqAGgMgR1AAQOYIaACJHUANA5AhqAIjc/wPAgXDjM4I0eQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7216, 0.5588, 0.0163],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.8445, 0.7417, 0.1469],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.8424, 0.6213, 0.9883],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460]])\n",
            "tensor([2, 4, 0, 6, 7, 1, 3, 5])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163]])\n",
            "tensor([[0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.4122, -9.7531, -9.2286, -9.5989, -9.1321, -9.4680, -9.3031, -9.7429,\n",
              "        -9.3805, -9.6507, -9.0406, -9.3168, -9.1272, -9.9820, -9.1291, -9.4314,\n",
              "        -9.7203, -9.4293, -9.0302, -9.4230])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.]),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.]], requires_grad=True)}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.),\n",
              " 'covar_module.raw_outputscale': tensor(0.),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.]])}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 237.86it/s]\n"
          ]
        }
      ],
      "source": [
        "fixed_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3770e-01, 5.9728e-01, 1.3027e-01, 8.7175e-01, 1.3623e-01],\n",
              "        [2.8008e-01, 5.2939e-01, 7.4921e-01, 6.7475e-01, 7.0635e-01],\n",
              "        [3.8596e-04, 1.7254e-01, 9.1312e-01, 5.6526e-01, 8.1478e-01],\n",
              "        [4.3732e-01, 4.3083e-01, 3.0867e-01, 7.7489e-01, 8.4643e-01],\n",
              "        [6.1417e-01, 7.0303e-01, 8.9406e-02, 6.5903e-01, 9.4700e-01],\n",
              "        [1.3595e-01, 2.9692e-01, 8.0865e-01, 3.6557e-01, 8.0262e-02],\n",
              "        [5.5435e-01, 2.0977e-01, 9.9751e-01, 2.5552e-01, 2.0415e-01],\n",
              "        [9.2425e-01, 4.8544e-01, 7.1970e-01, 3.0899e-01, 4.5466e-02],\n",
              "        [4.7055e-01, 6.2878e-01, 3.4137e-01, 1.5561e-01, 2.4682e-01],\n",
              "        [5.0904e-01, 5.2614e-01, 5.8093e-01, 3.4311e-02, 5.9625e-01],\n",
              "        [2.4432e-02, 3.5175e-01, 1.1442e-01, 4.1488e-01, 2.4443e-01],\n",
              "        [1.9026e-01, 5.0099e-01, 8.4974e-01, 9.3262e-01, 9.7229e-01],\n",
              "        [6.5269e-01, 1.5853e-01, 5.4473e-01, 3.1906e-01, 5.2323e-01],\n",
              "        [3.3650e-01, 5.1750e-01, 7.4551e-01, 5.5767e-01, 2.9194e-01],\n",
              "        [9.8836e-01, 4.7839e-01, 9.2729e-01, 5.5478e-02, 3.0561e-01],\n",
              "        [5.3924e-01, 5.8842e-02, 8.9266e-01, 9.7812e-01, 5.7267e-01],\n",
              "        [3.1673e-01, 2.5540e-01, 2.3361e-01, 5.1155e-01, 1.0439e-01],\n",
              "        [9.1125e-01, 9.1233e-01, 2.4270e-01, 6.6415e-01, 5.5721e-01],\n",
              "        [7.4868e-01, 8.5152e-01, 9.0714e-01, 2.8652e-01, 1.8544e-01],\n",
              "        [6.2989e-01, 1.9168e-02, 2.5467e-02, 8.0095e-01, 6.3958e-01]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = ListMapFunctionSamplesDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FunctionSamplesItem([0], [0]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([1], [1]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([2], [2]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([3], [3]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([4], [4]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([5], [5]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([6], [6]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([7], [7]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([8], [8]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([9], [9]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([10], [10]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([11], [11]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([12], [12]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([13], [13]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([14], [14]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([15], [15]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([16], [16]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([17], [17]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([18], [18]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([19], [19]) <class 'function_samples_dataset.FunctionSamplesItem'>\n",
            "FunctionSamplesItem([12, 13], [33]) <class 'function_samples_dataset.FunctionSamplesItem'>\n"
          ]
        }
      ],
      "source": [
        "# test_dataset = ListMapFunctionSamplesDataset([\n",
        "#     ([i], [i]) for i in range(20)\n",
        "# ] + [([12, 13], [33], SingleTaskGP(torch.zeros(2, 1), torch.zeros(2, 1), likelihood=likelihood, covar_module=kernel))])\n",
        "\n",
        "test_dataset = ListMapFunctionSamplesDataset([\n",
        "    ([i], [i]) for i in range(20)\n",
        "] + [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = ListMapFunctionSamplesDataset(\n",
        "#     [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x, type(x))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')\n",
        " # \"Generating GP realizations:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/123 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123/123 [00:00<00:00, 291.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating and saving realizations from GaussianProcessRandomDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 94/94 [00:00<00:00, 285.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5, dataset_size=94)\n",
        "function_samples_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 123)\n",
        "function_samples_dataset = function_samples_dataset[:20]\n",
        "function_samples_dataset.save('fixed', 17)\n",
        "rand_dataset.save('random')\n",
        "loaded_dataset = ListMapFunctionSamplesDataset.load('fixed')\n",
        "print(len(loaded_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 17)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0}\n",
            "1 batches:, want 27 prints, got 1 prints\n",
            "[0]\n",
            "\n",
            "{0, 1}\n",
            "2 batches:, want 27 prints, got 2 prints\n",
            "[0 1]\n",
            "\n",
            "{0, 1, 2}\n",
            "3 batches:, want 27 prints, got 3 prints\n",
            "[0 1 2]\n",
            "\n",
            "{0, 1, 2, 3}\n",
            "4 batches:, want 27 prints, got 4 prints\n",
            "[0 1 2 3]\n",
            "\n",
            "{0, 1, 2, 3, 4}\n",
            "5 batches:, want 27 prints, got 5 prints\n",
            "[0 1 2 3 4]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5}\n",
            "6 batches:, want 27 prints, got 6 prints\n",
            "[0 1 2 3 4 5]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6}\n",
            "7 batches:, want 27 prints, got 7 prints\n",
            "[0 1 2 3 4 5 6]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "8 batches:, want 27 prints, got 8 prints\n",
            "[0 1 2 3 4 5 6 7]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "9 batches:, want 27 prints, got 9 prints\n",
            "[0 1 2 3 4 5 6 7 8]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10 batches:, want 27 prints, got 10 prints\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
            "11 batches:, want 27 prints, got 11 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
            "12 batches:, want 27 prints, got 12 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
            "13 batches:, want 27 prints, got 13 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
            "14 batches:, want 27 prints, got 14 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
            "15 batches:, want 27 prints, got 15 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
            "16 batches:, want 27 prints, got 16 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
            "17 batches:, want 27 prints, got 17 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
            "18 batches:, want 27 prints, got 18 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n",
            "19 batches:, want 27 prints, got 19 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
            "20 batches:, want 27 prints, got 20 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}\n",
            "21 batches:, want 27 prints, got 21 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21}\n",
            "22 batches:, want 27 prints, got 22 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}\n",
            "23 batches:, want 27 prints, got 23 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}\n",
            "24 batches:, want 27 prints, got 24 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24}\n",
            "25 batches:, want 27 prints, got 25 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n",
            "26 batches:, want 27 prints, got 26 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26}\n",
            "27 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n",
            "28 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28}\n",
            "29 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24 25\n",
            " 26 27 28]\n",
            "\n",
            "{0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29}\n",
            "30 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 25 26\n",
            " 27 28 29]\n",
            "\n",
            "{0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30}\n",
            "31 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  5  6  7  8  9 10 12 13 14 15 16 17 18 20 21 22 23 24 25 27\n",
            " 28 29 30]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31}\n",
            "32 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 23 24 25 26 27\n",
            " 29 30 31]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32}\n",
            "33 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  9 10 11 12 14 15 16 17 18 20 21 22 23 25 26 27 28\n",
            " 30 31 32]\n",
            "\n",
            "{0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33}\n",
            "34 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  6  8  9 10 11 13 14 15 16 18 19 20 22 23 24 25 27 28 29\n",
            " 30 32 33]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34}\n",
            "35 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 10 12 13 14 16 17 18 20 21 22 24 25 26 27 29 30\n",
            " 31 33 34]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35}\n",
            "36 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 11 12 13 15 16 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 34 35]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36}\n",
            "37 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  8 10 11 12 14 15 17 18 19 21 22 24 25 26 28 29 30 32\n",
            " 33 35 36]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 36, 37}\n",
            "38 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 11 13 14 16 17 18 20 21 23 24 26 27 28 30 31 33\n",
            " 34 36 37]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38}\n",
            "39 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 12 13 15 16 18 19 20 22 23 25 26 28 29 31 32 34\n",
            " 35 37 38]\n",
            "\n",
            "{0, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 26, 27, 28, 30, 32, 33, 34, 36, 38, 39}\n",
            "40 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  4  6  8  9 10 12 14 15 16 18 20 21 22 24 26 27 28 30 32 33 34\n",
            " 36 38 39]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40}\n",
            "41 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 12 14 15 17 18 20 22 23 25 26 28 29 31 32 34 35\n",
            " 37 38 40]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 24, 25, 27, 28, 30, 32, 33, 35, 36, 38, 39, 41}\n",
            "42 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 13 14 16 17 19 20 22 24 25 27 28 30 32 33 35 36\n",
            " 38 39 41]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 10, 11, 13, 15, 16, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 36, 37, 39, 40, 42}\n",
            "43 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8 10 11 13 15 16 18 19 21 23 24 26 27 29 31 32 34 36 37\n",
            " 39 40 42]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 13, 15, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 35, 36, 38, 40, 41, 43}\n",
            "44 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 13 15 17 18 20 22 23 25 26 28 30 31 33 35 36 38\n",
            " 40 41 43]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 14, 15, 17, 19, 20, 22, 24, 25, 27, 29, 30, 32, 34, 36, 37, 39, 41, 42, 44}\n",
            "45 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 14 15 17 19 20 22 24 25 27 29 30 32 34 36 37 39\n",
            " 41 42 44]\n",
            "\n",
            "{0, 2, 3, 5, 7, 9, 10, 12, 14, 16, 17, 19, 21, 22, 24, 26, 28, 29, 31, 33, 35, 36, 38, 40, 42, 43, 45}\n",
            "46 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  9 10 12 14 16 17 19 21 22 24 26 28 29 31 33 35 36 38 40\n",
            " 42 43 45]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 12, 14, 16, 18, 19, 21, 23, 25, 27, 28, 30, 32, 34, 35, 37, 39, 41, 42, 44, 46}\n",
            "47 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 12 14 16 18 19 21 23 25 27 28 30 32 34 35 37 39 41\n",
            " 42 44 46]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 13, 14, 16, 18, 20, 22, 24, 25, 27, 29, 31, 33, 34, 36, 38, 40, 42, 43, 45, 47}\n",
            "48 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 13 14 16 18 20 22 24 25 27 29 31 33 34 36 38 40 42\n",
            " 43 45 47]\n",
            "\n",
            "{0, 2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 28, 30, 31, 33, 35, 37, 39, 41, 42, 44, 46, 48}\n",
            "49 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  7  9 11 13 15 17 18 20 22 24 26 28 30 31 33 35 37 39 41 42\n",
            " 44 46 48]\n",
            "\n",
            "{0, 2, 4, 6, 8, 9, 11, 13, 15, 17, 19, 21, 23, 24, 26, 28, 30, 32, 34, 36, 38, 40, 41, 43, 45, 47, 49}\n",
            "50 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8  9 11 13 15 17 19 21 23 24 26 28 30 32 34 36 38 40 41 43\n",
            " 45 47 49]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 38, 40, 42, 44, 46, 48, 50}\n",
            "51 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 13 15 17 19 21 23 25 27 29 31 33 35 37 38 40 42 44\n",
            " 46 48 50]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51}\n",
            "52 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 27 29 31 33 35 37 39 41 43 45\n",
            " 47 49 51]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52}\n",
            "53 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46\n",
            " 48 50 52]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53}\n",
            "54 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 29 31 33 35 37 39 41 43 45 47\n",
            " 49 51 53]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 52, 54}\n",
            "55 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 15 17 19 21 23 25 27 29 31 33 35 37 39 42 44 46 48\n",
            " 50 52 54]\n",
            "\n",
            "{0, 2, 4, 6, 8, 11, 13, 15, 17, 19, 21, 23, 25, 28, 30, 32, 34, 36, 38, 40, 42, 44, 47, 49, 51, 53, 55}\n",
            "56 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 11 13 15 17 19 21 23 25 28 30 32 34 36 38 40 42 44 47 49\n",
            " 51 53 55]\n",
            "\n",
            "{0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 22, 24, 26, 28, 30, 32, 34, 37, 39, 41, 43, 45, 47, 50, 52, 54, 56}\n",
            "57 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  9 11 13 15 17 19 22 24 26 28 30 32 34 37 39 41 43 45 47 50\n",
            " 52 54 56]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 15, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 53, 55, 57}\n",
            "58 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 15 18 20 22 24 26 29 31 33 35 37 39 42 44 46 48 50\n",
            " 53 55 57]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 16, 18, 20, 22, 25, 27, 29, 31, 33, 36, 38, 40, 42, 45, 47, 49, 51, 54, 56, 58}\n",
            "59 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 16 18 20 22 25 27 29 31 33 36 38 40 42 45 47 49 51\n",
            " 54 56 58]\n",
            "\n",
            "{0, 2, 5, 7, 9, 11, 14, 16, 18, 20, 23, 25, 27, 30, 32, 34, 36, 39, 41, 43, 45, 48, 50, 52, 54, 57, 59}\n",
            "60 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 11 14 16 18 20 23 25 27 30 32 34 36 39 41 43 45 48 50 52\n",
            " 54 57 59]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 18, 21, 23, 25, 28, 30, 32, 35, 37, 39, 42, 44, 46, 48, 51, 53, 55, 58, 60}\n",
            "61 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 18 21 23 25 28 30 32 35 37 39 42 44 46 48 51 53\n",
            " 55 58 60]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 19, 21, 23, 26, 28, 30, 33, 35, 38, 40, 42, 45, 47, 49, 52, 54, 56, 59, 61}\n",
            "62 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 19 21 23 26 28 30 33 35 38 40 42 45 47 49 52 54\n",
            " 56 59 61]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 29, 31, 33, 36, 38, 41, 43, 45, 48, 50, 52, 55, 57, 60, 62}\n",
            "63 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 14 17 19 21 24 26 29 31 33 36 38 41 43 45 48 50 52 55\n",
            " 57 60 62]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 19, 22, 24, 27, 29, 31, 34, 36, 39, 41, 44, 46, 48, 51, 53, 56, 58, 61, 63}\n",
            "64 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 19 22 24 27 29 31 34 36 39 41 44 46 48 51 53 56\n",
            " 58 61 63]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 20, 22, 25, 27, 30, 32, 34, 37, 39, 42, 44, 47, 49, 52, 54, 57, 59, 62, 64}\n",
            "65 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 20 22 25 27 30 32 34 37 39 42 44 47 49 52 54 57\n",
            " 59 62 64]\n",
            "\n",
            "{0, 2, 5, 8, 10, 12, 15, 18, 20, 22, 25, 28, 30, 32, 35, 38, 40, 42, 45, 48, 50, 52, 55, 58, 60, 62, 65}\n",
            "66 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  8 10 12 15 18 20 22 25 28 30 32 35 38 40 42 45 48 50 52 55 58\n",
            " 60 62 65]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 20, 23, 25, 28, 30, 33, 36, 38, 41, 43, 46, 48, 51, 53, 56, 58, 61, 63, 66}\n",
            "67 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 20 23 25 28 30 33 36 38 41 43 46 48 51 53 56 58\n",
            " 61 63 66]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 21, 23, 26, 28, 31, 34, 36, 39, 41, 44, 46, 49, 52, 54, 57, 59, 62, 64, 67}\n",
            "68 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 21 23 26 28 31 34 36 39 41 44 46 49 52 54 57 59\n",
            " 62 64 67]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 16, 18, 21, 24, 26, 29, 31, 34, 37, 39, 42, 44, 47, 50, 52, 55, 58, 60, 63, 65, 68}\n",
            "69 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 16 18 21 24 26 29 31 34 37 39 42 44 47 50 52 55 58 60\n",
            " 63 65 68]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 21, 24, 27, 29, 32, 34, 37, 40, 42, 45, 48, 50, 53, 56, 58, 61, 64, 66, 69}\n",
            "70 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 21 24 27 29 32 34 37 40 42 45 48 50 53 56 58 61\n",
            " 64 66 69]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 22, 24, 27, 30, 32, 35, 38, 40, 43, 46, 48, 51, 54, 57, 59, 62, 65, 67, 70}\n",
            "71 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 22 24 27 30 32 35 38 40 43 46 48 51 54 57 59 62\n",
            " 65 67 70]\n",
            "\n",
            "{0, 3, 5, 8, 11, 14, 16, 19, 22, 25, 27, 30, 33, 36, 38, 41, 44, 46, 49, 52, 55, 57, 60, 63, 66, 68, 71}\n",
            "72 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 14 16 19 22 25 27 30 33 36 38 41 44 46 49 52 55 57 60 63\n",
            " 66 68 71]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 19, 22, 25, 28, 30, 33, 36, 39, 42, 44, 47, 50, 53, 55, 58, 61, 64, 66, 69, 72}\n",
            "73 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 19 22 25 28 30 33 36 39 42 44 47 50 53 55 58 61 64\n",
            " 66 69 72]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 20, 22, 25, 28, 31, 34, 36, 39, 42, 45, 48, 51, 53, 56, 59, 62, 65, 67, 70, 73}\n",
            "74 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 20 22 25 28 31 34 36 39 42 45 48 51 53 56 59 62 65\n",
            " 67 70 73]\n",
            "\n",
            "{0, 3, 6, 9, 11, 14, 17, 20, 23, 26, 28, 31, 34, 37, 40, 43, 46, 48, 51, 54, 57, 60, 63, 65, 68, 71, 74}\n",
            "75 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 11 14 17 20 23 26 28 31 34 37 40 43 46 48 51 54 57 60 63 65\n",
            " 68 71 74]\n",
            "\n",
            "{0, 3, 6, 9, 12, 14, 17, 20, 23, 26, 29, 32, 35, 38, 40, 43, 46, 49, 52, 55, 58, 61, 63, 66, 69, 72, 75}\n",
            "76 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 14 17 20 23 26 29 32 35 38 40 43 46 49 52 55 58 61 63 66\n",
            " 69 72 75]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56, 58, 61, 64, 67, 70, 73, 76}\n",
            "77 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 20 23 26 29 32 35 38 41 44 47 50 53 56 58 61 64 67\n",
            " 70 73 76]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 38, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 71, 74, 77}\n",
            "78 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 38 41 44 47 50 53 56 59 62 65 68\n",
            " 71 74 77]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78}\n",
            "79 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69\n",
            " 72 75 78]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 70, 73, 76, 79}\n",
            "80 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 40 43 46 49 52 55 58 61 64 67 70\n",
            " 73 76 79]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55, 58, 62, 65, 68, 71, 74, 77, 80}\n",
            "81 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 22 25 28 31 34 37 40 43 46 49 52 55 58 62 65 68 71\n",
            " 74 77 80]\n",
            "\n",
            "{0, 3, 6, 9, 12, 16, 19, 22, 25, 28, 31, 34, 37, 40, 44, 47, 50, 53, 56, 59, 62, 65, 69, 72, 75, 78, 81}\n",
            "82 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 16 19 22 25 28 31 34 37 40 44 47 50 53 56 59 62 65 69 72\n",
            " 75 78 81]\n",
            "\n",
            "{0, 3, 6, 9, 13, 16, 19, 22, 25, 28, 32, 35, 38, 41, 44, 47, 50, 54, 57, 60, 63, 66, 69, 73, 76, 79, 82}\n",
            "83 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 13 16 19 22 25 28 32 35 38 41 44 47 50 54 57 60 63 66 69 73\n",
            " 76 79 82]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 22, 26, 29, 32, 35, 38, 42, 45, 48, 51, 54, 57, 61, 64, 67, 70, 73, 77, 80, 83}\n",
            "84 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 22 26 29 32 35 38 42 45 48 51 54 57 61 64 67 70 73\n",
            " 77 80 83]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 23, 26, 29, 32, 36, 39, 42, 45, 48, 52, 55, 58, 61, 65, 68, 71, 74, 78, 81, 84}\n",
            "85 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 23 26 29 32 36 39 42 45 48 52 55 58 61 65 68 71 74\n",
            " 78 81 84]\n",
            "\n",
            "{0, 3, 7, 10, 13, 16, 20, 23, 26, 29, 33, 36, 39, 42, 46, 49, 52, 56, 59, 62, 65, 69, 72, 75, 78, 82, 85}\n",
            "86 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 16 20 23 26 29 33 36 39 42 46 49 52 56 59 62 65 69 72 75\n",
            " 78 82 85]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 26, 30, 33, 36, 40, 43, 46, 50, 53, 56, 60, 63, 66, 69, 73, 76, 79, 83, 86}\n",
            "87 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 26 30 33 36 40 43 46 50 53 56 60 63 66 69 73 76\n",
            " 79 83 86]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 27, 30, 33, 37, 40, 44, 47, 50, 54, 57, 60, 64, 67, 70, 74, 77, 80, 84, 87}\n",
            "88 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 27 30 33 37 40 44 47 50 54 57 60 64 67 70 74 77\n",
            " 80 84 87]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 20, 24, 27, 30, 34, 37, 41, 44, 47, 51, 54, 58, 61, 64, 68, 71, 74, 78, 81, 85, 88}\n",
            "89 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 20 24 27 30 34 37 41 44 47 51 54 58 61 64 68 71 74 78\n",
            " 81 85 88]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 27, 31, 34, 38, 41, 44, 48, 51, 55, 58, 62, 65, 68, 72, 75, 79, 82, 86, 89}\n",
            "90 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 27 31 34 38 41 44 48 51 55 58 62 65 68 72 75 79\n",
            " 82 86 89]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 28, 31, 35, 38, 42, 45, 48, 52, 55, 59, 62, 66, 69, 73, 76, 80, 83, 87, 90}\n",
            "91 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 28 31 35 38 42 45 48 52 55 59 62 66 69 73 76 80\n",
            " 83 87 90]\n",
            "\n",
            "{0, 4, 7, 10, 14, 18, 21, 24, 28, 32, 35, 38, 42, 46, 49, 52, 56, 60, 63, 66, 70, 74, 77, 80, 84, 88, 91}\n",
            "92 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 10 14 18 21 24 28 32 35 38 42 46 49 52 56 60 63 66 70 74 77 80\n",
            " 84 88 91]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 28, 32, 35, 39, 42, 46, 50, 53, 57, 60, 64, 67, 71, 74, 78, 81, 85, 88, 92}\n",
            "93 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 28 32 35 39 42 46 50 53 57 60 64 67 71 74 78 81\n",
            " 85 88 92]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 29, 32, 36, 39, 43, 46, 50, 54, 57, 61, 64, 68, 72, 75, 79, 82, 86, 89, 93}\n",
            "94 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 29 32 36 39 43 46 50 54 57 61 64 68 72 75 79 82\n",
            " 86 89 93]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 22, 25, 29, 33, 36, 40, 43, 47, 51, 54, 58, 61, 65, 69, 72, 76, 80, 83, 87, 90, 94}\n",
            "95 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 22 25 29 33 36 40 43 47 51 54 58 61 65 69 72 76 80 83\n",
            " 87 90 94]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 29, 33, 37, 40, 44, 48, 51, 55, 58, 62, 66, 69, 73, 77, 80, 84, 88, 91, 95}\n",
            "96 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 29 33 37 40 44 48 51 55 58 62 66 69 73 77 80 84\n",
            " 88 91 95]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 30, 33, 37, 41, 44, 48, 52, 55, 59, 63, 66, 70, 74, 78, 81, 85, 89, 92, 96}\n",
            "97 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 30 33 37 41 44 48 52 55 59 63 66 70 74 78 81 85\n",
            " 89 92 96]\n",
            "\n",
            "{0, 4, 7, 11, 15, 19, 22, 26, 30, 34, 37, 41, 45, 48, 52, 56, 60, 63, 67, 71, 75, 78, 82, 86, 90, 93, 97}\n",
            "98 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 19 22 26 30 34 37 41 45 48 52 56 60 63 67 71 75 78 82 86\n",
            " 90 93 97]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 26, 30, 34, 38, 41, 45, 49, 53, 57, 60, 64, 68, 72, 75, 79, 83, 87, 90, 94, 98}\n",
            "99 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 26 30 34 38 41 45 49 53 57 60 64 68 72 75 79 83 87\n",
            " 90 94 98]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 65, 69, 72, 76, 80, 84, 88, 91, 95, 99}\n",
            "100 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 27 30 34 38 42 46 50 53 57 61 65 69 72 76 80 84 88\n",
            " 91 95 99]\n",
            "\n",
            "Elapsed time: 0.128855 seconds\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from utils import int_linspace\n",
        "from tictoc import tic, toc\n",
        "\n",
        "n_prints = 27\n",
        "\n",
        "tic()\n",
        "for k in range(1):\n",
        "    for n_iter in range(1, 100+1):\n",
        "        # every_n = math.ceil(n_iter / n_prints)\n",
        "        # nums = [x for x in range(n_iter) if x % every_n == 0]\n",
        "        \n",
        "        nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "        print(set(nums))\n",
        "\n",
        "        actual_n_prints = len(nums)\n",
        "        \n",
        "        print(f'{n_iter} batches:, want {n_prints} prints, got {actual_n_prints} prints')\n",
        "        print(nums)\n",
        "        print()\n",
        "toc()\n",
        "\n",
        "# tic()\n",
        "# for k in range(10_000):\n",
        "#     n_iter = 6700000\n",
        "#     nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "# toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 191.19it/s]\n"
          ]
        }
      ],
      "source": [
        "function_samples_dataset_2 = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 151.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([20, 6]) torch.Size([20])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "torch.Size([40, 6]) torch.Size([40])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=20)\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 150.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dataset_with_models.MapFunctionSamplesSubset'>\n",
            "<class 'dataset_with_models.MapFunctionSamplesSubset'> 12\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.0183, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5937, -0.7234, -0.7051, -0.3100,  0.2769, -0.5216]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(24.7716, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3166,  0.5050, -0.4871, -0.4972,  0.1745,  0.8940]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.7187, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3906, -0.7809, -1.0721, -0.8058, -0.3789, -1.7219]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([16, 6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([16])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.5066, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.6178, -1.3973, -0.9966,  0.0687, -0.8019, -0.7827]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(19.7305, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3467, -3.4180, -0.4457,  0.0798,  0.7735, -2.3735]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(30.5852, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3173, -0.1330, -0.6055, -1.2983,  0.1788, -1.1704]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.1442, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.4117,  0.7357,  0.2728, -0.0876,  0.0997, -1.9339]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.1815, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.4540, -1.2818, -0.0256, -0.7721, -0.2421, -0.2774]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.8933, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5878,  0.3725, -1.0817, -0.9872, -0.2428, -0.3045]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.7568, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.0724, -0.6240,  0.2163,  1.1081, -1.6193, -0.1446]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([27, 6]) torch.Size([27])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.9243, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4186, -1.4162, -0.9122, -0.3766, -0.8241, -1.9416]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.8280, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.9496, -1.6693, -1.7773,  0.0875, -1.2961, -0.7184]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "17 14 12 12\n",
            "\n",
            "\n",
            "torch.Size([3, 17, 6]) torch.Size([3, 17]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 17]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 19, 6]) torch.Size([3, 19]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 19]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 30, 6]) torch.Size([3, 30]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 30]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 18, 6]) torch.Size([3, 18]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 18]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "dataset = dataset[:-3]\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1), len(train_subset_1))\n",
        "# train_subset_1 = train_subset_1[:4]\n",
        "# print(type(train_subset_1), len(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = ListMapFunctionSamplesDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(dataset), len(train_dataset), len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = FunctionSamplesAcquisitionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function_samples_dataset.GaussianProcessRandomDataset at 0x7fba1761b850>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient w.r.t x (Approach a): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradient w.r.t x (Approach b): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradients w.r.t x are equal: True\n",
            "Gradient w.r.t y (Approach a): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradient w.r.t y (Approach b): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradients w.r.t y are equal: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=True)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=True)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data:\n",
            " tensor([[[ 0.,  1.,  2.,  3.],\n",
            "         [ 4.,  5.,  6.,  7.],\n",
            "         [ 8.,  9., 10., 11.]],\n",
            "\n",
            "        [[12., 13., 14., 15.],\n",
            "         [16., 17., 18., 19.],\n",
            "         [20., 21., 22., 23.]]], dtype=torch.float32)\n",
            "mask: torch.bool\n",
            " tensor([[[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]],\n",
            "\n",
            "        [[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]]])\n",
            "data masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "data2 masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "stacked_masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 43.,   0.,   0.,   0.,   0.,   0.,  35.,   0.,   0.,   0.,  31.,\n",
              "          0.,   0.,  36.,   0.,  30.,   0.,  36.,   0.,  38.,  36.,  44.,\n",
              "         37.,  28.,  23.,  59.,  39.,  69.,  71.,  67.,  77., 106.,  66.,\n",
              "        106., 144., 149., 130., 136., 198., 145., 243., 230., 236., 285.,\n",
              "        289., 381., 376., 404., 513., 531., 587., 625., 717., 777., 863.,\n",
              "        964.]),\n",
              " array([0.        , 0.10185326, 0.20370652, 0.30555978, 0.40741303,\n",
              "        0.50926629, 0.61111955, 0.71297281, 0.81482607, 0.91667933,\n",
              "        1.01853258, 1.12038584, 1.2222391 , 1.32409236, 1.42594562,\n",
              "        1.52779888, 1.62965214, 1.73150539, 1.83335865, 1.93521191,\n",
              "        2.03706517, 2.13891843, 2.24077169, 2.34262494, 2.4444782 ,\n",
              "        2.54633146, 2.64818472, 2.75003798, 2.85189124, 2.9537445 ,\n",
              "        3.05559775, 3.15745101, 3.25930427, 3.36115753, 3.46301079,\n",
              "        3.56486405, 3.66671731, 3.76857056, 3.87042382, 3.97227708,\n",
              "        4.07413034, 4.1759836 , 4.27783686, 4.37969011, 4.48154337,\n",
              "        4.58339663, 4.68524989, 4.78710315, 4.88895641, 4.99080967,\n",
              "        5.09266292, 5.19451618, 5.29636944, 5.3982227 , 5.50007596,\n",
              "        5.60192922, 5.70378247]),\n",
              " <BarContainer object of 56 artists>)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([479,  61, 736, 798,  30, 101,   1, 207, 625,  55, 805,   2, 456, 702,\n",
            "        554, 463, 154,  42,  80,  63, 324, 101,  34,  31, 401,  58, 893, 635,\n",
            "        533,  19, 598, 977, 753,  74, 293,  14, 125, 583,  10, 754,  15, 326,\n",
            "          5, 111, 422,  43,  80, 139, 185, 349, 108,  42,  37, 765, 146, 121,\n",
            "          2,  57,  34,  19,  22,  36,  63, 365,  21,  13, 911,  31, 913,  36,\n",
            "         17,  14, 299,   5,   7,  52,   6,  93,  50,  28,  31,   6, 168,  39,\n",
            "         10, 405,   6, 133,  79,  24,   6,  98,  12, 202, 736,   8, 238, 179,\n",
            "         19, 130, 193,  66, 371, 167, 484, 162, 935,  11,  20, 145,  17,  99,\n",
            "          3, 177,  10, 776,  94, 524, 266, 316,  51,  45,  33,  20, 133,   2,\n",
            "        845, 219,   9,  61, 353,  28,   9,  70, 187, 409, 740, 638,  28,  18,\n",
            "        191,  35, 148, 618, 394,  70, 381,   5, 411, 394,   1,  31, 318, 237,\n",
            "         39, 284, 312,  47, 158, 105,  44,  99, 133, 908,  39, 273, 134,  18,\n",
            "          5, 716, 279, 115,  44,  46, 106,  53,  26, 646,  18, 986, 994,  61,\n",
            "        218, 963,  17, 156,  47, 605,   4,  50,  58, 244, 729,  38, 993,  74,\n",
            "         21,  22,   6, 166, 798,   2, 312, 561,  53,  80, 235, 163, 159,  39,\n",
            "        155, 180, 252,   9, 818, 388,  18,  14,  64,   9,  42,  24, 416,   4,\n",
            "        734,  60,  15, 295, 232, 578, 235, 330, 272, 209, 275,  51,   2, 573,\n",
            "         14,  42, 109,   5,  79,  23, 119, 988,  90, 426, 182,  65, 132, 235,\n",
            "         68,  26,  63, 330,  25, 296, 372, 127,  49,  12,  40, 124, 169, 224,\n",
            "        238,  16,  19, 648, 107, 516, 614,  94, 737,  35,  35, 161,  11,  68,\n",
            "        742,  16, 348,  21, 346, 699,  21,   2,   3,  35,  10, 179,  13,  30,\n",
            "        114,  60,  24, 242, 258, 119,  48, 181,  15, 104,  23, 527,   7, 443,\n",
            "         21,   6,  49,  19, 927,   9, 604, 317, 519, 128, 178, 177, 555,  61,\n",
            "        177, 561, 160,  69,  34, 396, 849,  25, 311,  35,  13, 418, 895,  46,\n",
            "         82, 688, 436, 840,  50, 280, 810,  96,   1, 647,  76,  61,  69,  34,\n",
            "        722,   5,   1, 606,  39,  66, 354, 228, 108,   1,   5,  81,  28,  15,\n",
            "        375,  13, 343, 154, 475, 975, 475,   1,  17, 271,  51, 482, 491, 782,\n",
            "        390, 448,  58, 465, 100,  59,  42, 186,  19, 192,  37, 251,  51, 493,\n",
            "         15,   2,   8, 629, 105, 257,  50, 266, 100, 283,  35, 217, 192,  14,\n",
            "         16, 213, 107, 253,  96, 212, 703,  11, 355,  40,  80,  28, 415,   3,\n",
            "         94, 165,  47,   7, 138,  32, 137,  14, 893,  16,  42, 459, 663, 147,\n",
            "         43,  10, 308, 563, 382,  65,  10,  66,   8,   5, 131,   3, 100,  82,\n",
            "        253, 943, 370,  15,  41,  10,  13,  81,  23, 658,   7, 303, 803, 108,\n",
            "        899, 904, 791, 649, 327, 208, 312,   6, 153,  66, 306, 393,  17,   6,\n",
            "         22, 105,  37, 598, 101,  10, 981,  56, 114,  12,  21,   1,  48, 133,\n",
            "        311, 695, 195, 709, 793,  19,  65, 414, 648, 382,  61,  94, 325, 591,\n",
            "         53,  22, 390, 103, 267, 150, 162, 877,  74,  30, 813,  52,  29, 268,\n",
            "        162,   4,  25, 699, 241, 133,  26,  54,  82,  76,  35,   4,  44,  16,\n",
            "        713, 203, 405, 962, 149, 776, 364, 213,  54,  20,  88,  59, 115, 341,\n",
            "        315,  98, 349,  48,  23, 199,   7, 682, 948, 490, 179,  77,  66,  97,\n",
            "        183, 234,  49,  40,  34, 137, 159, 504, 289, 664, 622,  32,  82,  13,\n",
            "        243,   4, 100, 222,   4,  97,  30,  86,  75, 271, 108,   1, 630, 850,\n",
            "        820, 681, 255,   7,  63, 104,   2, 175, 499,  16,  95, 125,   8,  83,\n",
            "         28,  47,  38, 115, 461,  90, 237,  34,   1,  58,  62,  11, 919,  66,\n",
            "        705,  29,  10,  28, 459,  45,  46, 620,   2,   1, 102,   8,   9, 378,\n",
            "        587, 453, 280, 667, 286, 235,  48,   5,  11, 151, 188, 472, 479, 879,\n",
            "        163, 213, 689,  30, 446, 901,  55, 346,  37,  57,  19,  79,   2, 157,\n",
            "          2,  70,  27, 227,  12, 533, 220,  28, 335,  66,  37,  34,  79,  62,\n",
            "         27, 249,   4, 134, 177, 383,  12,  53,  74,  86,  53,  77,  59, 941,\n",
            "         11,  19,  47, 144,  56, 219, 763, 155, 122,  18, 518,  37, 287,  89,\n",
            "          2, 579, 428,  28,  59, 150, 648,  46, 574, 477, 127,  13, 975,   3,\n",
            "          4, 617, 148, 206, 109, 989, 334, 787,  47, 297,   2, 936, 512, 110,\n",
            "        527, 197,  77, 185, 188,  33,  57, 400,  14, 492, 839, 569,   3,  16,\n",
            "         18, 696, 101,  15, 237,  40,  57,  67, 250, 111, 107, 112, 849,  58,\n",
            "         29, 368, 526, 385, 269, 795,  51,  90, 128, 338, 508,  31, 504,  76,\n",
            "          5, 969,  29, 271,  29,  17,   6,  35,  20,  13, 384,  40, 519,  72,\n",
            "        514, 564, 156, 342,   2, 120, 355, 369,  45, 246, 435, 178, 237, 312,\n",
            "          2, 354,  69,  77, 137, 933,  85,   8, 242,   8, 272, 114, 255, 355,\n",
            "        294,  35, 159,   3, 110,  35, 321,  58,   2, 290,  76, 192, 190, 137,\n",
            "        115, 167,  51, 584, 926,  10, 843, 111, 929, 197,  53, 268,  22, 108,\n",
            "        940, 189, 208,  33,  25,  18, 200, 334, 811, 638, 931,  34,  19, 931,\n",
            "        216,   4, 837,   8, 135, 998,  56,  27, 743,  85,   4, 213,   9, 526,\n",
            "         21, 563, 291,   4,  29, 691, 668,   1, 915, 129,  45,  11, 131,  34,\n",
            "        170,  15, 112,  58,  66,   1,  10,  24, 260,  12, 295, 299,  19, 101,\n",
            "         17,  61, 615,  33,  13, 459,  99,  17,  76,  39,   2, 335,  14, 227,\n",
            "        885, 160, 106,  23, 412,  23, 124,  62,  20,  22, 454, 662,  11,   4,\n",
            "        338, 160, 243, 385,  98,   3, 120, 135,  16, 535, 843, 538, 244, 108,\n",
            "         30, 962, 776, 108,  44, 763,  57, 161,   8,  72,  21,  93,   1, 232,\n",
            "        295, 209, 118, 516, 994,  19,  29, 569,  51,  87,  89,  44,  24, 350,\n",
            "         56, 104, 234,  38,   2,  83,  86,   9, 470,  23, 129, 150,  16, 290,\n",
            "        306,   4, 510, 371, 106,  42,  15, 152, 556,  22, 143,  13,  19, 131,\n",
            "        255, 604, 186, 223,   9, 571], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
