{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
        "from gpytorch.constraints.constraints import GreaterThan\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset, LazyMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([10.,  2.,  3.], requires_grad=True), tensor([10.,  2.,  3.]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x.detach()\n",
        "y[0] = 10.\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "float"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "type(x.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.to(None) is x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = (torch.tensor([1.2, 3.4]), torch.tensor(9.))\n",
        "b = tuple(x for x in a)\n",
        "a == b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "items: (1, 2, 3)\n",
            "kwargs: {}\n",
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "{'items_list': [1, 2, 3], 'model_index': 0, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}}\n",
            "TESTING_______\n",
            "items: (1, 2, 3)\n",
            "kwargs: {}\n",
            "items: (1, 2, 3)\n",
            "kwargs: {}\n",
            "items: (4, 5, 6)\n",
            "kwargs: {}\n",
            "items: (1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "kwargs: {}\n",
            "TupleWithModel(1, 2, 3, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "TupleWithModel(4, 5, 6)\n",
            "items: (1, 2, 3)\n",
            "kwargs: {}\n",
            "items: (1, 2, 3)\n",
            "kwargs: {}\n",
            "items: ()\n",
            "kwargs: {'a': 1, 'b': 2, 'c': 3}\n",
            "items: (4, 1)\n",
            "kwargs: {'ba': 3, 's': 'df'}\n",
            "All tests passed!\n",
            "MORE TESTING_______\n",
            "items: (1, 2, 3, 4)\n",
            "kwargs: {'give_improvements': 2}\n",
            "4 2\n",
            "{'x_hist': 1, 'y_hist': 2, 'x_cand': 3, 'vals_cand': 4, 'model_index': 2, 'model_params': {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}, 'give_improvements': 2} <class 'dict'>\n",
            "items: ()\n",
            "kwargs: {'x_hist': 1, 'y_hist': 2, 'x_cand': 3, 'vals_cand': 4, 'give_improvements': 2}\n",
            "Adding the items from the kwargs\n",
            "name: x_hist\n",
            "name: y_hist\n",
            "name: x_cand\n",
            "name: vals_cand\n",
            "AcquisitionDatasetModelItem(1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "), give_improvements=2)\n",
            "items: (1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "kwargs: {'give_improvements': 2}\n",
            "items: (1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "), {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])})\n",
            "kwargs: {'give_improvements': 2}\n",
            "items: (1, 2, 3, 4, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "kwargs: {'give_improvements': 2}\n",
            "items: (1, 2, 3, 4, {'likelihood.noise_covar.raw_noise': tensor([2.0000]), 'mean_module.raw_constant': tensor(0.), 'covar_module.raw_lengthscale': tensor([[0.]])}, DummyGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (noise_prior): GammaPrior()\n",
            "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): RBFKernel(\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "))\n",
            "kwargs: {'give_improvements': 2}\n",
            "AcquisitionDatasetModelItem.__init__: model should be a SingleTaskGP instance.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.0446]), std = tensor([0.9236])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n",
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2603]), std = tensor([0.7938])). Please consider scaling the input to zero mean and unit variance.\n",
            "  warnings.warn(msg, InputDataWarning)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from gpytorch.kernels import RBFKernel\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "\n",
        "from dataset_with_models import RandomModelSampler, TupleWithModel\n",
        "\n",
        "# Create a dummy SingleTaskGP model\n",
        "class DummyGP(SingleTaskGP):\n",
        "    def __init__(self, train_X, train_Y):\n",
        "        super().__init__(train_X, train_Y)\n",
        "        self.mean_module = ConstantMean()\n",
        "        self.covar_module = RBFKernel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# Create dummy data\n",
        "train_X = torch.rand(10, 1)\n",
        "train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "# Initialize dummy models\n",
        "model1 = DummyGP(train_X, train_Y)\n",
        "model2 = DummyGP(train_X, train_Y)\n",
        "model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "\n",
        "# Initialize RandomModelSampler\n",
        "sampler = RandomModelSampler(models)\n",
        "\n",
        "# Example usage of TupleWithModel\n",
        "tuple_with_model = TupleWithModel(1, 2, 3, model=model1)\n",
        "\n",
        "print(tuple_with_model)\n",
        "print(tuple_with_model.to_dict())\n",
        "\n",
        "\n",
        "def test_tuple_with_model():\n",
        "    # Create dummy data\n",
        "    train_X = torch.rand(10, 1)\n",
        "    train_Y = torch.sin(train_X * (2 * torch.pi)) + 0.2 * torch.randn(10, 1)\n",
        "\n",
        "    # Initialize dummy models\n",
        "    model1 = DummyGP(train_X, train_Y)\n",
        "    model2 = DummyGP(train_X, train_Y)\n",
        "    model3 = DummyGP(train_X, train_Y)\n",
        "\n",
        "    models = [model1, model2, model3]\n",
        "    sampler = RandomModelSampler(models)\n",
        "\n",
        "    # Initialize TupleWithModel instances\n",
        "    twm1 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    twm2 = TupleWithModel(1, 2, 3, model=model2)\n",
        "    twm3 = TupleWithModel(4, 5, 6)\n",
        "\n",
        "    assert TupleWithModel(*twm1._tuple) == twm1\n",
        "\n",
        "    # Test __len__\n",
        "    assert len(twm1) == 4\n",
        "    assert len(twm3) == 3\n",
        "\n",
        "    # Test __getitem__\n",
        "    assert twm1[0] == 1\n",
        "    assert twm1[1] == 2\n",
        "    assert twm1[2] == 3\n",
        "    assert twm1[3] == model1\n",
        "\n",
        "    # Test __repr__\n",
        "    print(twm1)\n",
        "    print(twm3)\n",
        "\n",
        "    # Test __eq__\n",
        "    twm4 = TupleWithModel(1, 2, 3, model=model1)\n",
        "    assert twm1 == twm4\n",
        "    assert twm1 != twm2\n",
        "    assert twm1 != twm3\n",
        "\n",
        "    # Test to_dict and from_dict\n",
        "    twm_dict = twm1.to_dict()\n",
        "    twm_reconstructed = TupleWithModel.from_dict(twm_dict, model_sampler=sampler)\n",
        "    assert twm1 == twm_reconstructed\n",
        "\n",
        "    # Test initialization with kwargs\n",
        "    twm5 = TupleWithModel(a=1, b=2, c=3)\n",
        "    assert twm5._items == tuple()\n",
        "    assert twm5._kwargs == {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "    twm6 = TupleWithModel(4, 1, ba=3, s=\"df\")\n",
        "    assert twm6._items == (4, 1)\n",
        "    assert twm6._kwargs == {'ba': 3, 's': \"df\"}\n",
        "\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "print(\"TESTING_______\")\n",
        "test_tuple_with_model()\n",
        "\n",
        "from acquisition_dataset import AcquisitionDatasetModelItem\n",
        "\n",
        "print(\"MORE TESTING_______\")\n",
        "\n",
        "x = AcquisitionDatasetModelItem(1, 2, 3, 4, give_improvements=2, model=model3)\n",
        "print(x.vals_cand, x.give_improvements)\n",
        "d = x.to_dict()\n",
        "print(d, type(d))\n",
        "y = AcquisitionDatasetModelItem.from_dict(d, model_sampler=sampler)\n",
        "print(y)\n",
        "\n",
        "v = AcquisitionDatasetModelItem(*y._tuple, **y._kwargs)\n",
        "assert v == y\n",
        "\n",
        "w = AcquisitionDatasetModelItem(*v._tuple + (v.model_params,), **v._kwargs)\n",
        "assert w == y\n",
        "\n",
        "x = AcquisitionDatasetModelItem(*v._tuple, model_params=v.model_params, **v._kwargs)\n",
        "assert x == y\n",
        "\n",
        "try:\n",
        "    q = AcquisitionDatasetModelItem(*v._tuple[:-1] + (v.model_params, v.model), **v._kwargs)\n",
        "    assert False\n",
        "except ValueError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': -100, 'b': 5, 'c': 0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {'a': 4, 'b': 5}\n",
        "dict(d, c=0, a=-100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000],\n",
              "        [0.5000],\n",
              "        [1.0000],\n",
              "        [1.5000],\n",
              "        [2.0000]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.linspace(0, 2, 5).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3890],\n",
              "        [0.2284],\n",
              "        [0.2776],\n",
              "        [0.0168],\n",
              "        [0.9678]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5187,  0.6291],\n",
            "        [ 0.9814, -0.4486],\n",
            "        [-0.6453,  2.0720]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "indices = torch.argmax(a, dim=1, keepdim=True)\n",
        "print(torch.gather(a, 1, indices).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "true model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "fitted model\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([0.])\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(1.4415, requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(-2.6042, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[-0.5135]], requires_grad=True)\n",
            "\n",
            "True:   l=0.693, sigma^2=0.693, noise=0\n",
            "Fitted: l=0.469, sigma^2=0.0714, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "kernel = ScaleKernel(RBFKernel())\n",
        "kernel.initialize(**{'base_kernel.lengthscale': torch.tensor(0.2)})\n",
        "likelihood = GaussianLikelihood(\n",
        "    noise_prior=None, batch_shape=torch.Size(),\n",
        "    noise_constraint=GreaterThan(\n",
        "        0.0, transform=None, initial_value=0.2\n",
        "    )\n",
        ")\n",
        "train_X = torch.zeros(0, 1, device=device)\n",
        "train_Y = torch.zeros(0, 1, device=device)\n",
        "\n",
        "models = [SingleTaskGP(train_X, train_Y, likelihood=likelihood, covar_module=kernel)]\n",
        "\n",
        "# This is unsupported:\n",
        "# train_Yvar = torch.full_like(train_Y, 1e-6)\n",
        "# models =[\n",
        "#     SingleTaskGP(train_X, train_Y, train_Yvar)\n",
        "#     ]\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=3, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device,\n",
        "    randomize_params=False, models=None) # or models=None to make default\n",
        "\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=get_uniform_randint_generator(1, 8), \n",
        "#     observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=True, device=device,\n",
        "#     randomize_params=False, models=models) # or models=None to make default\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "true_noise = model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "print(\"true model\")\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().clone().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().clone().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.noise.squeeze().detach().clone().numpy()\n",
        "\n",
        "print(\"fitted model\")\n",
        "for name, param in fitted_model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mLazyMapFunctionSamplesDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:624\u001b[0m, in \u001b[0;36mLazyMapDatasetWithModels.__init__\u001b[0;34m(self, dataset, n_realizations)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_realizations \u001b[38;5;241m=\u001b[39m n_realizations\n\u001b[0;32m--> 624\u001b[0m items_generator, size \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_items_generator_and_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_realizations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items_generator \u001b[38;5;241m=\u001b[39m items_generator\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m size\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/dataset_with_models.py:329\u001b[0m, in \u001b[0;36mDatasetWithModels._get_items_generator_and_size\u001b[0;34m(self, n_samples, verbose, verbose_message)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iterable_is_finite(dataset):\n\u001b[0;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt store an infinite-sized \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m if n_samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not specified. Either specify n_samples or use a finite-sized dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# The dataset is finite and we want to save all of it\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     new_data_iterable \u001b[38;5;241m=\u001b[39m dataset\n",
            "\u001b[0;31mValueError\u001b[0m: Can't store an infinite-sized GaussianProcessRandomDataset if n_samples is not specified. Either specify n_samples or use a finite-sized dataset."
          ]
        }
      ],
      "source": [
        "# ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "# LazyMapFunctionSamplesDataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.2799e+00, 1.3863e+00, 2.2204e-16]) tensor([1.2799, 1.3863,    nan])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.25, 0.25, 0.25, 0.25], [0.0, 1.0, 0.0, 0.0]])\n",
        "entropy2 = Categorical(probs = p_tensor).entropy()\n",
        "print(entropy2, -(p_tensor * torch.log(p_tensor)).sum(axis=1))\n",
        "\n",
        "def max_one_hot(values, mask=None):\n",
        "    if mask is not None:\n",
        "        neg_inf = torch.zeros_like(values)\n",
        "        neg_inf[~mask] = float(\"-inf\")\n",
        "        values = values + neg_inf\n",
        "    return F.one_hot(torch.argmax(values, dim=1),\n",
        "                     num_classes=values.size(1)).double()\n",
        "\n",
        "max_one_hot(p_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9616098361677539"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_average_normalized_entropy(probabilities, mask=None):\n",
        "    entropy = Categorical(probs=probabilities).entropy()\n",
        "    counts = mask.sum(dim=1).double() if mask is not None else torch.tensor(probabilities.size(1), dtype=torch.double)\n",
        "    return (entropy / torch.log(counts)).mean()\n",
        "\n",
        "p_tensor = torch.Tensor([[0.1, 0.2, 0.4, 0.3], [0.5, 0.5, 0.0, 0.0]])\n",
        "get_average_normalized_entropy(p_tensor, mask=torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0.]], requires_grad=True))]\n",
            "\n",
            "['likelihood.noise_covar.raw_noise', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale']\n",
            "['likelihood.noise_covar.raw_noise', 'likelihood.noise_covar.raw_noise_constraint.lower_bound', 'likelihood.noise_covar.raw_noise_constraint.upper_bound', 'mean_module.raw_constant', 'covar_module.raw_outputscale', 'covar_module.base_kernel.raw_lengthscale', 'covar_module.base_kernel.lengthscale_prior.concentration', 'covar_module.base_kernel.lengthscale_prior.rate', 'covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', 'covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', 'covar_module.outputscale_prior.concentration', 'covar_module.outputscale_prior.rate', 'covar_module.raw_outputscale_constraint.lower_bound', 'covar_module.raw_outputscale_constraint.upper_bound']\n",
            "[('covar_module.outputscale_prior', ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method ScaleKernel._outputscale_param of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>, <bound method ScaleKernel._outputscale_closure of ScaleKernel(\n",
            "  (base_kernel): MaternKernel(\n",
            "    (lengthscale_prior): GammaPrior()\n",
            "    (raw_lengthscale_constraint): Positive()\n",
            "  )\n",
            "  (outputscale_prior): GammaPrior()\n",
            "  (raw_outputscale_constraint): Positive()\n",
            ")>), ('covar_module.base_kernel.lengthscale_prior', MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            "), GammaPrior(), <bound method Kernel._lengthscale_param of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>, <bound method Kernel._lengthscale_closure of MaternKernel(\n",
            "  (lengthscale_prior): GammaPrior()\n",
            "  (raw_lengthscale_constraint): Positive()\n",
            ")>)]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))\n",
        "print()\n",
        "\n",
        "print([name for name, param in item1[-1].named_parameters()])\n",
        "print([name for name in item1[-1].state_dict()])\n",
        "\n",
        "# https://docs.gpytorch.ai/en/stable/_modules/gpytorch/module.html#Module.named_priors\n",
        "model1 = item1[-1]\n",
        "print(list(model1.named_priors()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fba130f4ee0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7216, 0.5588, 0.0163],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.8445, 0.7417, 0.1469],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.8424, 0.6213, 0.9883],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460]])\n",
            "tensor([2, 4, 0, 6, 7, 1, 3, 5])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163],\n",
            "        [0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n",
            "tensor([[0.8445, 0.7417, 0.1469],\n",
            "        [0.1534, 0.6505, 0.3717],\n",
            "        [0.7216, 0.5588, 0.0163]])\n",
            "tensor([[0.7804, 0.5583, 0.8764],\n",
            "        [0.3487, 0.1458, 0.6460],\n",
            "        [0.2358, 0.4761, 0.7996],\n",
            "        [0.1755, 0.5438, 0.9176],\n",
            "        [0.8424, 0.6213, 0.9883]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.4122, -9.7531, -9.2286, -9.5989, -9.1321, -9.4680, -9.3031, -9.7429,\n",
              "        -9.3805, -9.6507, -9.0406, -9.3168, -9.1272, -9.9820, -9.1291, -9.4314,\n",
              "        -9.7203, -9.4293, -9.0302, -9.4230])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.]),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(0., requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.]], requires_grad=True)}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.),\n",
              " 'covar_module.raw_outputscale': tensor(0.),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.]])}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [00:04<00:00, 237.86it/s]\n"
          ]
        }
      ],
      "source": [
        "fixed_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3770e-01, 5.9728e-01, 1.3027e-01, 8.7175e-01, 1.3623e-01],\n",
              "        [2.8008e-01, 5.2939e-01, 7.4921e-01, 6.7475e-01, 7.0635e-01],\n",
              "        [3.8596e-04, 1.7254e-01, 9.1312e-01, 5.6526e-01, 8.1478e-01],\n",
              "        [4.3732e-01, 4.3083e-01, 3.0867e-01, 7.7489e-01, 8.4643e-01],\n",
              "        [6.1417e-01, 7.0303e-01, 8.9406e-02, 6.5903e-01, 9.4700e-01],\n",
              "        [1.3595e-01, 2.9692e-01, 8.0865e-01, 3.6557e-01, 8.0262e-02],\n",
              "        [5.5435e-01, 2.0977e-01, 9.9751e-01, 2.5552e-01, 2.0415e-01],\n",
              "        [9.2425e-01, 4.8544e-01, 7.1970e-01, 3.0899e-01, 4.5466e-02],\n",
              "        [4.7055e-01, 6.2878e-01, 3.4137e-01, 1.5561e-01, 2.4682e-01],\n",
              "        [5.0904e-01, 5.2614e-01, 5.8093e-01, 3.4311e-02, 5.9625e-01],\n",
              "        [2.4432e-02, 3.5175e-01, 1.1442e-01, 4.1488e-01, 2.4443e-01],\n",
              "        [1.9026e-01, 5.0099e-01, 8.4974e-01, 9.3262e-01, 9.7229e-01],\n",
              "        [6.5269e-01, 1.5853e-01, 5.4473e-01, 3.1906e-01, 5.2323e-01],\n",
              "        [3.3650e-01, 5.1750e-01, 7.4551e-01, 5.5767e-01, 2.9194e-01],\n",
              "        [9.8836e-01, 4.7839e-01, 9.2729e-01, 5.5478e-02, 3.0561e-01],\n",
              "        [5.3924e-01, 5.8842e-02, 8.9266e-01, 9.7812e-01, 5.7267e-01],\n",
              "        [3.1673e-01, 2.5540e-01, 2.3361e-01, 5.1155e-01, 1.0439e-01],\n",
              "        [9.1125e-01, 9.1233e-01, 2.4270e-01, 6.6415e-01, 5.5721e-01],\n",
              "        [7.4868e-01, 8.5152e-01, 9.0714e-01, 2.8652e-01, 1.8544e-01],\n",
              "        [6.2989e-01, 1.9168e-02, 2.5467e-02, 8.0095e-01, 6.3958e-01]])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = ListMapFunctionSamplesDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPDatasetItem([0], [0]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([1], [1]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([2], [2]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([3], [3]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([4], [4]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([5], [5]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([6], [6]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([7], [7]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([8], [8]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([9], [9]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([10], [10]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([11], [11]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([12], [12]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([13], [13]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([14], [14]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([15], [15]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([16], [16]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([17], [17]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([18], [18]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([19], [19]) <class 'function_samples_dataset.GPDatasetItem'>\n",
            "GPDatasetItem([12, 13], [33]) <class 'function_samples_dataset.GPDatasetItem'>\n"
          ]
        }
      ],
      "source": [
        "# test_dataset = ListMapFunctionSamplesDataset([\n",
        "#     ([i], [i]) for i in range(20)\n",
        "# ] + [([12, 13], [33], SingleTaskGP(torch.zeros(2, 1), torch.zeros(2, 1), likelihood=likelihood, covar_module=kernel))])\n",
        "\n",
        "test_dataset = ListMapFunctionSamplesDataset([\n",
        "    ([i], [i]) for i in range(20)\n",
        "] + [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = ListMapFunctionSamplesDataset(\n",
        "#     [([12, 13], [33])])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x, type(x))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')\n",
        " # \"Generating GP realizations:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/123 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 123/123 [00:00<00:00, 291.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating and saving realizations from GaussianProcessRandomDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 94/94 [00:00<00:00, 285.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5, dataset_size=94)\n",
        "function_samples_dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 123)\n",
        "function_samples_dataset = function_samples_dataset[:20]\n",
        "function_samples_dataset.save('fixed', 17)\n",
        "rand_dataset.save('random')\n",
        "loaded_dataset = ListMapFunctionSamplesDataset.load('fixed')\n",
        "print(len(loaded_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 17)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0}\n",
            "1 batches:, want 27 prints, got 1 prints\n",
            "[0]\n",
            "\n",
            "{0, 1}\n",
            "2 batches:, want 27 prints, got 2 prints\n",
            "[0 1]\n",
            "\n",
            "{0, 1, 2}\n",
            "3 batches:, want 27 prints, got 3 prints\n",
            "[0 1 2]\n",
            "\n",
            "{0, 1, 2, 3}\n",
            "4 batches:, want 27 prints, got 4 prints\n",
            "[0 1 2 3]\n",
            "\n",
            "{0, 1, 2, 3, 4}\n",
            "5 batches:, want 27 prints, got 5 prints\n",
            "[0 1 2 3 4]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5}\n",
            "6 batches:, want 27 prints, got 6 prints\n",
            "[0 1 2 3 4 5]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6}\n",
            "7 batches:, want 27 prints, got 7 prints\n",
            "[0 1 2 3 4 5 6]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "8 batches:, want 27 prints, got 8 prints\n",
            "[0 1 2 3 4 5 6 7]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "9 batches:, want 27 prints, got 9 prints\n",
            "[0 1 2 3 4 5 6 7 8]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10 batches:, want 27 prints, got 10 prints\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
            "11 batches:, want 27 prints, got 11 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
            "12 batches:, want 27 prints, got 12 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
            "13 batches:, want 27 prints, got 13 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n",
            "14 batches:, want 27 prints, got 14 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
            "15 batches:, want 27 prints, got 15 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}\n",
            "16 batches:, want 27 prints, got 16 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}\n",
            "17 batches:, want 27 prints, got 17 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n",
            "18 batches:, want 27 prints, got 18 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n",
            "19 batches:, want 27 prints, got 19 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
            "20 batches:, want 27 prints, got 20 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}\n",
            "21 batches:, want 27 prints, got 21 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21}\n",
            "22 batches:, want 27 prints, got 22 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}\n",
            "23 batches:, want 27 prints, got 23 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}\n",
            "24 batches:, want 27 prints, got 24 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24}\n",
            "25 batches:, want 27 prints, got 25 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n",
            "26 batches:, want 27 prints, got 26 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26}\n",
            "27 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n",
            "28 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27]\n",
            "\n",
            "{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28}\n",
            "29 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24 25\n",
            " 26 27 28]\n",
            "\n",
            "{0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29}\n",
            "30 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 25 26\n",
            " 27 28 29]\n",
            "\n",
            "{0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30}\n",
            "31 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  3  5  6  7  8  9 10 12 13 14 15 16 17 18 20 21 22 23 24 25 27\n",
            " 28 29 30]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31}\n",
            "32 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 23 24 25 26 27\n",
            " 29 30 31]\n",
            "\n",
            "{0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31, 32}\n",
            "33 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  2  4  5  6  7  9 10 11 12 14 15 16 17 18 20 21 22 23 25 26 27 28\n",
            " 30 31 32]\n",
            "\n",
            "{0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33}\n",
            "34 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  6  8  9 10 11 13 14 15 16 18 19 20 22 23 24 25 27 28 29\n",
            " 30 32 33]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34}\n",
            "35 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 10 12 13 14 16 17 18 20 21 22 24 25 26 27 29 30\n",
            " 31 33 34]\n",
            "\n",
            "{0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35}\n",
            "36 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  5  7  8  9 11 12 13 15 16 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 34 35]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36}\n",
            "37 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  8 10 11 12 14 15 17 18 19 21 22 24 25 26 28 29 30 32\n",
            " 33 35 36]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 36, 37}\n",
            "38 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 11 13 14 16 17 18 20 21 23 24 26 27 28 30 31 33\n",
            " 34 36 37]\n",
            "\n",
            "{0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38}\n",
            "39 batches:, want 27 prints, got 27 prints\n",
            "[ 0  1  3  4  6  7  9 10 12 13 15 16 18 19 20 22 23 25 26 28 29 31 32 34\n",
            " 35 37 38]\n",
            "\n",
            "{0, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 26, 27, 28, 30, 32, 33, 34, 36, 38, 39}\n",
            "40 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  4  6  8  9 10 12 14 15 16 18 20 21 22 24 26 27 28 30 32 33 34\n",
            " 36 38 39]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40}\n",
            "41 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 12 14 15 17 18 20 22 23 25 26 28 29 31 32 34 35\n",
            " 37 38 40]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 17, 19, 20, 22, 24, 25, 27, 28, 30, 32, 33, 35, 36, 38, 39, 41}\n",
            "42 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8  9 11 13 14 16 17 19 20 22 24 25 27 28 30 32 33 35 36\n",
            " 38 39 41]\n",
            "\n",
            "{0, 2, 3, 5, 6, 8, 10, 11, 13, 15, 16, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 36, 37, 39, 40, 42}\n",
            "43 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  6  8 10 11 13 15 16 18 19 21 23 24 26 27 29 31 32 34 36 37\n",
            " 39 40 42]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 13, 15, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 35, 36, 38, 40, 41, 43}\n",
            "44 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 13 15 17 18 20 22 23 25 26 28 30 31 33 35 36 38\n",
            " 40 41 43]\n",
            "\n",
            "{0, 2, 3, 5, 7, 8, 10, 12, 14, 15, 17, 19, 20, 22, 24, 25, 27, 29, 30, 32, 34, 36, 37, 39, 41, 42, 44}\n",
            "45 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  8 10 12 14 15 17 19 20 22 24 25 27 29 30 32 34 36 37 39\n",
            " 41 42 44]\n",
            "\n",
            "{0, 2, 3, 5, 7, 9, 10, 12, 14, 16, 17, 19, 21, 22, 24, 26, 28, 29, 31, 33, 35, 36, 38, 40, 42, 43, 45}\n",
            "46 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  3  5  7  9 10 12 14 16 17 19 21 22 24 26 28 29 31 33 35 36 38 40\n",
            " 42 43 45]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 12, 14, 16, 18, 19, 21, 23, 25, 27, 28, 30, 32, 34, 35, 37, 39, 41, 42, 44, 46}\n",
            "47 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 12 14 16 18 19 21 23 25 27 28 30 32 34 35 37 39 41\n",
            " 42 44 46]\n",
            "\n",
            "{0, 2, 4, 5, 7, 9, 11, 13, 14, 16, 18, 20, 22, 24, 25, 27, 29, 31, 33, 34, 36, 38, 40, 42, 43, 45, 47}\n",
            "48 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  5  7  9 11 13 14 16 18 20 22 24 25 27 29 31 33 34 36 38 40 42\n",
            " 43 45 47]\n",
            "\n",
            "{0, 2, 4, 6, 7, 9, 11, 13, 15, 17, 18, 20, 22, 24, 26, 28, 30, 31, 33, 35, 37, 39, 41, 42, 44, 46, 48}\n",
            "49 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  7  9 11 13 15 17 18 20 22 24 26 28 30 31 33 35 37 39 41 42\n",
            " 44 46 48]\n",
            "\n",
            "{0, 2, 4, 6, 8, 9, 11, 13, 15, 17, 19, 21, 23, 24, 26, 28, 30, 32, 34, 36, 38, 40, 41, 43, 45, 47, 49}\n",
            "50 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8  9 11 13 15 17 19 21 23 24 26 28 30 32 34 36 38 40 41 43\n",
            " 45 47 49]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 38, 40, 42, 44, 46, 48, 50}\n",
            "51 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 13 15 17 19 21 23 25 27 29 31 33 35 37 38 40 42 44\n",
            " 46 48 50]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51}\n",
            "52 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 27 29 31 33 35 37 39 41 43 45\n",
            " 47 49 51]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52}\n",
            "53 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46\n",
            " 48 50 52]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53}\n",
            "54 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 29 31 33 35 37 39 41 43 45 47\n",
            " 49 51 53]\n",
            "\n",
            "{0, 2, 4, 6, 8, 10, 12, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 52, 54}\n",
            "55 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 10 12 15 17 19 21 23 25 27 29 31 33 35 37 39 42 44 46 48\n",
            " 50 52 54]\n",
            "\n",
            "{0, 2, 4, 6, 8, 11, 13, 15, 17, 19, 21, 23, 25, 28, 30, 32, 34, 36, 38, 40, 42, 44, 47, 49, 51, 53, 55}\n",
            "56 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  8 11 13 15 17 19 21 23 25 28 30 32 34 36 38 40 42 44 47 49\n",
            " 51 53 55]\n",
            "\n",
            "{0, 2, 4, 6, 9, 11, 13, 15, 17, 19, 22, 24, 26, 28, 30, 32, 34, 37, 39, 41, 43, 45, 47, 50, 52, 54, 56}\n",
            "57 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  6  9 11 13 15 17 19 22 24 26 28 30 32 34 37 39 41 43 45 47 50\n",
            " 52 54 56]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 15, 18, 20, 22, 24, 26, 29, 31, 33, 35, 37, 39, 42, 44, 46, 48, 50, 53, 55, 57}\n",
            "58 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 15 18 20 22 24 26 29 31 33 35 37 39 42 44 46 48 50\n",
            " 53 55 57]\n",
            "\n",
            "{0, 2, 4, 7, 9, 11, 13, 16, 18, 20, 22, 25, 27, 29, 31, 33, 36, 38, 40, 42, 45, 47, 49, 51, 54, 56, 58}\n",
            "59 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  4  7  9 11 13 16 18 20 22 25 27 29 31 33 36 38 40 42 45 47 49 51\n",
            " 54 56 58]\n",
            "\n",
            "{0, 2, 5, 7, 9, 11, 14, 16, 18, 20, 23, 25, 27, 30, 32, 34, 36, 39, 41, 43, 45, 48, 50, 52, 54, 57, 59}\n",
            "60 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 11 14 16 18 20 23 25 27 30 32 34 36 39 41 43 45 48 50 52\n",
            " 54 57 59]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 18, 21, 23, 25, 28, 30, 32, 35, 37, 39, 42, 44, 46, 48, 51, 53, 55, 58, 60}\n",
            "61 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 18 21 23 25 28 30 32 35 37 39 42 44 46 48 51 53\n",
            " 55 58 60]\n",
            "\n",
            "{0, 2, 5, 7, 9, 12, 14, 16, 19, 21, 23, 26, 28, 30, 33, 35, 38, 40, 42, 45, 47, 49, 52, 54, 56, 59, 61}\n",
            "62 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7  9 12 14 16 19 21 23 26 28 30 33 35 38 40 42 45 47 49 52 54\n",
            " 56 59 61]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 14, 17, 19, 21, 24, 26, 29, 31, 33, 36, 38, 41, 43, 45, 48, 50, 52, 55, 57, 60, 62}\n",
            "63 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 14 17 19 21 24 26 29 31 33 36 38 41 43 45 48 50 52 55\n",
            " 57 60 62]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 19, 22, 24, 27, 29, 31, 34, 36, 39, 41, 44, 46, 48, 51, 53, 56, 58, 61, 63}\n",
            "64 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 19 22 24 27 29 31 34 36 39 41 44 46 48 51 53 56\n",
            " 58 61 63]\n",
            "\n",
            "{0, 2, 5, 7, 10, 12, 15, 17, 20, 22, 25, 27, 30, 32, 34, 37, 39, 42, 44, 47, 49, 52, 54, 57, 59, 62, 64}\n",
            "65 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  7 10 12 15 17 20 22 25 27 30 32 34 37 39 42 44 47 49 52 54 57\n",
            " 59 62 64]\n",
            "\n",
            "{0, 2, 5, 8, 10, 12, 15, 18, 20, 22, 25, 28, 30, 32, 35, 38, 40, 42, 45, 48, 50, 52, 55, 58, 60, 62, 65}\n",
            "66 batches:, want 27 prints, got 27 prints\n",
            "[ 0  2  5  8 10 12 15 18 20 22 25 28 30 32 35 38 40 42 45 48 50 52 55 58\n",
            " 60 62 65]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 20, 23, 25, 28, 30, 33, 36, 38, 41, 43, 46, 48, 51, 53, 56, 58, 61, 63, 66}\n",
            "67 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 20 23 25 28 30 33 36 38 41 43 46 48 51 53 56 58\n",
            " 61 63 66]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 15, 18, 21, 23, 26, 28, 31, 34, 36, 39, 41, 44, 46, 49, 52, 54, 57, 59, 62, 64, 67}\n",
            "68 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 15 18 21 23 26 28 31 34 36 39 41 44 46 49 52 54 57 59\n",
            " 62 64 67]\n",
            "\n",
            "{0, 3, 5, 8, 10, 13, 16, 18, 21, 24, 26, 29, 31, 34, 37, 39, 42, 44, 47, 50, 52, 55, 58, 60, 63, 65, 68}\n",
            "69 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 10 13 16 18 21 24 26 29 31 34 37 39 42 44 47 50 52 55 58 60\n",
            " 63 65 68]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 21, 24, 27, 29, 32, 34, 37, 40, 42, 45, 48, 50, 53, 56, 58, 61, 64, 66, 69}\n",
            "70 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 21 24 27 29 32 34 37 40 42 45 48 50 53 56 58 61\n",
            " 64 66 69]\n",
            "\n",
            "{0, 3, 5, 8, 11, 13, 16, 19, 22, 24, 27, 30, 32, 35, 38, 40, 43, 46, 48, 51, 54, 57, 59, 62, 65, 67, 70}\n",
            "71 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 13 16 19 22 24 27 30 32 35 38 40 43 46 48 51 54 57 59 62\n",
            " 65 67 70]\n",
            "\n",
            "{0, 3, 5, 8, 11, 14, 16, 19, 22, 25, 27, 30, 33, 36, 38, 41, 44, 46, 49, 52, 55, 57, 60, 63, 66, 68, 71}\n",
            "72 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  5  8 11 14 16 19 22 25 27 30 33 36 38 41 44 46 49 52 55 57 60 63\n",
            " 66 68 71]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 19, 22, 25, 28, 30, 33, 36, 39, 42, 44, 47, 50, 53, 55, 58, 61, 64, 66, 69, 72}\n",
            "73 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 19 22 25 28 30 33 36 39 42 44 47 50 53 55 58 61 64\n",
            " 66 69 72]\n",
            "\n",
            "{0, 3, 6, 8, 11, 14, 17, 20, 22, 25, 28, 31, 34, 36, 39, 42, 45, 48, 51, 53, 56, 59, 62, 65, 67, 70, 73}\n",
            "74 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  8 11 14 17 20 22 25 28 31 34 36 39 42 45 48 51 53 56 59 62 65\n",
            " 67 70 73]\n",
            "\n",
            "{0, 3, 6, 9, 11, 14, 17, 20, 23, 26, 28, 31, 34, 37, 40, 43, 46, 48, 51, 54, 57, 60, 63, 65, 68, 71, 74}\n",
            "75 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 11 14 17 20 23 26 28 31 34 37 40 43 46 48 51 54 57 60 63 65\n",
            " 68 71 74]\n",
            "\n",
            "{0, 3, 6, 9, 12, 14, 17, 20, 23, 26, 29, 32, 35, 38, 40, 43, 46, 49, 52, 55, 58, 61, 63, 66, 69, 72, 75}\n",
            "76 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 14 17 20 23 26 29 32 35 38 40 43 46 49 52 55 58 61 63 66\n",
            " 69 72 75]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56, 58, 61, 64, 67, 70, 73, 76}\n",
            "77 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 20 23 26 29 32 35 38 41 44 47 50 53 56 58 61 64 67\n",
            " 70 73 76]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 38, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 71, 74, 77}\n",
            "78 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 38 41 44 47 50 53 56 59 62 65 68\n",
            " 71 74 77]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78}\n",
            "79 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69\n",
            " 72 75 78]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 70, 73, 76, 79}\n",
            "80 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 21 24 27 30 33 36 40 43 46 49 52 55 58 61 64 67 70\n",
            " 73 76 79]\n",
            "\n",
            "{0, 3, 6, 9, 12, 15, 18, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55, 58, 62, 65, 68, 71, 74, 77, 80}\n",
            "81 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 15 18 22 25 28 31 34 37 40 43 46 49 52 55 58 62 65 68 71\n",
            " 74 77 80]\n",
            "\n",
            "{0, 3, 6, 9, 12, 16, 19, 22, 25, 28, 31, 34, 37, 40, 44, 47, 50, 53, 56, 59, 62, 65, 69, 72, 75, 78, 81}\n",
            "82 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 12 16 19 22 25 28 31 34 37 40 44 47 50 53 56 59 62 65 69 72\n",
            " 75 78 81]\n",
            "\n",
            "{0, 3, 6, 9, 13, 16, 19, 22, 25, 28, 32, 35, 38, 41, 44, 47, 50, 54, 57, 60, 63, 66, 69, 73, 76, 79, 82}\n",
            "83 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6  9 13 16 19 22 25 28 32 35 38 41 44 47 50 54 57 60 63 66 69 73\n",
            " 76 79 82]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 22, 26, 29, 32, 35, 38, 42, 45, 48, 51, 54, 57, 61, 64, 67, 70, 73, 77, 80, 83}\n",
            "84 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 22 26 29 32 35 38 42 45 48 51 54 57 61 64 67 70 73\n",
            " 77 80 83]\n",
            "\n",
            "{0, 3, 6, 10, 13, 16, 19, 23, 26, 29, 32, 36, 39, 42, 45, 48, 52, 55, 58, 61, 65, 68, 71, 74, 78, 81, 84}\n",
            "85 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  6 10 13 16 19 23 26 29 32 36 39 42 45 48 52 55 58 61 65 68 71 74\n",
            " 78 81 84]\n",
            "\n",
            "{0, 3, 7, 10, 13, 16, 20, 23, 26, 29, 33, 36, 39, 42, 46, 49, 52, 56, 59, 62, 65, 69, 72, 75, 78, 82, 85}\n",
            "86 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 16 20 23 26 29 33 36 39 42 46 49 52 56 59 62 65 69 72 75\n",
            " 78 82 85]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 26, 30, 33, 36, 40, 43, 46, 50, 53, 56, 60, 63, 66, 69, 73, 76, 79, 83, 86}\n",
            "87 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 26 30 33 36 40 43 46 50 53 56 60 63 66 69 73 76\n",
            " 79 83 86]\n",
            "\n",
            "{0, 3, 7, 10, 13, 17, 20, 23, 27, 30, 33, 37, 40, 44, 47, 50, 54, 57, 60, 64, 67, 70, 74, 77, 80, 84, 87}\n",
            "88 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 13 17 20 23 27 30 33 37 40 44 47 50 54 57 60 64 67 70 74 77\n",
            " 80 84 87]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 20, 24, 27, 30, 34, 37, 41, 44, 47, 51, 54, 58, 61, 64, 68, 71, 74, 78, 81, 85, 88}\n",
            "89 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 20 24 27 30 34 37 41 44 47 51 54 58 61 64 68 71 74 78\n",
            " 81 85 88]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 27, 31, 34, 38, 41, 44, 48, 51, 55, 58, 62, 65, 68, 72, 75, 79, 82, 86, 89}\n",
            "90 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 27 31 34 38 41 44 48 51 55 58 62 65 68 72 75 79\n",
            " 82 86 89]\n",
            "\n",
            "{0, 3, 7, 10, 14, 17, 21, 24, 28, 31, 35, 38, 42, 45, 48, 52, 55, 59, 62, 66, 69, 73, 76, 80, 83, 87, 90}\n",
            "91 batches:, want 27 prints, got 27 prints\n",
            "[ 0  3  7 10 14 17 21 24 28 31 35 38 42 45 48 52 55 59 62 66 69 73 76 80\n",
            " 83 87 90]\n",
            "\n",
            "{0, 4, 7, 10, 14, 18, 21, 24, 28, 32, 35, 38, 42, 46, 49, 52, 56, 60, 63, 66, 70, 74, 77, 80, 84, 88, 91}\n",
            "92 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 10 14 18 21 24 28 32 35 38 42 46 49 52 56 60 63 66 70 74 77 80\n",
            " 84 88 91]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 28, 32, 35, 39, 42, 46, 50, 53, 57, 60, 64, 67, 71, 74, 78, 81, 85, 88, 92}\n",
            "93 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 28 32 35 39 42 46 50 53 57 60 64 67 71 74 78 81\n",
            " 85 88 92]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 21, 25, 29, 32, 36, 39, 43, 46, 50, 54, 57, 61, 64, 68, 72, 75, 79, 82, 86, 89, 93}\n",
            "94 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 21 25 29 32 36 39 43 46 50 54 57 61 64 68 72 75 79 82\n",
            " 86 89 93]\n",
            "\n",
            "{0, 4, 7, 11, 14, 18, 22, 25, 29, 33, 36, 40, 43, 47, 51, 54, 58, 61, 65, 69, 72, 76, 80, 83, 87, 90, 94}\n",
            "95 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 14 18 22 25 29 33 36 40 43 47 51 54 58 61 65 69 72 76 80 83\n",
            " 87 90 94]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 29, 33, 37, 40, 44, 48, 51, 55, 58, 62, 66, 69, 73, 77, 80, 84, 88, 91, 95}\n",
            "96 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 29 33 37 40 44 48 51 55 58 62 66 69 73 77 80 84\n",
            " 88 91 95]\n",
            "\n",
            "{0, 4, 7, 11, 15, 18, 22, 26, 30, 33, 37, 41, 44, 48, 52, 55, 59, 63, 66, 70, 74, 78, 81, 85, 89, 92, 96}\n",
            "97 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 18 22 26 30 33 37 41 44 48 52 55 59 63 66 70 74 78 81 85\n",
            " 89 92 96]\n",
            "\n",
            "{0, 4, 7, 11, 15, 19, 22, 26, 30, 34, 37, 41, 45, 48, 52, 56, 60, 63, 67, 71, 75, 78, 82, 86, 90, 93, 97}\n",
            "98 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  7 11 15 19 22 26 30 34 37 41 45 48 52 56 60 63 67 71 75 78 82 86\n",
            " 90 93 97]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 26, 30, 34, 38, 41, 45, 49, 53, 57, 60, 64, 68, 72, 75, 79, 83, 87, 90, 94, 98}\n",
            "99 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 26 30 34 38 41 45 49 53 57 60 64 68 72 75 79 83 87\n",
            " 90 94 98]\n",
            "\n",
            "{0, 4, 8, 11, 15, 19, 23, 27, 30, 34, 38, 42, 46, 50, 53, 57, 61, 65, 69, 72, 76, 80, 84, 88, 91, 95, 99}\n",
            "100 batches:, want 27 prints, got 27 prints\n",
            "[ 0  4  8 11 15 19 23 27 30 34 38 42 46 50 53 57 61 65 69 72 76 80 84 88\n",
            " 91 95 99]\n",
            "\n",
            "Elapsed time: 0.128855 seconds\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from utils import int_linspace\n",
        "from tictoc import tic, toc\n",
        "\n",
        "n_prints = 27\n",
        "\n",
        "tic()\n",
        "for k in range(1):\n",
        "    for n_iter in range(1, 100+1):\n",
        "        # every_n = math.ceil(n_iter / n_prints)\n",
        "        # nums = [x for x in range(n_iter) if x % every_n == 0]\n",
        "        \n",
        "        nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "        print(set(nums))\n",
        "\n",
        "        actual_n_prints = len(nums)\n",
        "        \n",
        "        print(f'{n_iter} batches:, want {n_prints} prints, got {actual_n_prints} prints')\n",
        "        print(nums)\n",
        "        print()\n",
        "toc()\n",
        "\n",
        "# tic()\n",
        "# for k in range(10_000):\n",
        "#     n_iter = 6700000\n",
        "#     nums = int_linspace(0, n_iter-1, min(n_prints, n_iter))\n",
        "# toc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 100/100 [00:00<00:00, 191.19it/s]\n"
          ]
        }
      ],
      "source": [
        "function_samples_dataset_2 = ListMapFunctionSamplesDataset.from_iterable_dataset(rand_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SingleTaskGP(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (outputscale_prior): GammaPrior()\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:00<00:00, 151.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([20, 6]) torch.Size([20])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "torch.Size([40, 6]) torch.Size([40])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([28, 6]) torch.Size([28]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([26, 6]) torch.Size([26]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([8, 6]) torch.Size([8]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([7, 6]) torch.Size([7]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([1, 6]) torch.Size([1]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([19, 6]) torch.Size([19]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import GaussianProcessRandomDataset, ListMapFunctionSamplesDataset\n",
        "from acquisition_dataset import FunctionSamplesAcquisitionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "Saving realizations from GaussianProcessRandomDataset into ListMapFunctionSamplesDataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 20/20 [00:00<00:00, 150.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dataset_with_models.MapFunctionSamplesSubset'>\n",
            "<class 'dataset_with_models.MapFunctionSamplesSubset'> 12\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.0183, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5937, -0.7234, -0.7051, -0.3100,  0.2769, -0.5216]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(24.7716, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3166,  0.5050, -0.4871, -0.4972,  0.1745,  0.8940]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([19, 6]) torch.Size([19])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.7187, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.3906, -0.7809, -1.0721, -0.8058, -0.3789, -1.7219]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([16, 6])"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " torch.Size([16])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.5066, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.6178, -1.3973, -0.9966,  0.0687, -0.8019, -0.7827]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(19.7305, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3467, -3.4180, -0.4457,  0.0798,  0.7735, -2.3735]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(30.5852, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.3173, -0.1330, -0.6055, -1.2983,  0.1788, -1.1704]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.1442, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.4117,  0.7357,  0.2728, -0.0876,  0.0997, -1.9339]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([29, 6]) torch.Size([29])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.1815, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.4540, -1.2818, -0.0256, -0.7721, -0.2421, -0.2774]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([17, 6]) torch.Size([17])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.8933, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.5878,  0.3725, -1.0817, -0.9872, -0.2428, -0.3045]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(5.7568, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.0724, -0.6240,  0.2163,  1.1081, -1.6193, -0.1446]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([27, 6]) torch.Size([27])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.9243, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4186, -1.4162, -0.9122, -0.3766, -0.8241, -1.9416]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([31, 6]) torch.Size([31])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.])), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.8280, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.9496, -1.6693, -1.7773,  0.0875, -1.2961, -0.7184]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "17 14 12 12\n",
            "\n",
            "\n",
            "torch.Size([3, 17, 6]) torch.Size([3, 17]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 17]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 19, 6]) torch.Size([3, 19]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 19]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 30, 6]) torch.Size([3, 30]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 30]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n",
            "torch.Size([3, 18, 6]) torch.Size([3, 18]) torch.Size([3, 12, 6]) torch.Size([3, 12]) torch.Size([3, 18]) None\n",
            "[<class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>, <class 'botorch.models.gp_regression.SingleTaskGP'>]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from function_samples_dataset import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = ListMapFunctionSamplesDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "dataset = dataset[:-3]\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1), len(train_subset_1))\n",
        "# train_subset_1 = train_subset_1[:4]\n",
        "# print(type(train_subset_1), len(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = ListMapFunctionSamplesDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(dataset), len(train_dataset), len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = FunctionSamplesAcquisitionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = FunctionSamplesAcquisitionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function_samples_dataset.GaussianProcessRandomDataset at 0x7fba1761b850>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient w.r.t x (Approach a): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradient w.r.t x (Approach b): tensor([[ -2.6150],\n",
            "        [  1.7125],\n",
            "        [ -4.0522],\n",
            "        [  6.5352],\n",
            "        [  3.1333],\n",
            "        [  5.3518],\n",
            "        [  1.9289],\n",
            "        [  2.5856],\n",
            "        [  8.3773],\n",
            "        [ -1.6640],\n",
            "        [  7.7785],\n",
            "        [ -0.3526],\n",
            "        [  2.6515],\n",
            "        [ 12.2907],\n",
            "        [ -0.9190],\n",
            "        [-10.1967],\n",
            "        [ -2.0980],\n",
            "        [ -7.7207],\n",
            "        [ -3.3018],\n",
            "        [ -2.8200]])\n",
            "Gradients w.r.t x are equal: True\n",
            "Gradient w.r.t y (Approach a): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradient w.r.t y (Approach b): tensor([[ 0.0339,  0.0339,  0.0339,  ...,  0.0339,  0.0339,  0.0339],\n",
            "        [-0.2237, -0.2237, -0.2237,  ..., -0.2237, -0.2237, -0.2237],\n",
            "        [ 0.0906,  0.0906,  0.0906,  ...,  0.0906,  0.0906,  0.0906],\n",
            "        ...,\n",
            "        [-0.2514, -0.2514, -0.2514,  ..., -0.2514, -0.2514, -0.2514],\n",
            "        [-0.0682, -0.0682, -0.0682,  ..., -0.0682, -0.0682, -0.0682],\n",
            "        [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]])\n",
            "Gradients w.r.t y are equal: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=True)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=True)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data:\n",
            " tensor([[[ 0.,  1.,  2.,  3.],\n",
            "         [ 4.,  5.,  6.,  7.],\n",
            "         [ 8.,  9., 10., 11.]],\n",
            "\n",
            "        [[12., 13., 14., 15.],\n",
            "         [16., 17., 18., 19.],\n",
            "         [20., 21., 22., 23.]]], dtype=torch.float32)\n",
            "mask: torch.bool\n",
            " tensor([[[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]],\n",
            "\n",
            "        [[ True, False,  True, False],\n",
            "         [ True, False,  True, False],\n",
            "         [ True, False,  True, False]]])\n",
            "data masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "data2 masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n",
            "stacked_masked:\n",
            " MaskedTensor(\n",
            "  [\n",
            "    [\n",
            "      [  0.0000,       --,   2.0000,       --],\n",
            "      [  4.0000,       --,   6.0000,       --],\n",
            "      [  8.0000,       --,  10.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ 12.0000,       --,  14.0000,       --],\n",
            "      [ 16.0000,       --,  18.0000,       --],\n",
            "      [ 20.0000,       --,  22.0000,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.9267,       --,   1.0549,       --],\n",
            "      [ -0.8802,       --,  -0.8436,       --],\n",
            "      [  0.0279,       --,   2.4026,       --]\n",
            "    ],\n",
            "    [\n",
            "      [ -0.3278,       --,  -0.3652,       --],\n",
            "      [  0.6388,       --,   0.2709,       --],\n",
            "      [  0.0059,       --,  -0.2849,       --]\n",
            "    ]\n",
            "  ]\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
            "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 43.,   0.,   0.,   0.,   0.,   0.,  35.,   0.,   0.,   0.,  31.,\n",
              "          0.,   0.,  36.,   0.,  30.,   0.,  36.,   0.,  38.,  36.,  44.,\n",
              "         37.,  28.,  23.,  59.,  39.,  69.,  71.,  67.,  77., 106.,  66.,\n",
              "        106., 144., 149., 130., 136., 198., 145., 243., 230., 236., 285.,\n",
              "        289., 381., 376., 404., 513., 531., 587., 625., 717., 777., 863.,\n",
              "        964.]),\n",
              " array([0.        , 0.10185326, 0.20370652, 0.30555978, 0.40741303,\n",
              "        0.50926629, 0.61111955, 0.71297281, 0.81482607, 0.91667933,\n",
              "        1.01853258, 1.12038584, 1.2222391 , 1.32409236, 1.42594562,\n",
              "        1.52779888, 1.62965214, 1.73150539, 1.83335865, 1.93521191,\n",
              "        2.03706517, 2.13891843, 2.24077169, 2.34262494, 2.4444782 ,\n",
              "        2.54633146, 2.64818472, 2.75003798, 2.85189124, 2.9537445 ,\n",
              "        3.05559775, 3.15745101, 3.25930427, 3.36115753, 3.46301079,\n",
              "        3.56486405, 3.66671731, 3.76857056, 3.87042382, 3.97227708,\n",
              "        4.07413034, 4.1759836 , 4.27783686, 4.37969011, 4.48154337,\n",
              "        4.58339663, 4.68524989, 4.78710315, 4.88895641, 4.99080967,\n",
              "        5.09266292, 5.19451618, 5.29636944, 5.3982227 , 5.50007596,\n",
              "        5.60192922, 5.70378247]),\n",
              " <BarContainer object of 56 artists>)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([479,  61, 736, 798,  30, 101,   1, 207, 625,  55, 805,   2, 456, 702,\n",
            "        554, 463, 154,  42,  80,  63, 324, 101,  34,  31, 401,  58, 893, 635,\n",
            "        533,  19, 598, 977, 753,  74, 293,  14, 125, 583,  10, 754,  15, 326,\n",
            "          5, 111, 422,  43,  80, 139, 185, 349, 108,  42,  37, 765, 146, 121,\n",
            "          2,  57,  34,  19,  22,  36,  63, 365,  21,  13, 911,  31, 913,  36,\n",
            "         17,  14, 299,   5,   7,  52,   6,  93,  50,  28,  31,   6, 168,  39,\n",
            "         10, 405,   6, 133,  79,  24,   6,  98,  12, 202, 736,   8, 238, 179,\n",
            "         19, 130, 193,  66, 371, 167, 484, 162, 935,  11,  20, 145,  17,  99,\n",
            "          3, 177,  10, 776,  94, 524, 266, 316,  51,  45,  33,  20, 133,   2,\n",
            "        845, 219,   9,  61, 353,  28,   9,  70, 187, 409, 740, 638,  28,  18,\n",
            "        191,  35, 148, 618, 394,  70, 381,   5, 411, 394,   1,  31, 318, 237,\n",
            "         39, 284, 312,  47, 158, 105,  44,  99, 133, 908,  39, 273, 134,  18,\n",
            "          5, 716, 279, 115,  44,  46, 106,  53,  26, 646,  18, 986, 994,  61,\n",
            "        218, 963,  17, 156,  47, 605,   4,  50,  58, 244, 729,  38, 993,  74,\n",
            "         21,  22,   6, 166, 798,   2, 312, 561,  53,  80, 235, 163, 159,  39,\n",
            "        155, 180, 252,   9, 818, 388,  18,  14,  64,   9,  42,  24, 416,   4,\n",
            "        734,  60,  15, 295, 232, 578, 235, 330, 272, 209, 275,  51,   2, 573,\n",
            "         14,  42, 109,   5,  79,  23, 119, 988,  90, 426, 182,  65, 132, 235,\n",
            "         68,  26,  63, 330,  25, 296, 372, 127,  49,  12,  40, 124, 169, 224,\n",
            "        238,  16,  19, 648, 107, 516, 614,  94, 737,  35,  35, 161,  11,  68,\n",
            "        742,  16, 348,  21, 346, 699,  21,   2,   3,  35,  10, 179,  13,  30,\n",
            "        114,  60,  24, 242, 258, 119,  48, 181,  15, 104,  23, 527,   7, 443,\n",
            "         21,   6,  49,  19, 927,   9, 604, 317, 519, 128, 178, 177, 555,  61,\n",
            "        177, 561, 160,  69,  34, 396, 849,  25, 311,  35,  13, 418, 895,  46,\n",
            "         82, 688, 436, 840,  50, 280, 810,  96,   1, 647,  76,  61,  69,  34,\n",
            "        722,   5,   1, 606,  39,  66, 354, 228, 108,   1,   5,  81,  28,  15,\n",
            "        375,  13, 343, 154, 475, 975, 475,   1,  17, 271,  51, 482, 491, 782,\n",
            "        390, 448,  58, 465, 100,  59,  42, 186,  19, 192,  37, 251,  51, 493,\n",
            "         15,   2,   8, 629, 105, 257,  50, 266, 100, 283,  35, 217, 192,  14,\n",
            "         16, 213, 107, 253,  96, 212, 703,  11, 355,  40,  80,  28, 415,   3,\n",
            "         94, 165,  47,   7, 138,  32, 137,  14, 893,  16,  42, 459, 663, 147,\n",
            "         43,  10, 308, 563, 382,  65,  10,  66,   8,   5, 131,   3, 100,  82,\n",
            "        253, 943, 370,  15,  41,  10,  13,  81,  23, 658,   7, 303, 803, 108,\n",
            "        899, 904, 791, 649, 327, 208, 312,   6, 153,  66, 306, 393,  17,   6,\n",
            "         22, 105,  37, 598, 101,  10, 981,  56, 114,  12,  21,   1,  48, 133,\n",
            "        311, 695, 195, 709, 793,  19,  65, 414, 648, 382,  61,  94, 325, 591,\n",
            "         53,  22, 390, 103, 267, 150, 162, 877,  74,  30, 813,  52,  29, 268,\n",
            "        162,   4,  25, 699, 241, 133,  26,  54,  82,  76,  35,   4,  44,  16,\n",
            "        713, 203, 405, 962, 149, 776, 364, 213,  54,  20,  88,  59, 115, 341,\n",
            "        315,  98, 349,  48,  23, 199,   7, 682, 948, 490, 179,  77,  66,  97,\n",
            "        183, 234,  49,  40,  34, 137, 159, 504, 289, 664, 622,  32,  82,  13,\n",
            "        243,   4, 100, 222,   4,  97,  30,  86,  75, 271, 108,   1, 630, 850,\n",
            "        820, 681, 255,   7,  63, 104,   2, 175, 499,  16,  95, 125,   8,  83,\n",
            "         28,  47,  38, 115, 461,  90, 237,  34,   1,  58,  62,  11, 919,  66,\n",
            "        705,  29,  10,  28, 459,  45,  46, 620,   2,   1, 102,   8,   9, 378,\n",
            "        587, 453, 280, 667, 286, 235,  48,   5,  11, 151, 188, 472, 479, 879,\n",
            "        163, 213, 689,  30, 446, 901,  55, 346,  37,  57,  19,  79,   2, 157,\n",
            "          2,  70,  27, 227,  12, 533, 220,  28, 335,  66,  37,  34,  79,  62,\n",
            "         27, 249,   4, 134, 177, 383,  12,  53,  74,  86,  53,  77,  59, 941,\n",
            "         11,  19,  47, 144,  56, 219, 763, 155, 122,  18, 518,  37, 287,  89,\n",
            "          2, 579, 428,  28,  59, 150, 648,  46, 574, 477, 127,  13, 975,   3,\n",
            "          4, 617, 148, 206, 109, 989, 334, 787,  47, 297,   2, 936, 512, 110,\n",
            "        527, 197,  77, 185, 188,  33,  57, 400,  14, 492, 839, 569,   3,  16,\n",
            "         18, 696, 101,  15, 237,  40,  57,  67, 250, 111, 107, 112, 849,  58,\n",
            "         29, 368, 526, 385, 269, 795,  51,  90, 128, 338, 508,  31, 504,  76,\n",
            "          5, 969,  29, 271,  29,  17,   6,  35,  20,  13, 384,  40, 519,  72,\n",
            "        514, 564, 156, 342,   2, 120, 355, 369,  45, 246, 435, 178, 237, 312,\n",
            "          2, 354,  69,  77, 137, 933,  85,   8, 242,   8, 272, 114, 255, 355,\n",
            "        294,  35, 159,   3, 110,  35, 321,  58,   2, 290,  76, 192, 190, 137,\n",
            "        115, 167,  51, 584, 926,  10, 843, 111, 929, 197,  53, 268,  22, 108,\n",
            "        940, 189, 208,  33,  25,  18, 200, 334, 811, 638, 931,  34,  19, 931,\n",
            "        216,   4, 837,   8, 135, 998,  56,  27, 743,  85,   4, 213,   9, 526,\n",
            "         21, 563, 291,   4,  29, 691, 668,   1, 915, 129,  45,  11, 131,  34,\n",
            "        170,  15, 112,  58,  66,   1,  10,  24, 260,  12, 295, 299,  19, 101,\n",
            "         17,  61, 615,  33,  13, 459,  99,  17,  76,  39,   2, 335,  14, 227,\n",
            "        885, 160, 106,  23, 412,  23, 124,  62,  20,  22, 454, 662,  11,   4,\n",
            "        338, 160, 243, 385,  98,   3, 120, 135,  16, 535, 843, 538, 244, 108,\n",
            "         30, 962, 776, 108,  44, 763,  57, 161,   8,  72,  21,  93,   1, 232,\n",
            "        295, 209, 118, 516, 994,  19,  29, 569,  51,  87,  89,  44,  24, 350,\n",
            "         56, 104, 234,  38,   2,  83,  86,   9, 470,  23, 129, 150,  16, 290,\n",
            "        306,   4, 510, 371, 106,  42,  15, 152, 556,  22, 143,  13,  19, 131,\n",
            "        255, 604, 186, 223,   9, 571], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
