{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkr_DkG3Ztxz",
        "outputId": "fe157ef3-ee14-4858-9ca5-781483306390"
      },
      "outputs": [],
      "source": [
        "# for Colab\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mregrjzrYp5_",
        "outputId": "92ebd97a-ec69-45f7-e363-fdda1f75420a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import botorch\n",
        "import gpytorch\n",
        "\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double # double == float64\n",
        "\n",
        "# isn't this easier?\n",
        "# https://github.com/pytorch/botorch/discussions/1444\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "# torch.set_default_device(device) # similarly\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "from predict_EI_simple import calculate_EI_GP\n",
        "from utils import get_uniform_randint_generator, loguniform_randint, get_loguniform_randint_generator, pad_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 1., 0.]])\n",
            "tensor([[0.0000, 0.0000, 0.5000, 0.5000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with multiple maximum values\n",
        "x = torch.tensor([[1.0, 2.0, 3.0, 3.0]], requires_grad=True)\n",
        "\n",
        "# Using max\n",
        "max_value = torch.max(x, dim=-1).values\n",
        "max_value.backward(torch.ones_like(max_value))\n",
        "print(x.grad)  # Gradient is propagated to a single maximum value\n",
        "\n",
        "# Reset the gradient\n",
        "x.grad.zero_()\n",
        "\n",
        "# Using amax\n",
        "amax_value = torch.amax(x, dim=-1)\n",
        "amax_value.backward(torch.ones_like(amax_value))\n",
        "print(x.grad)  # Gradient is evenly distributed among the maximum values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=30, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create a sequential model\n",
        "# model = nn.Sequential(*[nn.Linear(i, i+1) for i in range(5)])\n",
        "model = nn.Sequential()\n",
        "\n",
        "# Append another linear layer to the model using the + operator\n",
        "model.append(nn.Linear(20, 30))\n",
        "\n",
        "# Print the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gp_posterior(ax, posterior, test_x, train_x, train_y, color, name=None):\n",
        "    lower, upper = posterior.mvn.confidence_region()\n",
        "    mean = posterior.mean.squeeze().cpu().numpy()\n",
        "    lower = lower.squeeze().cpu().numpy()\n",
        "    upper = upper.squeeze().cpu().numpy()\n",
        "\n",
        "    train_x = train_x.squeeze().cpu().numpy()\n",
        "    train_y = train_y.squeeze().cpu().numpy()\n",
        "    test_x = test_x.squeeze().cpu().numpy()\n",
        "\n",
        "    extension = '' if name is None else f' {name}'\n",
        "\n",
        "    # Plot training points as black stars\n",
        "    ax.plot(train_x, train_y, f'{color}*', label=f'Observed Data{extension}')\n",
        "    # Plot posterior means as blue line\n",
        "    ax.plot(test_x, mean, color, label=f'Mean{extension}')\n",
        "    # Shade between the lower and upper confidence bounds\n",
        "    ax.fill_between(test_x, lower, upper, color=color, alpha=0.5, label=f'Confidence{extension}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n",
            "\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([1.0000e-06])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.)), ('covar_module.raw_outputscale', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale', tensor([[0.]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "index: 0\n",
            "index: 1\n",
            "index: 2\n",
            "index: 3\n",
            "SingleTaskGP(\n",
            "  (likelihood): GaussianLikelihood(\n",
            "    (noise_covar): HomoskedasticNoise(\n",
            "      (raw_noise_constraint): GreaterThan(0.000E+00)\n",
            "    )\n",
            "  )\n",
            "  (mean_module): ConstantMean()\n",
            "  (covar_module): ScaleKernel(\n",
            "    (base_kernel): MaternKernel(\n",
            "      (lengthscale_prior): GammaPrior()\n",
            "      (raw_lengthscale_constraint): Positive()\n",
            "    )\n",
            "    (outputscale_prior): GammaPrior()\n",
            "    (raw_outputscale_constraint): Positive()\n",
            "  )\n",
            ")\n",
            "likelihood.noise_covar.raw_noise Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)\n",
            "\n",
            "mean_module.raw_constant Parameter containing:\n",
            "tensor(0., requires_grad=True)\n",
            "\n",
            "covar_module.raw_outputscale Parameter containing:\n",
            "tensor(9.2216, requires_grad=True)\n",
            "\n",
            "covar_module.base_kernel.raw_lengthscale Parameter containing:\n",
            "tensor([[0.4666]], requires_grad=True)\n",
            "\n",
            "True:   l=0.953, sigma^2=9.22, noise=0\n",
            "Fitted: l=0.798, sigma^2=9.24, noise=0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# randint_gen = get_uniform_randint_generator(4, 20)\n",
        "# dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=1, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "#     device=device)\n",
        "\n",
        "# torch.manual_seed(1703)\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=1, n_datapoints=7, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=True, device=device)\n",
        "\n",
        "for name, param in dataset.model_sampler.get_model(0).named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "print(dataset.model_sampler.get_model(0).state_dict())\n",
        "\n",
        "x_values, y_values, model = next(dataset)\n",
        "print(model)\n",
        "\n",
        "true_lengthscale = model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "true_outputscale = model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "true_noise = model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "test_x = torch.linspace(0, 1, 100, device=device)\n",
        "\n",
        "# Get posterior under true model parameters\n",
        "posterior_true = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "\n",
        "\n",
        "for name, param in model.named_parameters(): \n",
        "    print(name, param)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Get posterior by fitting by MAP\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "posterior_fitted = model.posterior(test_x, observation_noise=OBSERVATION_NOISE)\n",
        "fitted_model = model\n",
        "\n",
        "fitted_lengthscale = fitted_model.covar_module.base_kernel.lengthscale.squeeze().detach().numpy()\n",
        "fitted_outputscale = fitted_model.covar_module.outputscale.squeeze().detach().numpy()\n",
        "fitted_noise = fitted_model.likelihood.noise_covar.raw_noise.squeeze().detach().numpy()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "\n",
        "    description_true   = f'True:   l={  true_lengthscale:.3g}, sigma^2={  true_outputscale:.3g}, noise={true_noise:.3g}'\n",
        "    description_fitted = f'Fitted: l={fitted_lengthscale:.3g}, sigma^2={fitted_outputscale:.3g}, noise={fitted_noise:.3g}'\n",
        "    print(description_true)\n",
        "    print(description_fitted)\n",
        "    \n",
        "    plot_gp_posterior(ax, posterior_true, test_x, x_values, y_values, 'b', name='True')\n",
        "    plot_gp_posterior(ax, posterior_fitted, test_x, x_values, y_values, 'r', name='Fitted')\n",
        "\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "index: -1\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0234)), ('covar_module.raw_outputscale', tensor(9.3840)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.2305]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "index: -1\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0234)), ('covar_module.raw_outputscale', tensor(9.3840)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-1.2305]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "index: -1\n",
            "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([0.])), ('likelihood.noise_covar.raw_noise_constraint.lower_bound', tensor(0.)), ('likelihood.noise_covar.raw_noise_constraint.upper_bound', tensor(inf)), ('mean_module.raw_constant', tensor(0.0234)), ('covar_module.raw_outputscale', tensor(4.0672)), ('covar_module.base_kernel.raw_lengthscale', tensor([[-0.5661]])), ('covar_module.base_kernel.lengthscale_prior.concentration', tensor(3.)), ('covar_module.base_kernel.lengthscale_prior.rate', tensor(6.)), ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound', tensor(0.)), ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound', tensor(inf)), ('covar_module.outputscale_prior.concentration', tensor(2.)), ('covar_module.outputscale_prior.rate', tensor(0.1500)), ('covar_module.raw_outputscale_constraint.lower_bound', tensor(0.)), ('covar_module.raw_outputscale_constraint.upper_bound', tensor(inf))])\n",
            "index: -1\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([0.], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0.0234, requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(9.3840, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2305]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "item1 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "item2 = next(dataset)\n",
        "print(item1[-1].state_dict())\n",
        "print(item2[-1].state_dict())\n",
        "\n",
        "print(list(item1[-1].named_parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9270c8c9a0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import cProfile, pstats, io\n",
        "# from pstats import SortKey\n",
        "# pr = cProfile.Profile()\n",
        "# pr.enable()\n",
        "\n",
        "\n",
        "OBSERVATION_NOISE = False\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=5, n_datapoints=20, observation_noise=OBSERVATION_NOISE,\n",
        "    set_random_model_train_data=False, device=device)\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "ei_values = torch.empty(n_samples, device=device)\n",
        "improvement_values = torch.empty(n_samples, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_samples):\n",
        "        x_values, y_values, random_model = next(dataset)\n",
        "\n",
        "        # x_values is shape (n_datapoints, dimension)\n",
        "        # y_values is shape (n_datapoints,)\n",
        "        x_hist = x_values[:-1, :]\n",
        "        y_hist = y_values[:-1]\n",
        "        x = x_values[-1:, :]\n",
        "        y = y_values[-1:]\n",
        "        \n",
        "        ei_value, improvement_value = calculate_EI_GP(random_model, x_hist, y_hist, x, y, fit_params=False)\n",
        "        ei_values[i] = ei_value[0]\n",
        "        improvement_values[i] = improvement_value[0]\n",
        "\n",
        "    # print(ei_values)\n",
        "    # print(improvement_values)\n",
        "\n",
        "\n",
        "# pr.disable()\n",
        "# s = io.StringIO()\n",
        "# sortby = SortKey.CUMULATIVE\n",
        "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
        "# ps.print_stats()\n",
        "# print(s.getvalue())\n",
        "\n",
        "plt.scatter(ei_values.cpu().numpy(), improvement_values.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, start, end):\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start, \"this example code only works with end >= start\"\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.end))\n",
        "\n",
        "for x in MyIterableDataset(3, 7):\n",
        "    print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4321, 0.9570, 0.2413],\n",
            "        [0.7917, 0.6027, 0.1502],\n",
            "        [0.7692, 0.3887, 0.8973],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.2266, 0.2300, 0.7466]])\n",
            "tensor([2, 6, 5, 4, 3, 0, 7, 1])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886],\n",
            "        [0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n",
            "tensor([[0.7692, 0.3887, 0.8973],\n",
            "        [0.0205, 0.9009, 0.2009],\n",
            "        [0.1277, 0.4359, 0.3886]])\n",
            "tensor([[0.6843, 0.2177, 0.8816],\n",
            "        [0.2957, 0.0481, 0.0261],\n",
            "        [0.4321, 0.9570, 0.2413],\n",
            "        [0.2266, 0.2300, 0.7466],\n",
            "        [0.7917, 0.6027, 0.1502]])\n"
          ]
        }
      ],
      "source": [
        "u = torch.rand(8, 3)\n",
        "print(u)\n",
        "rand_indices = torch.randperm(u.shape[0])\n",
        "print(rand_indices)\n",
        "print(u[rand_indices])\n",
        "print(u[rand_indices[:3]])\n",
        "print(u[rand_indices[3:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9.5747, -9.7501, -9.6260, -9.5177, -9.1595, -9.5724, -9.6298, -9.1459,\n",
              "        -9.6044, -9.6240, -9.6702, -9.5881, -9.5899, -9.7063, -9.1460, -9.7534,\n",
              "        -9.3527, -9.5060, -9.5050, -9.8674])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.rand(20)\n",
        "q - 10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list[dict]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "isinstance(dataset, torch.utils.data.IterableDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': Parameter containing:\n",
              " tensor([0.], requires_grad=True),\n",
              " 'mean_module.raw_constant': Parameter containing:\n",
              " tensor(0.0074, requires_grad=True),\n",
              " 'covar_module.raw_outputscale': Parameter containing:\n",
              " tensor(14.9644, requires_grad=True),\n",
              " 'covar_module.base_kernel.raw_lengthscale': Parameter containing:\n",
              " tensor([[0.8065]], requires_grad=True)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likelihood.noise_covar.raw_noise': tensor([0.]),\n",
              " 'mean_module.raw_constant': tensor(0.0074),\n",
              " 'covar_module.raw_outputscale': tensor(14.9644),\n",
              " 'covar_module.base_kernel.raw_lengthscale': tensor([[0.8065]])}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{x:y.detach() for x, y in model.named_parameters()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 1000)\n",
        "fixed_dataset.save(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8489, 0.1965, 0.0284, 0.0234, 0.1666],\n",
              "        [0.8518, 0.9975, 0.9318, 0.0532, 0.1928],\n",
              "        [0.9660, 0.5656, 0.1563, 0.1609, 0.0425],\n",
              "        [0.4375, 0.4648, 0.2420, 0.1713, 0.9196],\n",
              "        [0.0546, 0.8694, 0.4443, 0.5036, 0.8704],\n",
              "        [0.9682, 0.4215, 0.7049, 0.4719, 0.8775],\n",
              "        [0.6631, 0.9408, 0.6663, 0.5284, 0.6014],\n",
              "        [0.8294, 0.9148, 0.5544, 0.8021, 0.8817],\n",
              "        [0.7465, 0.8460, 0.5765, 0.1917, 0.8225],\n",
              "        [0.2578, 0.8584, 0.0147, 0.4841, 0.8581],\n",
              "        [0.8904, 0.7481, 0.0781, 0.5039, 0.5400],\n",
              "        [0.1587, 0.6665, 0.6906, 0.8259, 0.9701],\n",
              "        [0.1105, 0.4084, 0.0324, 0.1800, 0.1766],\n",
              "        [0.9080, 0.4782, 0.8625, 0.7269, 0.8146],\n",
              "        [0.5159, 0.9522, 0.1116, 0.6569, 0.7407],\n",
              "        [0.7568, 0.2690, 0.5293, 0.2926, 0.5500],\n",
              "        [0.6386, 0.7783, 0.5267, 0.3157, 0.0216],\n",
              "        [0.3528, 0.7596, 0.1990, 0.9174, 0.3976],\n",
              "        [0.2512, 0.9899, 0.4709, 0.1600, 0.5643],\n",
              "        [0.7841, 0.6821, 0.1907, 0.4530, 0.0499]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fixed_dataset_loaded = FunctionSamplesMapDataset.load(\"data\")\n",
        "fixed_dataset_loaded[0][2].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([0], [0])\n",
            "([1], [1])\n",
            "([2], [2])\n",
            "([3], [3])\n",
            "([4], [4])\n",
            "([5], [5])\n",
            "([6], [6])\n",
            "([7], [7])\n",
            "([8], [8])\n",
            "([9], [9])\n",
            "([10], [10])\n",
            "([11], [11])\n",
            "([12], [12])\n",
            "([13], [13])\n",
            "([14], [14])\n",
            "([15], [15])\n",
            "([16], [16])\n",
            "([17], [17])\n",
            "([18], [18])\n",
            "([19], [19])\n",
            "([12, 13], [33])\n"
          ]
        }
      ],
      "source": [
        "test_dataset = FunctionSamplesMapDataset([\n",
        "    {'x_values': [i], \n",
        "     'y_values': [i]}\n",
        "     for i in range(20)\n",
        "] + [{'x_values': [12, 13], 'y_values': [33]}])\n",
        "\n",
        "# test_dataset = GaussianProcessRandomDataset(\n",
        "#     dimension=2, n_datapoints=4, observation_noise=OBSERVATION_NOISE,\n",
        "#     set_random_model_train_data=False, device=device)\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=None,\n",
        "                                        #   sampler=torch.utils.data.RandomSampler(test_dataset, replacement=False, num_samples=200)\n",
        "                                          )\n",
        "\n",
        "for x in test_dataset:\n",
        "    print(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hasattr(test_dataset, '_model_sampler')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rand_dataset = GaussianProcessRandomDataset(n_datapoints=15, dimension=5)\n",
        "function_samples_dataset = FunctionSamplesMapDataset.from_iterable_dataset(rand_dataset, 100)\n",
        "function_samples_dataset.save('test')\n",
        "loaded_dataset = FunctionSamplesMapDataset.load('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(function_samples_dataset), len(loaded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (x1,y1,z1), (x2,y2,z2) in zip(loaded_dataset, function_samples_dataset):\n",
        "    assert torch.allclose(x1, x2)\n",
        "    assert torch.allclose(y1, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2 = FunctionSamplesMapDataset.from_iterable_dataset(function_samples_dataset, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dataset[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function_samples_dataset_2[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import numpy as np\n",
        "print(isinstance([1, 2, 3], Sequence))\n",
        "print(isinstance((1,2,3), Sequence))\n",
        "print(isinstance(np.array([1,5,5]), Sequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.array([1,5,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1,5,5])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IndexError\n"
          ]
        }
      ],
      "source": [
        "qq = [1]\n",
        "try:\n",
        "    a = qq[1]\n",
        "except TypeError:\n",
        "    print(\"IndexError\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "int(torch.distributions.Binomial(10, 0.5).sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset:\n",
            "torch.Size([25, 6]) torch.Size([25])\n",
            "torch.Size([30, 6]) torch.Size([30])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "torch.Size([16, 6]) torch.Size([16])\n",
            "torch.Size([42, 6]) torch.Size([42])\n",
            "torch.Size([15, 6]) torch.Size([15])\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "torch.Size([36, 6]) torch.Size([36])\n",
            "\n",
            "aq_dataset:\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "train_aq_dataset:\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([30, 6]) torch.Size([30]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([3, 6]) torch.Size([3]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([4, 6]) torch.Size([4]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([24, 6]) torch.Size([24]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([13, 6]) torch.Size([13]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([18, 6]) torch.Size([18]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([23, 6]) torch.Size([23]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "test_aq_dataset:\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([2, 6]) torch.Size([2]) torch.Size([12, 6]) torch.Size([12])\n",
            "torch.Size([6, 6]) torch.Size([6]) torch.Size([12, 6]) torch.Size([12])\n",
            "\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0.]], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import GaussianProcessRandomDataset, FunctionSamplesMapDataset, TrainAcquisitionFunctionDataset\n",
        "\n",
        "N_CANDIDATES = 12\n",
        "MAX_HISTORY = 30\n",
        "HISTORY_LOGUNIFORM = True\n",
        "\n",
        "if HISTORY_LOGUNIFORM:\n",
        "    randint_gen = get_loguniform_randint_generator(\n",
        "        1, MAX_HISTORY, pre_offset=3.0, offset=N_CANDIDATES)\n",
        "else:\n",
        "    randint_gen = get_uniform_randint_generator(\n",
        "        N_CANDIDATES+1, N_CANDIDATES+MAX_HISTORY)\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset, 10)\n",
        "\n",
        "aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "    dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=3)\n",
        "\n",
        "train_aq_dataset, test_aq_dataset = aq_dataset.random_split([0.8, 0.2])\n",
        "\n",
        "print(\"dataset:\")\n",
        "for x, y, model in dataset:\n",
        "    print(x.shape, y.shape)\n",
        "    # print(list(model.named_parameters()))\n",
        "print()\n",
        "\n",
        "print(\"aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"train_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in train_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(\"test_aq_dataset:\")\n",
        "for x_hist, y_hist, x_cand, improvements, model in test_aq_dataset:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)\n",
        "print()\n",
        "\n",
        "print(list(dataset.model_sampler.initial_models[0].named_parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aloja/opt/anaconda3/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1708025540001/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
            "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True True\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "<class 'generate_gp_data.FunctionSamplesMapSubset'>\n",
            "torch.Size([22, 6]) torch.Size([22])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(15.7515, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.2738,  0.1005, -0.0165, -1.3715, -0.3896, -0.5113]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([39, 6]) torch.Size([39])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(23.0031, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.0501, -1.2738, -0.3901, -1.5378, -0.3554, -0.9313]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.4107, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-2.1873, -1.0822, -0.9720,  0.3895, -1.8195, -0.7942]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(8.4552, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8715, -0.7563, -1.9962,  0.3406, -1.3481, -1.3639]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(16.7275, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.7267, -0.0601, -0.3362, -0.0522, -0.4599,  0.0694]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(20.8934, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.1963,  0.8783, -1.1001, -2.2270, -1.0603, -1.4609]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([18, 6]) torch.Size([18])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(2.9053, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.5863, -0.8679,  0.8952, -0.3738, -1.4301, -1.2107]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([35, 6]) torch.Size([35])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(3.8494, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.1173, -1.5392, -2.3209, -1.9974, -0.4123,  0.4334]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([14, 6]) torch.Size([14])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(13.0844, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.4966, -1.4197, -0.4233, -0.1163, -1.5528, -1.2228]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([13, 6]) torch.Size([13])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(29.5562, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-0.8981, -0.0556,  0.7221, -0.7472, -1.0052,  0.0350]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(26.4354, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.7095,  1.0966, -0.4885, -0.6091, -1.4057, -0.3684]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([26, 6]) torch.Size([26])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(11.1059, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[-1.0928, -0.8568, -1.9886, -0.8789, -0.3097, -1.2336]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "torch.Size([38, 6]) torch.Size([38])\n",
            "[('likelihood.noise_covar.raw_noise', Parameter containing:\n",
            "tensor([1.0000e-06], requires_grad=True)), ('mean_module.raw_constant', Parameter containing:\n",
            "tensor(0., requires_grad=True)), ('covar_module.raw_outputscale', Parameter containing:\n",
            "tensor(35.7868, requires_grad=True)), ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
            "tensor([[ 0.3215, -1.9727, -0.9548, -0.9040, -0.6960, -0.6197]],\n",
            "       requires_grad=True))]\n",
            "\n",
            "13 13\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m aq1\u001b[38;5;241m.\u001b[39mget_dataloader(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#           hist_mask if hist_mask is None else hist_mask.shape,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#           cand_mask if cand_mask is None else cand_mask.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     print([type(model) for model in models])\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     print()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(u)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 6] at entry 0 and [2, 6] at entry 1"
          ]
        }
      ],
      "source": [
        "from generate_gp_data import FunctionSamplesDataset\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=20)\n",
        "print(isinstance(dataset, FunctionSamplesDataset), isinstance(dataset, IterableDataset))\n",
        "dataset = FunctionSamplesMapDataset.from_iterable_dataset(dataset)\n",
        "\n",
        "# v = iter(dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "\n",
        "train_dataset, test_dataset = dataset.random_split([0.8, 0.2])\n",
        "print(type(train_dataset))\n",
        "train_subset_1, train_subset_2 = train_dataset.random_split([0.8, 0.2])\n",
        "print(type(train_subset_1))\n",
        "train_subset_1.save('train')\n",
        "loaded_train = FunctionSamplesMapDataset.load('train')\n",
        "for x, y, model in loaded_train:\n",
        "    print(x.shape, y.shape)\n",
        "    print(list(model.named_parameters()))\n",
        "    print()\n",
        "\n",
        "print(len(loaded_train), len(train_subset_1))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "aq1 = TrainAcquisitionFunctionDataset(\n",
        "    train_subset_1, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2, dataset_size_factor=1)\n",
        "dataloader = aq1.get_dataloader(batch_size=3, drop_last=True)\n",
        "for x_hist, y_hist, x_cand, vals_cand, hist_mask, cand_mask, models in dataloader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, vals_cand.shape,\n",
        "          hist_mask if hist_mask is None else hist_mask.shape,\n",
        "          cand_mask if cand_mask is None else cand_mask.shape)\n",
        "    print([type(model) for model in models])\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "# aq_dataset = TrainAcquisitionFunctionDataset(\n",
        "#     dataset, n_candidate_points=N_CANDIDATES, n_samples=\"all\", give_improvements=True, min_n_candidates=2)\n",
        "# v = iter(aq_dataset)\n",
        "# for _ in range(2):\n",
        "#     print(next(v))\n",
        "# train_aq_dataset, test_aq_dataset = aq_dataset.random_split([20, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.GaussianProcessRandomDataset at 0x7fe36900b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = GaussianProcessRandomDataset(\n",
        "    dimension=6, n_datapoints_random_gen=randint_gen, observation_noise=False,\n",
        "    set_random_model_train_data=False, device=device, dataset_size=None)\n",
        "v = iter(dataset)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 4, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.rand(10, 4)\n",
        "w.unsqueeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 3), (2, 4)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(*[(1,2), (3,4)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterable, Optional\n",
        "\n",
        "\n",
        "class SizedIterableMixin(Iterable):\n",
        "    _size: Optional[int] = None\n",
        "\n",
        "    def copy_with_new_size(self, size:int) -> \"SizedIterableMixin\":\n",
        "        \"\"\"\n",
        "        Creates a copy of the object with a new size.\n",
        "        Should set the _size attribute of the new object to the specified size.\n",
        "\n",
        "        Args:\n",
        "            size (int): The new size for the object.\n",
        "\n",
        "        Returns:\n",
        "            A new instance of the object with the specified size.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement copy_with_new_size.\")\n",
        "\n",
        "    def _next(self):\n",
        "        \"\"\"Returns the next element in the iterable.\"\"\"\n",
        "        raise NotImplementedError(\"Subclasses of SizedIterableMixin should implement _next.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__iter__\")\n",
        "            return self\n",
        "        else:\n",
        "            return self._finite_iterator()\n",
        "    \n",
        "    def _finite_iterator(self):\n",
        "        for _ in range(self._size):\n",
        "            yield self._next()\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self._size is None:\n",
        "            raise TypeError(f\"Length of the {type(self)} is infinite\")\n",
        "        return self._size\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._size is None:\n",
        "            # print(\"SizedIterableMixin.__next__\")\n",
        "            return self._next()\n",
        "        raise TypeError(f\"Cannot call __next__ on a finitely sized {type(self)}. Use iter() first.\")\n",
        "\n",
        "\n",
        "# Example subclass implementation\n",
        "class Example(SizedIterableMixin):\n",
        "    def __init__(self, size: Optional[int]):\n",
        "        self._size = size\n",
        "        self.current = 0\n",
        "\n",
        "    def _next(self):\n",
        "        result = self.current\n",
        "        self.current += 1\n",
        "        return result\n",
        "\n",
        "    def copy_with_new_size(self, size: int) -> \"Example\":\n",
        "        return Example(size)\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "dataset = Example(None)  # Infinite size\n",
        "v = iter(dataset)\n",
        "print(next(v))  # Output: 0\n",
        "print(next(v))  # Output: 1\n",
        "\n",
        "dataset_finite = Example(5)  # Finite size\n",
        "v_finite = iter(dataset_finite)\n",
        "print(list(v_finite))  # Output: [0, 1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/cornell/RESEARCH/BayesOpt/CODE/DeepBayesOpt/generate_gp_data.py:191\u001b[0m, in \u001b[0;36mSizedIterableMixin.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is infinite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size\n",
            "\u001b[0;31mTypeError\u001b[0m: Length of the <class 'generate_gp_data.GaussianProcessRandomDataset'> is infinite"
          ]
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_aq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 6]) torch.Size([2, 3]) torch.Size([2, 1, 6]) torch.Size([2, 1])\n",
            "torch.Size([1, 3, 6]) torch.Size([1, 3]) torch.Size([1, 1, 6]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "test_split_1, test_split_2 = test_aq_dataset.random_split([0.5, 0.5])\n",
        "\n",
        "data_loader = test_split_2.get_dataloader(batch_size=2, drop_last=False)\n",
        "\n",
        "for x_hist, y_hist, x_cand, improvements, model in data_loader:\n",
        "    print(x_hist.shape, y_hist.shape, x_cand.shape, improvements.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "generate_gp_data.FunctionSamplesMapSubset"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_split_2.base_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generate_gp_data.FunctionSamplesMapSubset at 0x7f7ae8d7f520>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_split_2.base_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4083, -1.7979, -0.4755],\n",
            "        [ 1.1438, -1.4784, -0.8719],\n",
            "        [-0.5840,  1.3183, -1.9384],\n",
            "        [-0.0928, -1.0771,  0.1488],\n",
            "        [ 1.0000,  1.0000,  1.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n",
            "tensor([[ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [ True,  True,  True],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [  0.6548],\n",
            "    [  0.6184],\n",
            "    [  0.1261],\n",
            "    [ -1.2328],\n",
            "    [ -0.5295],\n",
            "    [  0.8754]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755],\n",
            "    [  1.1438,  -1.4784,  -0.8719],\n",
            "    [ -0.5840,   1.3183,  -1.9384],\n",
            "    [ -0.0928,  -1.0771,   0.1488],\n",
            "    [      --,       --,       --],\n",
            "    [      --,       --,       --]\n",
            "  ]\n",
            ")\n",
            "MaskedTensor(\n",
            "  [\n",
            "    [ -0.4083,  -1.7979,  -0.4755,   0.6548],\n",
            "    [  1.1438,  -1.4784,  -0.8719,   0.6184],\n",
            "    [ -0.5840,   1.3183,  -1.9384,   0.1261],\n",
            "    [ -0.0928,  -1.0771,   0.1488,  -1.2328],\n",
            "    [      --,       --,       --,  -0.5295],\n",
            "    [      --,       --,       --,   0.8754]\n",
            "  ]\n",
            ")\n",
            "torch.Size([6, 4])\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False,  True]])\n"
          ]
        }
      ],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "def pad_tensor(vec, length, dim, add_mask=True):\n",
        "    \"\"\"\n",
        "    Pads a tensor 'vec' to a size 'length' in dimension 'dim' with zeros.\n",
        "    args:\n",
        "        vec - tensor to pad\n",
        "        length - the size to pad to in dimension 'dim'\n",
        "        dim - dimension to pad\n",
        "        add_mask - whether to return a MaskedTensor that includes the mask\n",
        "\n",
        "    return:\n",
        "        a new tensor padded to 'length' in dimension 'dim'\n",
        "    \"\"\"\n",
        "    pad_size = length - vec.size(dim)\n",
        "    if pad_size < 0:\n",
        "        raise ValueError(\"Tensor cannot be padded to length less than it already is\")\n",
        "    \n",
        "    vec_shape = list(vec.shape)\n",
        "    pad_shape = vec_shape.copy()\n",
        "    pad_shape[dim] = pad_size\n",
        "    if pad_size == 0: # Could pad with nothing but that's unnecessary\n",
        "        padded = vec\n",
        "    else:\n",
        "        padding = torch.ones(*pad_shape, dtype=vec.dtype, device=vec.device)\n",
        "        padded = torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "    if add_mask:\n",
        "        mask_true = torch.ones(vec.shape, dtype=torch.bool, device=vec.device)\n",
        "        mask_false = torch.zeros(*pad_shape, dtype=torch.bool, device=vec.device)\n",
        "        mask = torch.cat([mask_true, mask_false], dim=dim)\n",
        "        padded_masked = masked_tensor(padded, mask)\n",
        "        return padded, padded_masked\n",
        "\n",
        "    return padded\n",
        "\n",
        "data = torch.randn(4, 3)\n",
        "padded, padded_masked = pad_tensor(data, 6, dim=0, add_mask=True)\n",
        "\n",
        "print(padded)\n",
        "print(padded_masked.get_mask())\n",
        "\n",
        "data2 = torch.randn(6)\n",
        "data2 = masked_tensor(data2, torch.ones_like(data2, dtype=torch.bool))\n",
        "data2 = data2.unsqueeze(-1)\n",
        "print(data2)\n",
        "print(padded_masked)\n",
        "data3 = torch.cat((padded_masked, data2), dim=1)\n",
        "print(data3)\n",
        "print(data3.shape)\n",
        "print(data3.get_mask())\n",
        "\n",
        "\n",
        "\n",
        "# linear = torch.nn.Linear(4, 2)\n",
        "# result = linear(data3)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clone'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m output_a \u001b[38;5;241m=\u001b[39m linear_layer_a(input_matrix)  \u001b[38;5;66;03m# (N, p)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m output_a\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m grad_x_a \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m()\n\u001b[1;32m     33\u001b[0m grad_y_a \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clone'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dimensions\n",
        "N = 10  # Number of y_i vectors\n",
        "d = 20  # Dimension of x\n",
        "p = 30  # Dimension of output\n",
        "m = 256  # Dimension of y_i\n",
        "\n",
        "# Example inputs\n",
        "x = torch.randn(d, 1, requires_grad=False)  # (d, 1)\n",
        "y = torch.randn(m, N, requires_grad=False)  # (m, N)\n",
        "\n",
        "# Define the linear layers\n",
        "linear_layer_a = nn.Linear(d + m, p)\n",
        "linear_layer_x = nn.Linear(d, p)\n",
        "linear_layer_y = nn.Linear(m, p, bias=False)\n",
        "\n",
        "# Manually set the weights and biases to ensure they are the same\n",
        "with torch.no_grad():\n",
        "    # Combine weights and biases for the linear layer in Approach (a)\n",
        "    combined_weight = torch.cat((linear_layer_x.weight, linear_layer_y.weight), dim=1)\n",
        "    linear_layer_a.weight.copy_(combined_weight)\n",
        "    linear_layer_a.bias.copy_(linear_layer_x.bias)\n",
        "\n",
        "# Approach (a): Stacking and Applying a Single Linear Layer\n",
        "x_repeated = x.t().repeat(N, 1)  # (N, d)\n",
        "input_matrix = torch.cat((x_repeated, y.t()), dim=1)  # (N, d + m)\n",
        "output_a = linear_layer_a(input_matrix)  # (N, p)\n",
        "output_a.sum().backward()\n",
        "grad_x_a = x.grad.clone()\n",
        "grad_y_a = y.grad.clone()\n",
        "\n",
        "# Reset gradients\n",
        "x.grad.zero_()\n",
        "y.grad.zero_()\n",
        "\n",
        "# Approach (b): Separate Linear Layers and Summing Results\n",
        "output_x = linear_layer_x(x.t()).repeat(N, 1)  # (N, p)\n",
        "output_y = linear_layer_y(y.t())  # (N, p)\n",
        "output_b = output_x + output_y  # (N, p)\n",
        "output_b.sum().backward()\n",
        "grad_x_b = x.grad.clone()\n",
        "grad_y_b = y.grad.clone()\n",
        "\n",
        "# Compare gradients\n",
        "print(\"Gradient w.r.t x (Approach a):\", grad_x_a)\n",
        "print(\"Gradient w.r.t x (Approach b):\", grad_x_b)\n",
        "print(\"Gradients w.r.t x are equal:\", torch.allclose(grad_x_a, grad_x_b, atol=1e-6))\n",
        "\n",
        "print(\"Gradient w.r.t y (Approach a):\", grad_y_a)\n",
        "print(\"Gradient w.r.t y (Approach b):\", grad_y_b)\n",
        "print(\"Gradients w.r.t y are equal:\", torch.allclose(grad_y_a, grad_y_b, atol=1e-6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.masked import masked_tensor\n",
        "\n",
        "data = torch.arange(24).reshape(2, 3, 4).float()\n",
        "mask = data % 2 == 0\n",
        "\n",
        "print(\"data:\\n\", data)\n",
        "print(f\"mask: {mask.dtype}\\n\", mask)\n",
        "mt = masked_tensor(data, mask)\n",
        "print(\"data masked:\\n\", mt)\n",
        "\n",
        "data2 = torch.randn(2, 3, 4)\n",
        "mt2 = masked_tensor(data2, mask)\n",
        "print(\"data2 masked:\\n\", mt2)\n",
        "\n",
        "stacked_masked = torch.vstack([mt, mt2])\n",
        "print(\"stacked_masked:\\n\", stacked_masked)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m])\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.7\u001b[39m])\n\u001b[1;32m      3\u001b[0m y\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.5000, 0.0000, 1.7000])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([True, False, True])\n",
        "y = torch.tensor([2.5, 0.0, 1.7])\n",
        "\n",
        "z = x * y  # or z = torch.bitwise_and(x, y)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 40.,   0.,   0.,   0.,   0.,   0.,  37.,   0.,   0.,   0.,  28.,\n",
              "          0.,   0.,  28.,   0.,   0.,  35.,  28.,   0.,  28.,  38.,  32.,\n",
              "          0.,  71.,  34.,  31.,  28.,  67.,  64.,  73.,  53.,  68., 110.,\n",
              "        101.,  95.,  94., 154., 121., 170., 171., 215., 195., 237., 297.,\n",
              "        324., 303., 384., 381., 431., 454., 524., 561., 659., 683., 762.,\n",
              "        861., 930.]),\n",
              " array([0.        , 0.10006636, 0.20013272, 0.30019908, 0.40026544,\n",
              "        0.5003318 , 0.60039816, 0.70046451, 0.80053087, 0.90059723,\n",
              "        1.00066359, 1.10072995, 1.20079631, 1.30086267, 1.40092903,\n",
              "        1.50099539, 1.60106175, 1.70112811, 1.80119447, 1.90126082,\n",
              "        2.00132718, 2.10139354, 2.2014599 , 2.30152626, 2.40159262,\n",
              "        2.50165898, 2.60172534, 2.7017917 , 2.80185806, 2.90192442,\n",
              "        3.00199078, 3.10205714, 3.20212349, 3.30218985, 3.40225621,\n",
              "        3.50232257, 3.60238893, 3.70245529, 3.80252165, 3.90258801,\n",
              "        4.00265437, 4.10272073, 4.20278709, 4.30285345, 4.4029198 ,\n",
              "        4.50298616, 4.60305252, 4.70311888, 4.80318524, 4.9032516 ,\n",
              "        5.00331796, 5.10338432, 5.20345068, 5.30351704, 5.4035834 ,\n",
              "        5.50364976, 5.60371612, 5.70378247]),\n",
              " <BarContainer object of 57 artists>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_val = 1\n",
        "max_val = 300\n",
        "vals = torch.randint(min_val, max_val+1, (10_000,), dtype=torch.float64)\n",
        "\n",
        "data = torch.log(vals).numpy()\n",
        "plt.hist(data, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Distribution.sample of Uniform(low: 0.0, high: 5.0)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.distributions import Uniform\n",
        "m = Uniform(torch.tensor(0.0), torch.tensor(5.0))\n",
        "m.sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3, dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([3, 4, 5], [3, 4])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = [3,4,5]\n",
        "v = u\n",
        "v = v[:2]\n",
        "\n",
        "u, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method from class D\n",
            "Method from class B\n",
            "Method from class C\n",
            "Method from class A\n"
          ]
        }
      ],
      "source": [
        "class A:\n",
        "    def method(self):\n",
        "        print(\"Method from class A\")\n",
        "\n",
        "class B(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class B\")\n",
        "        super().method()\n",
        "\n",
        "class C(A):\n",
        "    def method(self):\n",
        "        print(\"Method from class C\")\n",
        "        super().method()\n",
        "\n",
        "class D(B, C):\n",
        "    def method(self):\n",
        "        print(\"Method from class D\")\n",
        "        super().method()\n",
        "\n",
        "# Demonstration\n",
        "d = D()\n",
        "d.method()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'D' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'D' has no len()"
          ]
        }
      ],
      "source": [
        "len(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.as_tensor(3).to(dtype=torch.int32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9.1915)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.log(torch.tensor(9813))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(torch.exp(torch.rand(1)).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([45, 46, 46, 45, 45, 45, 45, 45, 45, 46], dtype=torch.int32)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(torch.rand(10)).to(dtype=torch.int32) + 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([300, 476,  12,  28,   8,  52,  98, 758, 881, 199, 176,  58,  11, 119,\n",
            "        164, 848, 173, 306,   6, 924,   3, 386,  15,  70, 565,   9, 149, 880,\n",
            "          7,  12,  51, 154, 177, 119,  39, 134,  87,   3, 143,  31,  31, 123,\n",
            "          2, 258, 957,  12, 113, 338, 393,  92,  41,  54,  22,  47, 170, 972,\n",
            "         15, 516,  41, 369,  57,  15, 383, 546,  79,  64,  12,  25,  71, 105,\n",
            "          9,  22,  92,  12,  31, 583, 111,  12, 571,  21,  49, 854, 329, 884,\n",
            "        238, 704, 116, 640, 125,  63, 145, 437,  73,   5, 917,   5,  98,  11,\n",
            "         37,   1,  82, 993,  71, 425, 712, 176, 121,  40, 776,  75, 133, 210,\n",
            "        209, 254, 535,  72, 451,   3, 710,  99, 582, 237,   9, 705, 509, 207,\n",
            "         56,  79,  53, 223,  13, 862, 292,  94, 562,  18,  15, 923,   2, 473,\n",
            "        293,  10, 229, 100, 129,  77,  30,  69, 242, 721, 956,  23,  32,  17,\n",
            "         10,  41, 721,   4, 378,  55,  45, 354, 121, 288, 120, 322,  33, 969,\n",
            "         43,  74, 146,  16,  30,  86,  24, 422,  86,   5,   6,  54,  32,   4,\n",
            "        259,  11, 461, 227,  55, 548, 422, 402,  73, 105,   2,   4,  13,  98,\n",
            "          4,  30,  38,   5, 285, 902,  88,  53, 231, 138,   6,  11,   2, 423,\n",
            "         95,  16,   7,  19,  25, 121,   1, 810,  20,  15, 192,  69, 536, 180,\n",
            "         50, 269,  20,  30,  60, 628, 178,  72, 421, 224, 435,   6, 358, 372,\n",
            "         80,  12, 562, 851,  16,  49,  55, 209,  50, 944,  61,  52, 165, 122,\n",
            "        694, 176, 845, 113, 367,  98,  83,   7, 348, 343,  65, 169,  51, 411,\n",
            "         60, 244,   6,  24, 678,  91, 620, 669, 151,  66, 267, 356,  14, 125,\n",
            "        980,  22,  18,  64, 766, 331, 637, 490,  72,  98,  62, 652,  23,  13,\n",
            "          2, 154, 868, 159, 452,  10,   2,  85, 557, 702,  43,  68,  74, 100,\n",
            "        130, 315,  75, 357,  82, 193,  12, 406,  95, 258,   7,  32, 238,  84,\n",
            "         13, 178, 773, 772, 201, 339,  83,  77, 170,   2, 885, 162, 525, 313,\n",
            "         19,   9,  37, 722,  20,   4,  71,  26,  40, 207,  38,  62, 105,  68,\n",
            "         50, 453,  88,  12, 614, 151,  30, 587, 353, 254,  51, 131,  23, 223,\n",
            "          9,  80, 248,  57, 132, 140,  52, 251, 438, 169,   4, 215, 356,  43,\n",
            "        220,  36, 226, 164,  25, 351,  44,  11,   3,  94,  10,  18, 122, 179,\n",
            "        696, 347,  64, 535, 577, 243, 269,  69,  16, 639, 160,  68, 151, 475,\n",
            "        720,  22, 278, 535,   6,  18, 660,   7,  64, 150,   4,  81,   8,  39,\n",
            "        103,  38, 167,  16, 673,  11,   5, 121,   3,  37, 248, 184,  21,   3,\n",
            "         47,  31,  30, 729, 154,  42,  44, 137, 358, 203,  43, 129,  54, 192,\n",
            "         65,  28,  28, 324, 321,  62,  17,   8, 382,  16,   6,  48,   8,   7,\n",
            "        187,  12,  42, 128,   1, 102,  16,   9,   3, 255, 201,  14,  12,   8,\n",
            "        664, 190,  15,  74,  89,   7,  10,  69, 303,   5,  18, 181,  54, 106,\n",
            "          5, 212, 676, 115, 179,  18, 231, 108, 634,  16, 296, 170,  19, 501,\n",
            "        655, 997,   4, 468, 697,  83,  78,  19,  19, 109,   3,   7,  51, 319,\n",
            "        138, 708, 177,  39, 282,  20, 719,  33,  51, 872,   1,  30, 889,  20,\n",
            "         25, 255, 647,  37, 318,  18, 147,  55, 362, 110,  31,  84, 822,  99,\n",
            "        751, 598,   9,  25, 580,  24,  43, 294,  23,  16,   4, 514,  56, 796,\n",
            "          9,  19,   4,  99, 256, 121, 954,  14,  26,  21, 656, 951, 525,  39,\n",
            "         17, 232,  24, 686,  42, 792, 122,  87, 713, 375, 596, 120, 357, 604,\n",
            "        222,  26,  55, 778,   3,   7, 126, 360, 520, 879,   1, 198, 115,  19,\n",
            "          5, 253,  81,   7, 153,  22,  38,  90,  11,  39, 537, 245,  38,  31,\n",
            "        570, 765, 323,  99, 145, 216,  35,  11, 240, 497,  77,  33,  23, 775,\n",
            "         42, 369, 207, 322,  16,  17,  17, 140, 408, 194,  75, 224, 661, 640,\n",
            "        202,  20,  55, 307, 711, 467,  73, 401,  86, 153, 383,  20, 732,  93,\n",
            "          9, 503,   2,  15,  51,   5, 209, 381,  48, 196, 108,  13,  93, 519,\n",
            "         33,  12, 387, 159,   1,  76, 564, 127, 693,   3, 265, 472, 100, 159,\n",
            "        895, 945, 292,  23, 298,   5,  85, 373, 182, 225,  84,   2, 212, 223,\n",
            "        168, 105,  15, 111, 318,  38,  56, 381, 202, 142, 489,  42, 143,  83,\n",
            "         50,  50,  59,  44,  59, 154, 532, 575,  65, 464, 655, 855, 794,   6,\n",
            "          1, 256, 273, 142,  14, 310,  11, 110, 356, 471, 110, 128, 265,  35,\n",
            "         22,   2, 675, 244, 142,  81, 116,  21, 173, 846,  61,  18,  27, 297,\n",
            "         75,  80,   2,  82,  56,  32,  18, 180,  13,   5, 258,  42, 639, 657,\n",
            "        648,  75, 312, 573, 103, 128,  87, 838, 743, 372,   5, 355,  16, 339,\n",
            "         25, 436, 824,   6,   4, 622, 165, 121, 149,  22, 164, 342,  22, 207,\n",
            "         11,  73,  23, 139, 152, 939,  13, 151,  12, 703,  58, 294,  30, 968,\n",
            "        537, 742, 202,  88,  85,  49, 110, 392,  43, 166,  17,  27,  65, 700,\n",
            "        667,   1,   1,  28,  22, 106, 219,  17,  11, 905,  91, 237,  12, 232,\n",
            "         14, 220, 128,  40, 151, 169, 343, 203,  32, 107,  78, 654, 287, 252,\n",
            "         53, 149,  49,  12, 706,  65,  76, 434, 150,  42,  49,  38,  41, 773,\n",
            "        104, 202,  43, 766, 101, 274,   6, 141, 527, 109,   1,   6, 115,  44,\n",
            "         29,  45, 310, 597, 317, 120,  22, 625,   4, 762,  14,  50,  16, 598,\n",
            "        267, 262,  24,  29,   5, 659,  10, 757,  42, 100, 153,  26,  90, 986,\n",
            "         11,   2,  26,  99, 116,  10,  21, 551,  47, 107,  74,   6, 722, 921,\n",
            "          2, 448, 108,   2, 124, 146,   1,  36,   8,   7,  80,   8, 272,  11,\n",
            "         78,   1, 512,  10, 987,  47, 222, 650, 249, 513, 799, 263,  27,  89,\n",
            "          6, 288, 566,  81,  12,  25,  86, 244, 253,  53, 287,  17, 281,  88,\n",
            "         73,  44, 504,  35,  45,  15, 303, 400, 325, 296, 349,  25,   6, 132,\n",
            "        819, 458,  55,  46,   4,   2, 661, 383, 426, 136, 405,   2, 313,  60,\n",
            "        455, 405,  11,  52,   5, 198], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vals = loguniform_randint(1, 1000, 1000, pre_offset=15.0)\n",
        "print(vals)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(2, 1, 1)\n",
        "# ax.hist(vals.numpy(), bins=500)\n",
        "# ax.set_xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 + 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7867, -0.2701,  0.1800],\n",
              "        [-0.4704, -0.5729, -0.2115]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661],\n",
              "        [ 0.7351,  2.2052, -0.1024],\n",
              "        [ 0.3160,  1.1978, -1.0705],\n",
              "        [ 0.0312, -0.9250,  0.6934],\n",
              "        [ 0.6693,  0.9474,  0.6085],\n",
              "        [ 0.5895,  0.2485, -0.2172],\n",
              "        [-0.6764,  2.4663, -0.7710],\n",
              "        [ 0.1756,  0.0874, -0.2661]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randn(7, 3)\n",
        "torch.cat((w, w), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0335, -1.5776, -0.1009],\n",
              "        [-1.4248,  0.2405, -0.1990],\n",
              "        [-1.5726, -0.2506,  0.8141],\n",
              "        [-0.5141,  0.7484, -0.5117],\n",
              "        [-2.6152, -0.0900, -1.0199],\n",
              "        [-1.2312, -0.2395, -0.3144],\n",
              "        [-1.1721,  1.2124, -1.7637],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = list(w.shape)\n",
        "pad_shape = list(w.shape)\n",
        "pad_shape[0] = 10\n",
        "padding = torch.zeros(*pad_shape, dtype=w.dtype, device=w.device)\n",
        "padded = torch.cat([w, padding], dim=0)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0232, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "loss = nn.MSELoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "output = loss(input, target)\n",
        "# output.backward()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
